<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="15 Optimum Approximation | Project XXII" />
<meta property="og:type" content="book" />





<meta name="author" content="Zhengyuan Gao" />

<meta name="date" content="2021-03-10" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="15 Optimum Approximation | Project XXII">

<title>15 Optimum Approximation | Project XXII</title>

<link href="libs/tufte-css/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>



</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Project XXII<p><p class="author">Zhengyuan Gao</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BA; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Preface</a>
<a href="part-i-inference-based-upon-logic-and-logical-computation.html">PART I: Inference Based upon Logic and Logical Computation</a>
<a href="sub-logic.html"><span class="toc-section-number">1</span> Logic</a>
<a href="sub-set-theory.html"><span class="toc-section-number">2</span> Set Theory</a>
<a href="sub-axioms.html"><span class="toc-section-number">3</span> Axioms</a>
<a href="sub-inferknow.html"><span class="toc-section-number">4</span> Inference and Knowledge</a>
<a href="sub-incomplete.html"><span class="toc-section-number">5</span> Incompleteness</a>
<a href="part-ii-infinitesimal-changes-and-their-consequences.html">PART II: Infinitesimal Changes and their Consequences</a>
<a href="sub-continuity.html"><span class="toc-section-number">6</span> Continuity</a>
<a href="sub-calculus.html"><span class="toc-section-number">7</span> Calculus</a>
<a href="ch-DE.html"><span class="toc-section-number">8</span> Differential Equations</a>
<a href="ch-CalUn.html"><span class="toc-section-number">9</span> Calculus under Uncertainty</a>
<a href="part-iii-emergence-of-abstract-interactions.html">PART III: Emergence of Abstract Interactions</a>
<a href="ch-vecMat.html"><span class="toc-section-number">10</span> Vector and Matrix</a>
<a href="ch-MatComp.html"><span class="toc-section-number">11</span> Matrix Computation</a>
<a href="ch-eigen.html"><span class="toc-section-number">12</span> Eigenvalues and Eigenvectors</a>
<a href="ch-UnMulti.html"><span class="toc-section-number">13</span> Uncertainty in Multiple Dimensions</a>
<a href="part-iv-three-masons-to-illuminate-the-dual-world.html">PART IV: Three Masons to Illuminate the Dual World</a>
<a href="ch-representation.html"><span class="toc-section-number">14</span> Representation</a>
<a id="active-page" href="ch-optApp.html"><span class="toc-section-number">15</span> Optimum Approximation</a><ul class="toc-sections">
<li class="toc"><a href="#sub:appSys"> Approximating Systems</a></li>
<li class="toc"><a href="#sub:Optimization"> Optimization and Inequalities</a></li>
<li class="toc"><a href="#sub:Proj1"> Miscellaneous Examples: Part 1</a></li>
<li class="toc"><a href="#sub:Proj2"> * Miscellaneous Examples: Part 2</a></li>
</ul>
<a href="ch-randomization.html"><span class="toc-section-number">16</span> Randomization</a>
<a href="bibliography.html">Bibliography</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="ch:optApp" class="section level1">
<h1>
<span class="header-section-number">15</span> Optimum Approximation</h1>
<p>The adjective word optimum and the noun approximation reflect two philosophical, one secular and one sacred, attitudes towards a closeted world. Suppose the representation was thought of relating to the omniscience of God; in that case, the approximation should distract our attention from omnipotences to a milieu of <em>bounded beings</em> who are continuously driven by the operations with imperfect, limited scopes.<label for="tufte-sn-366" class="margin-toggle sidenote-number">366</label><input type="checkbox" id="tufte-sn-366" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">366</span> If bounded operations are defined in a proper space (a <a href="ch-MatComp.html#sub:vecSpaces">vector space</a> with defined <a href="ch-vecMat.html#sub:vec">norms</a> and <a href="ch-vecMat.html#sub:linearity">linear structures</a>), we can also call these <strong>bounded beings</strong> continuous beings.</span> The preference of aiming for “optimum” as bounded beings is metaphysical: it is believed that optimality relates to evidence of imperfection of the Creator’s wisdom.<label for="tufte-sn-367" class="margin-toggle sidenote-number">367</label><input type="checkbox" id="tufte-sn-367" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">367</span> The metaphysical roots of the <em>principle of extremes</em> (<em>principle of least action</em> in science and <em>principle of maximum utility</em> in social science) can date back to Aristotle’s statement: “Nature does nothing in vain.” It can be interpreted as follows. If there is a purpose in the nature of having imperfection, then it should lead to the disclosure of the perfect means. Later, <span class="citation">Newton (<a href="bibliography.html#ref-Newton1846">1846</a>)</span> wrote the following sentence as the first rule of his reasoning in Philosophy. “We are to admit no more causes of natural things than such as are both true and sufficient to explain their appearances.” <span class="citation">Newton (<a href="bibliography.html#ref-Newton1846">1846</a>)</span> commented on this rule by writing, “Nature is pleased with simplicity and affects not the pomp of superfluous causes.”</span></p>
<p>Our world is too complex, while our life-time, our intellectual scales, and our physical abilities are too limited compared to the orders of magnitudes of such complexity. We have neither the knowledge nor the computational facility required to formulate all the terms correctly in a system of equations for understanding the universe, the earth, the society, or even ourselves. On the other hand, the logical machinery, together with the axiomatizations of laws and orders, has established a closeted limited realm within which the procedures and subroutines of bounded beings make explicit the advantages of natural modularities and hierarchical organizations to achieve constructive triumphs.</p>
<p>The ideology descending from optimum approximation is <a href="ch-DE.html#sub:MecWorld">reductionism</a>. It allows us to move from an intractable situation with a full set of elements to an easy-going place in the absence of non-principal ones. Unlike the <strong>holism</strong> flavor wrapped in Leibniz’s <a href="ch-representation.html#sub:pseudoRandom">representation</a>, the approximating thing is imperfect so that the ontological identity no longer holds.<label for="tufte-sn-368" class="margin-toggle sidenote-number">368</label><input type="checkbox" id="tufte-sn-368" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">368</span> If we set the ontological identity as <span class="math display">\[f =\sum_{i=1}^{\infty} \langle f, \phi_i\rangle \phi_i,\]</span>
then the approximation is intended to reduce the synthesis to, say a combination of <span class="math inline">\(N\)</span> principal objects, <span class="math inline">\(\sum_{i=1}^{N} \langle f, \phi_i\rangle \phi_i\)</span> by hoping that the approximating function can still reflect the causal relation of <span class="math inline">\(f\)</span>.</span>
However, with the approximation, the remaining skeleton of the <a href="ch-representation.html#sub:pseudoRandom">representational problem</a> preserves conceptual relations, approaches to the original norms, and provides understandable cognitions and constitutions that can be optimally embodied and socialized by <strong>bounded beings</strong>.</p>
<div id="sub:appSys" class="section level2">
<h2>
<span class="header-section-number">15.1</span> Approximating Systems</h2>
<p>One guiding principle in model development is Occam’s razor: “keep it simple.” More precisely, the model should be no more complicated than is necessary to represent the principal features. The intention of approximation is to replace some complicated system with a new system, one that is simpler and easier to work with, at the price of some (hopefully small) difference between the two systems. The new system is called an <em>approximating system</em>.</p>
<p>There are two critical criteria in using the approximation as a razor: first, how much nicer (or simpler) is the approximating system? Second, how similar is the approximating system to the original (or the true) one? Of course, the answers to these two questions depend on the exact meanings of nicer and similarity, which vary according to the context. The analyses of giving precise measurements to these two criteria are tied to the notations of <a href="ch-vecMat.html#sub:vec">norms</a>.<label for="tufte-sn-369" class="margin-toggle sidenote-number">369</label><input type="checkbox" id="tufte-sn-369" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">369</span> Recall that in one of the simplest approximations, the <a href="sub-calculus.html#sub:Taylor">Taylor series</a>, if the function <span class="math inline">\(f:\mathbb{R}\rightarrow \mathbb{R}\)</span> is <span class="math inline">\(n\)</span>-th order differentiable, then we have an <span class="math inline">\(n\)</span>-th order <a href="sub-calculus.html#sub:Taylor">polynomial approximation</a> <span class="math inline">\(p_n(x)=\sum_{i=1}^{n} c_i(x -a)^{i}\)</span> where <span class="math inline">\(c_i\)</span> is the <span class="math inline">\(i\)</span>-th order differentiation of <span class="math inline">\(f(x)\)</span> evaluated at <span class="math inline">\(x=a\)</span>. This approximation is only good when the error, namely <span class="math inline">\(|f(x)-p_n(x)|\)</span>, is small. Here the <a href="ch-vecMat.html#sub:vec">norm</a>, namely the absolute value, gives a measurement of the error.</span></p>
<p>In the infinite-dimensional space, the <a href="ch-vecMat.html#sub:vec">norm</a> is a special functional mapping from a vector space to the non-negative <a href="sub-continuity.html#sub:completeness">real number field</a>, and it shares some similarities with the <strong>non-negative (real-valued) linear functionals</strong>. The following table makes the comparison.<label for="tufte-sn-370" class="margin-toggle sidenote-number">370</label><input type="checkbox" id="tufte-sn-370" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">370</span> If we replace the linearity in point 3 with the condition <span class="math inline">\(\mathbf{T}(f+g)\leq \mathbf{T}(f)+\mathbf{T}(g)\)</span>, the <strong>non-negative linear functional</strong> <span class="math inline">\(\mathbf{T}\)</span> is called the <em>sub-additive functional</em>.</span></p>
<table>
<colgroup>
<col width="30%">
<col width="38%">
<col width="30%">
</colgroup>
<thead><tr class="header">
<th align="center">Definition</th>
<th align="left"><a href="ch-vecMat.html#sub:vec">Norm</a></th>
<th align="left"><em>Non-negative linear functional</em></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">1.</td>
<td align="left">Positive definiteness, non-degeneracy:</td>
<td align="left">Positive definiteness, non-degeneracy:</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="left">
<span class="math inline">\(\|f\|\geq0\)</span> for all <span class="math inline">\(f\in\mathcal{V}\)</span>, and <span class="math inline">\(\|f\|=0\)</span> if and only if <span class="math inline">\(f=0\)</span>.</td>
<td align="left">
<span class="math inline">\(\mathbf{T}(f)\geq0\)</span> for all <span class="math inline">\(f\in\mathcal{V}\)</span>, and <span class="math inline">\(\mathbf{T}(f)=0\)</span> if and only if <span class="math inline">\(f=0\)</span>.</td>
</tr>
<tr class="odd">
<td align="center">2.</td>
<td align="left">Multiplicativity:</td>
<td align="left">Multiplicativity:</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="left">
<span class="math inline">\(\|af\|=|a|\times\|f\|\)</span> for all <span class="math inline">\(f\in\mathcal{V}\)</span> and scalars <span class="math inline">\(a\)</span>.</td>
<td align="left">
<span class="math inline">\(|\mathbf{T}(af)|=|a|\times|\mathbf{T}(f)|\)</span> for all <span class="math inline">\(f\in\mathcal{V}\)</span>. and scalars <span class="math inline">\(a\)</span>.</td>
</tr>
<tr class="odd">
<td align="center">3.</td>
<td align="left">
<a href="sub-continuity.html#sub:continuousFunc">Triangle inequality</a>:</td>
<td align="left">Linearity:</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="left">
<span class="math inline">\(\|f+g\|\leq\|f\|+\|g\|\)</span> for <span class="math inline">\(f,g\in\mathcal{V}\)</span>.</td>
<td align="left">
<span class="math inline">\(\mathbf{T}(f+g)=\mathbf{T}(f)+\mathbf{T}(g)\)</span> for <span class="math inline">\(f,g\in\mathcal{V}\)</span>.</td>
</tr>
</tbody>
</table>
<p>In between the linear functionals and norms in the infinite-dimensional vector space lies the <a href="ch-vecMat.html#sub:vec">inner product</a> because the <a href="ch-vecMat.html#sub:vec">inner product</a> always gives rise to a norm <span class="math inline">\(\|f\|=\sqrt{\langle f, f\rangle}\)</span>, and always acquires the linear property in a <a href="ch-representation.html#sub:conjugacy">Hilbert space</a>, <span class="math inline">\(\mathbf{T}(f)= \langle f, \cdot \rangle\)</span>. The only difference between the <a href="ch-vecMat.html#sub:vec">norm</a> and the <a href="ch-vecMat.html#sub:vec">inner product</a> is that functional defined by a norm only focus on the distance (a real value) while the functional defined by an inner product focus on both the distance and angle (between two points).<label for="tufte-sn-371" class="margin-toggle sidenote-number">371</label><input type="checkbox" id="tufte-sn-371" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">371</span> Notice that the <a href="ch-representation.html#sub:conjugacy">orthogonality</a> (90 degree angle) defined by the <a href="ch-vecMat.html#sub:vec">inner product</a> cannot be specified only by the <a href="ch-vecMat.html#sub:vec">norms</a>. To see this, notice that the orthogonality is characterized by the <a href="ch-vecMat.html#sub:vec">generalized Pythagoras’ theorem</a>:
<span class="math display">\[\|f+g\|^{2}=\|f\|^2 +\|g\|^2.\]</span>
The equality holds for every orthogonal pair <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> from an <a href="ch-representation.html#sub:innerProd">inner product space</a>. But this equality is a special case of
<span class="math display">\[\begin{align*}
\|f+g\|^2 &amp;= \langle f+g, f+g \rangle\\
&amp;= \|f\|^2+\|g\|^2 + 2\langle f, g\rangle 
\end{align*}\]</span>
when <span class="math inline">\(\langle f, g\rangle=\|f\|\|g\|\cos90^{\circ}=0\)</span> (see <a href="ch-vecMat.html#eq:inner-2">(10.3)</a>). In other words, the definition of orthogonality makes use of the angle information contained in the inner product <span class="math inline">\(\langle \cdot, \cdot \rangle :\mathcal{V}\times\mathcal{V}\rightarrow \mathbb{R}\)</span>.</span> Thus, we can say that the vector space attached to the <a href="ch-vecMat.html#sub:vec">norm</a> structure requires less specifications than the <a href="ch-vecMat.html#sub:vec">inner product</a> structure, and thus the <a href="ch-vecMat.html#sub:vec">norm</a> structure is more general than the <a href="ch-vecMat.html#sub:vec">inner product</a> structure.</p>
<p>One important motivation for extending the attention from the inner product structure to the norm is that we can confront a “bigger” dual that is <a href="sub-continuity.html#sub:completeness">complete</a>. We discussed in chapter <a href="ch-representation.html#sub:dualBasis">14.4</a> that the <a href="ch-representation.html#sub:dualBasis">dual spaces</a> of the <a href="ch-representation.html#sub:conjugacy">Hilbert spaces</a> or the finite-dimensional <a href="ch-MatComp.html#sub:vecSpaces">vector spaces</a> preserve structures from the original ones. But in general, a <a href="#dualBasis">dual space</a> is “bigger” than its original space. A “bigger” often brings in additional complications. But if the <a href="ch-vecMat.html#sub:vec">vector space</a> is attached to the <a href="ch-vecMat.html#sub:vec">norm</a>, the “bigger” size allows its <a href="ch-representation.html#sub:dualBasis">dual space</a> to makes the <a href="sub-continuity.html#sub:completeness">completion</a> of itself.</p>
<ul>
<li>A vector space <span class="math inline">\(\mathcal{V}\)</span> endowed with a <a href="ch-vecMat.html#sub:vec">norm</a> on <span class="math inline">\(\mathcal{V}\)</span> is called the <em>normed vector space</em>, denoted by <span class="math inline">\((\mathcal{V},\|\cdot\|)\)</span>. The <em>dual normed space</em> <span class="math inline">\(\mathcal{V}^{*}\)</span> consists of all the continuous <a href="ch-MatComp.html#sub:vecSpaces">linear functionals</a> of the <strong>normed vector space</strong>. When the dual space <span class="math inline">\(\mathcal{V}^*\)</span> is equipped with the <em>supremum norm</em> or the <em>infimum norm</em><label for="tufte-sn-372" class="margin-toggle sidenote-number">372</label><input type="checkbox" id="tufte-sn-372" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">372</span> Note that definitions given in <a href="ch-optApp.html#eq:norm-2">(15.2)</a> and <a href="ch-optApp.html#eq:norm-4">(15.4)</a> are simply the normalized versions of <a href="ch-optApp.html#eq:norm-1">(15.1)</a> and <a href="ch-optApp.html#eq:norm-3">(15.3)</a>, respectively. The equivalence between <a href="ch-optApp.html#eq:norm-1">(15.1)</a> and <a href="ch-optApp.html#eq:norm-3">(15.3)</a> gives a <a href="ch-representation.html#sub:dualBasis">duality</a> that holds for the functions and their bounds. Such a duality is analogous to the one in the inner product space, i.e., the duality between the basis function and Fourier series coefficient. Examples will be given in sec[?]</span>
<span class="math display" id="eq:norm-4">\[
\begin{align}
\|\mathbf{T}\| &amp;= \sup \left\{ \frac{|\mathbf{T}(f)|}{\|f\|} \,:\,  f\in\mathcal{V},\ \right \} \tag{15.1}\\
&amp;= \sup_{ f\in\mathcal{V}}\frac{|\mathbf{T}(f)|}{\|f\|}=\sup_{ f\in\mathcal{V},\,  \|f\|=1}|\mathbf{T}(f)| \tag{15.2}\\
&amp;= \inf \left\{ M \,:\, \frac{|\mathbf{T}(f)|}{\|f\|}\leq M,\, f\in\mathcal{V} \right\} \tag{15.3}\\
&amp; = \inf_{ f\in\mathcal{V},\,  \|f\|=1, |\mathbf{T}(f)|\leq M} M \tag{15.4}
\end{align}\]</span>
for any <a href="ch-MatComp.html#sub:vecSpaces">linear functional</a> <span class="math inline">\(\mathbf{T}\in\mathcal{V}^*\)</span>, then the <strong>dual normed space</strong> is a <em>complete normed space</em> (even if <span class="math inline">\(\mathcal{V}\)</span> is not complete). A <em>complete normed space</em> is also called the <em>Banach space</em>.</li>
</ul>
<p>An <a href="ch-representation.html#sub:innerProd">inner product space</a> is a particular kind of <strong>normed vector space</strong>. So the <a href="ch-representation.html#sub:conjugacy">Hilbert space</a> is a particular kind of <strong>Banach space</strong>.</p>
<div class="solution">
<p class="solution-begin">
Equivalence of the supremum norm and the infimum norm <span id="sol-start-88" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-88', 'sol-start-88')"></span>
</p>
<div id="sol-body-88" class="solution-body" style="display: none;">
<p>Let <span class="math inline">\(\sup_{f\in\mathcal{V},\,\|f\|=1}|\mathbf{T}(f)|=\overline{M}\)</span> and let <span class="math inline">\(\inf_{f\in\mathcal{V},\,\|f\|=1,|\mathbf{T}(f)|\leq M}M=\underline{M}\)</span>. We need to show <span class="math inline">\(\underline{M}=\overline{M}\)</span>. Suppose <span class="math inline">\(\underline{M}\neq\overline{M}\)</span>. So there is some <span class="math inline">\(\epsilon\in\mathbb{R}\)</span> such that <span class="math inline">\(\underline{M}+\epsilon=\overline{M}\)</span>.</p>
<p>Suppose <span class="math inline">\(\epsilon&gt;0\)</span>. The definition of the infimum norm
<span class="math display">\[\inf_{f\in\mathcal{V},\,\|f\|=1,|\mathbf{T}(f)|\leq M}M=\underline{M}\]</span> says that <span class="math inline">\(|\mathbf{T}(f)|\leq\underline{M}\)</span> for all <span class="math inline">\(\mathbf{T}\in\mathcal{V}^{*}\)</span>. Then for all <span class="math inline">\(\mathbf{T}\in\mathcal{V}^{*}\)</span>, there is
<span class="math display">\[|\mathbf{T}(f)|\leq\underline{M}\Leftrightarrow|\mathbf{T}(f)|+\epsilon\leq\underline{M}+\epsilon=\overline{M}\]</span>
which says that <span class="math inline">\(|\mathbf{T}(f)|\leq\overline{M}-\epsilon\)</span>. As <span class="math inline">\(\epsilon&gt;0\)</span>, we can say <span class="math inline">\(|\mathbf{T}(f)|\leq\overline{M}-\epsilon/2\)</span> for all <span class="math inline">\(\mathbf{T}\in\mathcal{V}^{*}\)</span>. Thus, we find another <a href="sub-continuity.html#sub:completeness">supremum</a> <span class="math display">\[\sup_{f\in\mathcal{V},\,\|f\|=1}|\mathbf{T}(f)|=\overline{M}-\epsilon/2\]</span> which contradicts with the definition of <a href="sub-continuity.html#sub:completeness">supremum</a>. So <span class="math inline">\(\epsilon\)</span> cannot be positive.</p>
<p>Suppose <span class="math inline">\(\epsilon&lt;0\)</span>. So <span class="math inline">\(\underline{M}=\overline{M}-\epsilon\)</span> implies <span class="math inline">\(\underline{M}&gt;\overline{M}\)</span>. It says that
<span class="math display">\[\inf\left\{ M\,:\,\frac{|\mathbf{T}(f)|}{\|f\|}\leq M,\, f\in\mathcal{V}\right\} &gt;\sup\left\{ \frac{|\mathbf{T}(f)|}{\|f\|}\,:\, f\in\mathcal{V},\ \right\}\]</span> an obvious contradiction. So <span class="math inline">\(\epsilon\)</span> cannot be negative.</p>
<p>We can conclude that <span class="math inline">\(\epsilon\)</span> has to be zero. The result follows.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The <a href="sub-continuity.html#sub:completeness">supremum</a> and <a href="sub-continuity.html#sub:completeness">infimum</a> on the <a href="sub-continuity.html#sub:completeness">real number field</a> make sure that a continuous function over a bounded interval <span class="math inline">\([a,b]\)</span> always has its maximum and minimum. The <strong>supremum norm</strong> or the <strong>infimum norm</strong> offers a strict criterion for assessing the continuity.<label for="tufte-sn-373" class="margin-toggle sidenote-number">373</label><input type="checkbox" id="tufte-sn-373" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">373</span> We have seen in figure <a href="ch-representation.html#fig:stepFun">14.4</a> that a convergent sequence of continuous functions may not preserve the continuity under the <span class="math inline">\(l_2\)</span>-norm. Hence, the space of all continuous functions <span class="math inline">\(\mathcal{C}([a,b])\)</span> under the <span class="math inline">\(l_{2}\)</span>-norm is incomplete. But if we assess the continuity using the <strong>supremum norm</strong>, we can see that the functions in the convergent sequence are all discontinuous as
<span class="math display">\[\sup_{x\in [0,\pi]} f_n(x)= 1\, \\
\sup_{x\in [-\pi,0)} f_n(x)= 0\]</span>
for any <span class="math inline">\(n\in\mathbb{N}\)</span>. Also for the <strong>infimum norm</strong>, the discontinuity appears at <span class="math inline">\(1/n\)</span>, as for any <span class="math inline">\(n\in\mathbb{N}\)</span>
<span class="math display">\[\inf_{x\in [1/n,\pi]} f_n(x)= 1 \\
\inf_{x\in [-\pi,1/n)} f_n(x)= 0.\]</span> Thus, the function in figure <a href="ch-representation.html#fig:stepFun">14.4</a> should not belong to the space <span class="math inline">\(\mathcal{C}([a,b])\)</span> under the <strong>supremum norm</strong> or <strong>infimum norm</strong>. In fact, <span class="math inline">\(\mathcal{C}([a,b])\)</span> becomes a <a href="sub-continuity.html#sub:completeness">complete</a> <strong>normed space</strong>, namely a <strong>Banach space</strong>, under the <strong>supremum norm</strong> or <strong>infimum norm</strong>.</span> The <a href="sub-continuity.html#sub:completeness">completion</a> of the <strong>dual normed space</strong> is due to this strict criterion: if the functionals under the best scenario and the worst scenario are bounded/continuous according to the <strong>supremum norm</strong> or the <strong>infimum norm</strong>, all the other <a href="ch-MatComp.html#sub:vecSpaces">linear functionals</a> should also be bounded/continuous.</p>
<p>Note that the <strong>dual normed space</strong> is <a href="sub-continuity.html#sub:completeness">complete</a> even though the original <strong>normed space</strong> is not. This feature is useful. As many approximation problems cannot find an exact answer in the original setting, people have to switch to the <strong>dual normed space</strong> where the “completion” of the space guarantees the existence of the solution. For example, if
a system <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span> consists of <span class="math inline">\(n\)</span> linear equations but only <span class="math inline">\(k\)</span> unknown variables (<span class="math inline">\(k&lt;n\)</span>). Then the system is an <a href="ch-MatComp.html#sub:GElimination">overdetermined system</a>. That is, no solution <span class="math inline">\(\mathbf{x}^*\)</span> exists for <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span>. To resolve the problem, one needs to reformulate an <strong>approximating system</strong>. Suppose that the <strong>approximating system</strong> is to make the residual vector <span class="math inline">\(\mathbf{A}\mathbf{x}-\mathbf{x}\)</span> as “small” as possible, and this system is solvable under some functional operation. The solution, say <span class="math inline">\(\hat{\mathbf{x}}\)</span>, will not belong to the set containing the original object but some other set.<label for="tufte-sn-374" class="margin-toggle sidenote-number">374</label><input type="checkbox" id="tufte-sn-374" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">374</span> Let <span class="math inline">\(\mathbf{x}\)</span> belong to the vector space <span class="math inline">\(\mathbb{R}^{k}\)</span>. The solution vector <span class="math inline">\(\hat{\mathbf{x}}\)</span> usually is from the space <span class="math inline">\(\mathcal{L}(\mathbb{R}^{k},\mathbb{R}^{k})\)</span>, a set of all linear operators mapping from <span class="math inline">\(\mathbb{R}^{k}\)</span> to <span class="math inline">\(\mathbb{R}^{k}\)</span>. The linear operator <span class="math inline">\(\hat{\mathbf{x}}\)</span> consists of linear functionals <span class="math inline">\(\hat{x}_1, \dots, \hat{x}_k\)</span>. So the solutions <span class="math inline">\(\hat{x}_1, \dots, \hat{x}_k\)</span> are from in the <strong>dual normed space</strong>. In other words, each <span class="math inline">\(\hat{x}_i\)</span> of the solution vector is a functional belonging to the <strong>dual normed space</strong> rather than a scalar.</span>
In particular, if the solution set of the <strong>approximating system</strong> belongs to the <strong>dual normed vector space</strong>, we expect that the solution will always exist. So we call the solution of the <strong>approximating system</strong> the <em>approximation</em>.</p>
<p>To fulfill the goal of pushing the solution set to a <strong>Banach space</strong>, when we model an <strong>approximating system</strong>, we often consider the setup to be solvable by one continuous linear <a href="ch-MatComp.html#sub:vecSpaces">operator</a> or a sequence of them. Also, we hope that the norms of these <a href="ch-MatComp.html#sub:vecSpaces">operators</a> should approximate the unit value so that these <strong>approximations</strong> have the tendencies to preserve the <a href="ch-vecMat.html#sub:vec">norms</a> of the “solutions” in the original system.</p>
<p>Formally speaking, solving an <strong>approximating system</strong> depends on the <em>“hat” operator</em> <span class="math inline">\(\hat{(\cdot)}:\mathcal{V}\rightarrow\mathcal{V}^{*}\)</span>, namely <span class="math inline">\(\hat{(\cdot)} \in \mathcal{L}(\mathcal{V},\mathcal{V}^{*})\)</span> where <span class="math inline">\(\mathcal{L}(\mathcal{V},\mathcal{V}^{*})\)</span> denotes the set of all continuous linear mapping from <span class="math inline">\(\mathcal{V}\)</span> to <span class="math inline">\(\mathcal{V}^{*}\)</span>.<label for="tufte-sn-375" class="margin-toggle sidenote-number">375</label><input type="checkbox" id="tufte-sn-375" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">375</span> The <strong>hat operator</strong> emerged in several fields under different names. The successive series started in physics (quantum position measurement) around the 1920s, then it spread to operation research (optimizer), statistics and information theory (point estimator), economics and finance (pricing operator). Indeed, there is a hidden inter-connection among these subjects. All their intentions are trying to approximate the real-world phenomena (the quantum movements, the transportation flows, the observable samples or the receiving signals, and changes of commodities) with some analytical systems that are believed to be solvable (eigensystem, linear programming, likelihoods/entropies, and supply-demand models). The <strong>hat operator</strong> did a wonderful job as it can always provide a “solution” to any of these real-world problems. However, many people are apparently ignoring (or perhaps unaware) the fact that these “solutions” given by the dual, and blindly worship some of these operators as “the” solutions of the real phenomena.</span> On many occasions, we want the <strong>hat operator</strong> to preserve the norm such that <span class="math inline">\(\|\hat{f}\|=\|f\|\)</span> for every <span class="math inline">\(f\in\mathcal{V}\)</span>.</p>
<p>All <strong>approximations</strong> can be conducted in either one-step or multiple-steps. Let’s consider two representative examples.</p>
<p><span class="newthought">One-step approximation </span></p>
<p>The <strong>approximation</strong> <span class="math inline">\(\hat{\mathbf{x}}=(\mathbf{A}^{\top}\mathbf{A})^{-1}\mathbf{A}^{\top}\mathbf{b}\)</span> of the system <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span> is a <strong>hat operator</strong>. It is also the solution of the following <strong>approximating system</strong>
of minimizing the residual <span class="math inline">\(\mathbf{A}\mathbf{x}-\mathbf{b}\)</span> in terms of the <span class="math inline">\(\ell_2\)</span>-norm:
<span class="math display">\[\min_{\mathbf{x}}(\mathbf{A}\mathbf{x}-\mathbf{b})^\top (\mathbf{A}\mathbf{x}-\mathbf{b}).\]</span>
To see this, the norm <span class="math inline">\((\mathbf{A}\mathbf{x}-\mathbf{b})^\top (\mathbf{A}\mathbf{x}-\mathbf{b})\)</span> is a quadratic term. By taking a second derivative of the norm with respect to <span class="math inline">\(\mathbf{x}\)</span>, we have <span class="math inline">\(\mathbf{A}^{\top}\mathbf{A}\geq0\)</span>. According to the optimality criterion given in chapter <a href="sub-calculus.html#sub:opt">7.3</a>, we know that any <span class="math inline">\(\mathbf{x}\)</span> that can attain zero for the first derivative of the norm will give the minimum of the norm. The first derivative is
<span class="math inline">\(2\mathbf{A}^\top (\mathbf{A}\mathbf{x}-\mathbf{b})=0 \Leftrightarrow \mathbf{A}^\top\mathbf{A}\mathbf{x}=\mathbf{A}^\top\mathbf{b}.\)</span>
By inverting <span class="math inline">\(\mathbf{A}^\top\mathbf{A}\)</span> on both sides, we have the solution <span class="math inline">\(\hat{\mathbf{x}}=(\mathbf{A}^{\top}\mathbf{A})^{-1}\mathbf{A}^{\top}\mathbf{b}\)</span>. Note that this solution exists even if <span class="math inline">\(\mathbf{A}\)</span> is not a square matrix (the number of unknowns and the number of equations do not match). That is to say, the solution <span class="math inline">\(\hat{\mathbf{x}}\)</span> may or may not be the solution of <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{b}\)</span>.</p>
<p><span class="newthought">Sequential approximation </span></p>
<p>Consider a dynamical system of simultaneous equations:
<span class="math display">\[u_{t}(x_{j})=\sum_{s=1}^{n}p_{js}u_{t-1}(x_{s}),\, j=1,\dots n,\]</span>
where <span class="math inline">\(u_t(\cdot)\)</span> stands for an unknown function at time <span class="math inline">\(t\)</span>, <span class="math inline">\(x_{j}\)</span> is the state value of the input of the function, <span class="math inline">\(p_{js}\)</span> is from an <span class="math inline">\(n\times n\)</span>
<a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a> <span class="math inline">\(\mathbf{P}=[p]_{js}\)</span>. The system can be written in matrix form <span class="math display">\[\mathbf{u}_t=\mathbf{P}\mathbf{u}_{t-1}.\]</span>
Because <span class="math inline">\(\mathbf{u}_t(\cdot)\)</span> is an unknown vector given by an unknown function, we need to approximate <span class="math inline">\(\mathbf{u}_t(\cdot)\)</span> by some tractable candidate. Let the <strong>approximation</strong> at <span class="math inline">\(t\)</span>-step be
<span class="math inline">\(\hat{\mathbf{u}}_t= [\langle \mathbf{c}_t, \phi(x_1)\rangle, \dots, \langle \mathbf{c}_t, \phi(x_n)\rangle]^\top\)</span>, where <span class="math inline">\(\phi(\cdot)\)</span> is the <a href="ch-representation.html#sub:innerProd">basis function</a>, and <span class="math inline">\(\mathbf{c}_t\)</span> is the coefficient vector. The <strong>approximating system</strong> is
<span class="math display">\[\begin{align*}
\mbox{at time }t: &amp; \,\, \hat{\mathbf{u}}_t= [\langle \hat{\mathbf{c}}_t, \phi(x_1)\rangle, \dots, \langle \hat{\mathbf{c}}_t, \phi(x_n)\rangle]^\top \\
\mbox{ where } \hat{\mathbf{c}}_t \mbox{ is from } &amp;\,\, \min_{\mathbf{c}_t} \| \hat{\mathbf{u}}_t - \mathbf{P}\hat{\mathbf{u}}_{t-1}\|\\
\mbox{at time }t+1: &amp; \, \, \hat{\mathbf{u}}_{t+1}= [\langle \hat{\mathbf{c}}_{t+1}, \phi(x_1)\rangle, \dots, \langle \hat{\mathbf{c}}_{t+1}, \phi(x_n)\rangle]\top \\
\mbox{ where } \hat{\mathbf{c}}_{t+1} \mbox{ is from } &amp;\,\, \min_{\mathbf{c}_{t+1}} \| \hat{\mathbf{u}}_{t+1}- \mathbf{P}\hat{\mathbf{u}}_{t}\|\\
\vdots &amp;
\end{align*}
\]</span>
Note that we have a sequence of <strong>hat operators</strong> <span class="math inline">\(\{\hat{\mathbf{u}}_1, \hat{\mathbf{u}}_2,\dots, \hat{\mathbf{u}}_t\}\)</span> for this system up to time <span class="math inline">\(t\)</span> rather than a single one.</p>
<p>By now, we know that if we can present the original system by an approximating one whose solution is defined on the <strong>dual normed space</strong>, the solution for the <strong>approximating system</strong> always exists. But we haven’t known yet how to specify a general routine to set up the <strong>approximating system</strong>.</p>
<p>Recall the previous routine of representing an object in the <a href="ch-representation.html#sub:innerProd">inner product space</a>. We project any object of the <a href="ch-representation.html#sub:innerProd">inner product space</a> onto a basis system that spans the space. The basis system is known; therefore, they are tractable for presenting the object. Similarly, an <strong>approximating system</strong> emerges when we project some object that belongs to an “unapproachable” set onto an “approachable” set. The minimizations in both above examples are actually the <strong>metric projection operators</strong> for the <strong>normed vector space</strong>.</p>
<p>For a <strong>normed vector space</strong> <span class="math inline">\((\mathcal{V},\|\cdot\|)\)</span>, the operator <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}(f)\)</span> is called <em>metric projection operator</em> if it yields the multi-valued operator between the point <span class="math inline">\(f\in\mathcal{V}\)</span> and the nearest point(s) <span class="math inline">\(\hat{f}\in\mathcal{Y}\subset\mathcal{V}\)</span>:
<span class="math display">\[\mathbf{P}_{\mathcal{Y}}(f)=\hat{f},\,\,\mbox{with }\,  \|f - \hat{f}\|=\inf_{g\in\mathcal{Y}}\|f-g\|\]</span>
where the set <span class="math inline">\(\mathcal{Y}\)</span> is projected set.</p>
<p>If we consider <span class="math inline">\(f\)</span> as the original system of interests, setting up an <strong>approximating system</strong> is equivalent to defining a <strong>metric projection operator</strong> of <span class="math inline">\(f\)</span> on the <a href="ch-UnMulti.html#sub:WLLN">a priori</a> selected set <span class="math inline">\(\mathcal{Y}\)</span> where the systems are all solvable or computable (or understandable) by human beings.<label for="tufte-sn-376" class="margin-toggle sidenote-number">376</label><input type="checkbox" id="tufte-sn-376" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">376</span> The projected set <span class="math inline">\(\mathcal{Y}\)</span> includes the <strong>approximating system</strong> but does not necessarily <span class="math inline">\(f\)</span>.</span></p>
<p>Notice that the <strong>metric projection operator</strong> is a multi-valued operator. The multi-valued operator allows us to project the original system onto multiple approximating ones.<label for="tufte-sn-377" class="margin-toggle sidenote-number">377</label><input type="checkbox" id="tufte-sn-377" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">377</span> There could be multiple <span class="math inline">\(\hat{f}_i\)</span> such that
<span class="math display">\[\inf_{g\in\mathcal{Y}}\|f-g\|=\\
\|f-\hat{f}_1\|=\|f-\hat{f}_2\|=\cdots\]</span>
That is to say, you can project <span class="math inline">\(f\)</span> to several directions, and multiple nearest points are corresponding to this projection. Thus the <strong>metric projection operator</strong> is <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}(f)=\{\hat{f}_{i}\}\)</span>.</span> But the cost of this generality is that it is ambiguous to proceed on which system. To avoid ambiguity, people often shift their attention to the set <span class="math inline">\(\mathcal{Y}\)</span> that can generate a single-valued <strong>metric projection operator</strong>, namely a unique nearest point from the projection:
<span class="math display">\[\mathbf{P}_{\mathcal{Y}}(f)=\hat{f},\,\,\mbox{with }\, \|f-\hat{f}\|=\min_{g\in\mathcal{Y}}\|f-g\|.\]</span>
A technical discussion about how to characterize <span class="math inline">\(\mathcal{Y}\)</span> to achieve this goal will be given later. For the moment, I should give a remark about the role of uniqueness. Looking for a unique optimum under the <a href="sub-calculus.html#sub:opt">maximization/minimization</a> rather than multiple optima under the <a href="sub-continuity.html#sub:completeness">supremum/infimum</a> somehow relates to the visions towards the world’s order. There are various arguments in favor of the unique optimal outcome.<label for="tufte-sn-378" class="margin-toggle sidenote-number">378</label><input type="checkbox" id="tufte-sn-378" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">378</span> When the light rays are refracted in a glass window, they bend and follow the path that minimizes their travel time. A solid body moves along the direction with the least resistance through a fluid. Soap films seek to minimize their surface area, and adopt a spherical shape. While the circle shape is also the one on which Queen Dido formed the longest loop in order to enclose the largest possible territory.</span> Amongst all the arguments, perhaps the most fundamental one comes from <em>monotheism</em>, where one can derive a unique logical limit of the universal order.</p>
<div class="solution">
<p class="solution-begin">
Descartes’ proposition of NOT MANY GODS <span id="sol-start-89" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-89', 'sol-start-89')"></span>
</p>
<div id="sol-body-89" class="solution-body" style="display: none;">
<p>Proposition V in <span class="citation">Spinoza (<a href="bibliography.html#ref-Spinoza1943">1905</a>)</span></p>
<blockquote>
<blockquote>
<p>“God’s existence is known merely from the consideration of his nature”</p>
</blockquote>
</blockquote>
<p>Proposition IX in <span class="citation">Spinoza (<a href="bibliography.html#ref-Spinoza1943">1905</a>)</span></p>
<blockquote>
<blockquote>
<p>“God is omniscient”</p>
</blockquote>
</blockquote>
<p>Proposition XI in <span class="citation">Spinoza (<a href="bibliography.html#ref-Spinoza1943">1905</a>)</span></p>
<blockquote>
<blockquote>
<p>“There are not many gods”</p>
</blockquote>
</blockquote>
<p>Here is the proof of proposition XI.</p>
<p>Suppose there are many gods, say A and B.</p>
<p>Then A and B are both omniscient (Proposition IX).</p>
<p>A is the cause of the idea of B. (Proposition V)</p>
<p>B is the cause of the idea of A. (Proposition V)</p>
<p>Therefore there will be some perfection in A that is not self-caused, and likewise with B.</p>
<p>Neither A nor B is omniscient, hence they cannot be gods.</p>
<p>Therefore, there is only one God.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
</div>
<div id="sub:Optimization" class="section level2">
<h2>
<span class="header-section-number">15.2</span> Optimization and Inequalities</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:Cone"></span>
<img src="fig/Part4/cone.gif" alt="The union of infinite many nested balls gives a cone" width="100%"><!--
<p class="caption marginnote">-->Figure 15.1: The union of infinite many nested balls gives a cone<!--</p>-->
<!--</div>--></span>
</p>
<p>How to characterize the unique optimum? <a href="ch-optApp.html#sub:appSys">Monotheism</a> attaches a pyramid to the <a href="ch-UnMulti.html#sub:Markov">hierarchical chain of beings</a>. In this pyramid, this chain’s order follows a monotonic structure, and at the ultimate end, there sits one and only one being, the <a href="sub-inferknow.html#determinism">first cause</a>. This kind of pyramidal shape provides a primitive way of characterizing the uniqueness for the optimum. Different mythological symbols in several religions advertised such a characterization.
Moreover, the mythology tells us that the pyramid is far from static. The positions of the beings give them the incentives (called <em>potential energies</em> in physics) to triggers the movements within the chain. Behind these tendencies, there were forces and power (called <em>kinetic energies</em> in physics) that were actually functioning on shatter or re-order the pyramid. Consequently, ascending and descending transitions in some subsets of the pyramid happened to be the themes in various myths and religious stories. They provided variational melodies on the static staffs.<label for="tufte-sn-379" class="margin-toggle sidenote-number">379</label><input type="checkbox" id="tufte-sn-379" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">379</span> Also, they delivered several ideas/clues on how to preserve the principal order in the plays without losing attractive variations and on how to implant different seeds on the followers’ thoughts (so that the “prophets” in those sects were able to “forecast” the development of some projected movements in reality).</span></p>
<p>When we retreat to the mathematical aspect, the characterization of the unique optimality is about the (dynamical) utilization of the inequality to shape a <strong>conical</strong> type subset where things are in order. In a nutshell, a real-valued inequality provides a <strong>conical</strong> shape where the projection can attain one “peak.”<label for="tufte-sn-380" class="margin-toggle sidenote-number">380</label><input type="checkbox" id="tufte-sn-380" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">380</span> The inequalities of beings evolve under some functions or operations during the movements. In myths, most principal characters had to (at least pretended to) continuously adapt themselves to the movements so that their orders can be preserved in the storylines). The dynamical storylines preserved the (principal) subset of maintaining the chain of the inequality and pointing out the ascending/descending direction of the desired final stage.</span> This property turns out to be useful if we allow the <a href="ch-representation.html#sub:conjugacy">projection operator</a> to keep “stirring” the system (so that it can make iterative moves to approximate the object). Some special shape reserves the order, and the inequality serves as an engine force to guide the projections (and avoid them blowing up the iterations). This kind of idea was extensively studied in the <em>optimization theory</em>, a subject being largely concerned with the maximization or minimization of real-valued function(al)s over a given subset.<label for="tufte-sn-381" class="margin-toggle sidenote-number">381</label><input type="checkbox" id="tufte-sn-381" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">381</span> In 1920s, the military squad, Blackett’s Circus, applied the theory to military operations and developed a formal discipline now called operation research. Since then, the <strong>optimization theory</strong> has been applied to many other fields. For example, it helps economists to quantify the ideology about the <a href="ch-DE.html#sub:MecWorld">laissez-faire</a> by the physiocrats or the <a href="ch-DE.html#sub:MecWorld">invisible hand</a> by Smith to describe the movements of achieving an “optimal” situation of some economic system based on the principle of maximizing individual <a href="sub-axioms.html#sub:zorn">happinesses</a> or <a href="sub-axioms.html#sub:zorn">utilities</a>.</span></p>
<p>In the <a href="sub-continuity.html#sub:completeness">real number field</a> <span class="math inline">\(\mathbb{R}\)</span>, one can easily attain the optimum (maximum or minimum), as <span class="math inline">\(\mathbb{R}\)</span> is an <a href="sub-set-theory.html#sub:order">ordered</a> <a href="ch-MatComp.html#sub:vecSpaces">field</a> where the inequality order is well defined. For example, if the minimum point in a set <span class="math inline">\(\mathcal{X}\subset \mathbb{R}\)</span> exists, then the inequality
<span class="math display">\[x^{*}\leq x \mbox{ for all } x\in\mathcal{X}\]</span> immediately defines the minimum <span class="math inline">\(x^{*}\)</span>.</p>
<p>Things become non-trivial for the vectors. When we compare the vector <span class="math inline">\([3,1]\)</span> with <span class="math inline">\([2,2]\)</span>, the <a href="sub-set-theory.html#sub:order">ordering axioms</a> given in chapter <a href="sub-set-theory.html#sub:order">2.3</a> are violated. The order <span class="math inline">\(3&gt;1\)</span> for the first entities in both vectors contradicts with the order <span class="math inline">\(1&lt;2\)</span> for the second ones. One resolution is to map the vectors onto the <a href="sub-continuity.html#sub:completeness">real number field</a> where the ordering structure re-emerges on the <a href="sub-set-theory.html#sub:func">image</a> of the mappings. For a function <span class="math inline">\(f:\mathbb{R}^k\rightarrow\mathbb{R}\)</span>, if the inequality <span class="math inline">\(f(\mathbf{x})\geq f(\mathbf{x}^{*})\)</span> holds for all <span class="math inline">\(\mathbf{x}\in \mathbb{R}^{k}\)</span>, then we can say that <span class="math inline">\(x^{*}\)</span> gives the minimum value of the function <span class="math inline">\(f\)</span>.<label for="tufte-sn-382" class="margin-toggle sidenote-number">382</label><input type="checkbox" id="tufte-sn-382" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">382</span> There are infinitely many choices for selecting such a function <span class="math inline">\(f\)</span>. For example, by <a href="ch-vecMat.html#sub:vec"><span class="math inline">\(l_2\)</span>-norm</a>, <span class="math inline">\([3,1]\)</span> is <span class="math inline">\(\sqrt{10}\)</span>, and <span class="math inline">\([2,2]\)</span> is <span class="math inline">\(\sqrt{8}\)</span>. Thus one can order <span class="math inline">\([3,1]\)</span> and <span class="math inline">\([2,2]\)</span> by this norm (the size of a vector).</span></p>
<p>But the inequality <span class="math inline">\(f(\mathbf{x})\geq f(\mathbf{x}^{*})\)</span> doesn’t give any information about the “order” around the point <span class="math inline">\(\mathbf{x}^{*}\)</span>. More specifically, it doesn’t tell what kind of <a href="sub-continuity.html#sub:continuousFunc">neighborhood</a> of <span class="math inline">\(\mathbf{x}^{*}\)</span> can endow the optimal <span class="math inline">\(f(\mathbf{x}^{*})\)</span>. We need an informative inequality that can reveal some specific <a href="sub-continuity.html#sub:continuousFunc">topological structure</a> around the vector <span class="math inline">\(\mathbf{x}^{*}\)</span>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:PointLine"></span>
<img src="fig/Part4/PointLine.png" alt="A curve and its tangent lines " width="100%"><!--
<p class="caption marginnote">-->Figure 15.2: A curve and its tangent lines <!--</p>-->
<!--</div>--></span>
</p>
<p>Figure <a href="ch-optApp.html#fig:PointLine">15.2</a> reveals an interesting “duality” between points (of a curve) and their tangent lines. The shape of the curve can be specified not only by the function, but also by the collection of derivatives of this function. Recall that derivatives are about local behaviors. Given that the optimality of the function induces the inequality <span class="math inline">\(f(\mathbf{x})\geq f(\mathbf{x}^{*})\)</span>, can this “duality” disclose another inequality that makes use of the local information?</p>
<ul>
<li>
<strong>Convexity</strong> and <strong>variational inequality</strong> : Consider a set <span class="math inline">\(\mathcal{Y}\)</span>. Assume that <span class="math inline">\(\mathbf{y}_i,\mathbf{y}_j\in\mathcal{Y}\)</span> and <span class="math inline">\(\alpha \in [0,1]\)</span>. If
<span class="math display">\[\alpha \mathbf{y}_i + (1-\alpha)\mathbf{y}_j \in \mathcal{Y},\]</span>
then the set <span class="math inline">\(\mathcal{Y}\)</span> is called a <em>convex set</em>. In a finite-dimensional vector space <span class="math inline">\(\mathcal{V}=\mathbb{R}^{k}\)</span>, suppose that <span class="math inline">\(f:\mathcal{Y}\rightarrow \mathbb{R}\)</span> is <a href="sub-calculus.html#sub:diffInt">differentiable</a> on the <strong>convex set</strong> <span class="math inline">\(\mathcal{Y}\subset\mathcal{V}\)</span>, and the <a href="sub-continuity.html#sub:completeness">minimum</a> exists such that<label for="tufte-sn-383" class="margin-toggle sidenote-number">383</label><input type="checkbox" id="tufte-sn-383" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">383</span> Or say <span class="math display">\[\mathbf{y}^{*} = \arg\min_{\mathbf{y}\in\mathcal{Y}} f(\mathbf{y}),\]</span> where <span class="math inline">\(\arg\)</span> stands for the argument of the function.</span>
<span class="math display">\[f(\mathbf{y}^{*}) = \min_{\mathbf{y}\in\mathcal{Y}} f(\mathbf{y}),\]</span>
then we have the <em>variational inequality</em><label for="tufte-sn-384" class="margin-toggle sidenote-number">384</label><input type="checkbox" id="tufte-sn-384" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">384</span> Or say <span class="math display">\[\langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y}^{*}\rangle \leq \langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y}\rangle.\]</span></span>
<span class="math display">\[\left\langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y} - \mathbf{y}^{*} \right\rangle \geq 0\]</span>
where <span class="math inline">\(\nabla f(\mathbf{y}^{*})\)</span> is the <a href="ch-vecMat.html#sub:linearity">gradient</a> of <span class="math inline">\(f\)</span> evaluated at <span class="math inline">\(\mathbf{y}^{*}\)</span>.</li>
</ul>
<div class="solution">
<p class="solution-begin">
Variational inequality <span id="sol-start-90" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-90', 'sol-start-90')"></span>
</p>
<div id="sol-body-90" class="solution-body" style="display: none;">
<p>To derive the <strong>variational inequality</strong>, let’s consider any <span class="math inline">\(\mathbf{y}\in\mathcal{Y}\)</span> around the minimum <span class="math inline">\(\mathbf{y}^{*}\)</span>.
The <strong>convexity</strong> tells that
<span class="math display">\[(1-\epsilon)\mathbf{y}^{*}+\epsilon\mathbf{y}=\mathbf{y}^{*}+\epsilon(\mathbf{y}-\mathbf{y}^{*})\in\mathcal{Y}\]</span>
for any small <span class="math inline">\(\epsilon&gt;0\)</span>. The minimum condition tells that
<span class="math display">\[f\left(\mathbf{y}^{*}+\epsilon(\mathbf{y}-\mathbf{y}^{*})\right)\geq f(\mathbf{y}^{*}).\]</span>
Let’s only consider <span class="math inline">\(\mathbf{y}\)</span> and <span class="math inline">\(\mathbf{y}^{*}\)</span> in the <span class="math inline">\(i\)</span>-th entry. We know that
<span class="math display">\[\left[\frac{f\left(\mathbf{y}^{*}+\epsilon(\mathbf{y}-\mathbf{y}^{*})\right)-f(\mathbf{y}^{*})}{\epsilon(y_i-y_i^{*})}\right](y_i-y_i^{*})\geq0,\]</span>
By taking <span class="math inline">\(\epsilon\)</span> to zero, we have
<span class="math display">\[\lim_{\epsilon \rightarrow 0} \left[\frac{f\left(\mathbf{y}^{*}+\epsilon(\mathbf{y}-\mathbf{y}^{*})\right)-f(\mathbf{y}^{*})}{\epsilon(y_i-y_i^{*})}\right] = \frac{\partial
  f(\mathbf{y}^{*})}{\partial y_i}.\]</span>
We can apply the same argument to the rest entries. Then we have the inequality
<span class="math display">\[\left\langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y} - \mathbf{y}^{*} \right\rangle \geq 0.\]</span></p>
<p>The result follows.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The inequality set up an additional <a href="ch-DE.html#sub:ode">equilibrium</a> condition regarding the optimum.
The gradient <span class="math inline">\(\nabla f(\mathbf{x}^{*})\)</span> is about the effect of an <a href="sub-calculus.html#sub:diffInt">infinitesimal change</a> of <span class="math inline">\(f(\mathbf{x})\)</span> around <span class="math inline">\(\mathbf{x}^{*}\)</span>. The inequality of this <a href="sub-calculus.html#sub:diffInt">infinitesimal change</a> <span class="math inline">\(\langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y}^{*}\rangle \leq \langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y}\rangle\)</span> points out the direction on <span class="math inline">\(\mathcal{Y}\)</span> by which the linear function <span class="math inline">\(\langle \nabla f(\mathbf{y}^{*}),\:\cdot \rangle\)</span> can move towards its minimum.</p>
<p>The <strong>variational inequality</strong> also provides a standard way of constructing <a href="sub-continuity.html#sub:Cauchy">fixed point iterations</a>. By modifying the inequality a little bit, we have
<span class="math display">\[\left\langle \left(\mathbf{y}^{*}- \epsilon\nabla f(\mathbf{y}^{*}) \right)- \mathbf{y}^{*},\:\mathbf{y} - \mathbf{y}^{*} \right\rangle \leq 0\]</span>
for any arbitrary positive real number <span class="math inline">\(\epsilon\)</span>. The inequality implies the following <a href="sub-continuity.html#sub:Cauchy">fixed point</a> condition<label for="tufte-sn-385" class="margin-toggle sidenote-number">385</label><input type="checkbox" id="tufte-sn-385" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">385</span> The gradient <span class="math inline">\(\nabla f(\cdot)\)</span> is a <a href="ch-MatComp.html#sub:vecSpaces">linear functional</a>, so it is not necessarily in <span class="math inline">\(\mathcal{Y}\)</span>. But given that <span class="math inline">\(\epsilon\)</span> is small, we can replace <span class="math inline">\(\mathbf{y}^{*}- \epsilon\nabla f(\mathbf{y}^{*})\)</span> with a projection of <span class="math inline">\(\mathbf{y}^{*}- \epsilon\nabla f(\mathbf{y}^{*})\)</span> onto <span class="math inline">\(\mathcal{Y}\)</span>, i.e. <span class="math inline">\(\hat{\mathbf{y}}=\mathbf{P}_{\mathcal{Y}}(\mathbf{y}^{*}- \epsilon\nabla f(\mathbf{y}^{*}) ) \in \mathcal{Y}\)</span> so that
<span class="math display">\[\left\langle  \hat{\mathbf{y}} - \mathbf{y}^{*},\:\mathbf{y} - \mathbf{y}^{*} \right\rangle \leq 0.\]</span>
Since the above inequality holds for any <span class="math inline">\(\mathbf{y}\in\mathcal{Y}\)</span> and <span class="math inline">\(\hat{\mathbf{y}}\in\mathcal{Y}\)</span>, we may have
<span class="math display">\[\left\langle \hat{\mathbf{y}} - \mathbf{y}^{*},\:\hat{\mathbf{y}} - \mathbf{y}^{*} \right\rangle \leq 0\]</span>
that is only true when <span class="math inline">\(\hat{\mathbf{y}} = \mathbf{y}^{*}\)</span>.</span>
<span class="math display">\[\mathbf{y}^{*}=\mathbf{P}_{\mathcal{Y}}(\mathbf{y}^{*}- \epsilon\nabla f(\mathbf{y}^{*}) )\]</span> where <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}(\cdot)\)</span> is the <a href="ch-optApp.html#sub:appSys">metric projection</a> onto the subset <span class="math inline">\(\mathcal{Y}\)</span>.
The iteration of this fixed point condition can be written as <span class="math display">\[\mathbf{y}_{n+1}=\mathbf{P}_{\mathcal{Y}}(\mathbf{y}_n- \epsilon\nabla f(\mathbf{y}_n) ).\]</span></p>
<p>In fact, building up a <a href="ch-optApp.html#sub:appSys">metric projection operator</a> on the <strong>convex set</strong> and setting up a <strong>variational inequality</strong> are two sides of one coin. To grab some intuition of this statement, note that the <a href="ch-optApp.html#sub:appSys">metric projection</a> of some element in <span class="math inline">\(\mathcal{V}\)</span> onto the subset <span class="math inline">\(\mathcal{Y}\subset \mathcal{V}\)</span> defines the inequality of <span class="math inline">\(\hat{f}\in\mathcal{Y}\)</span> such that <span class="math display">\[\|f-\hat{f}\|\leq\|f-g\|\quad\mbox{for any }g\in\mathcal{Y}.\]</span>
Meanwhile, the <a href="ch-vecMat.html#sub:vec">norm</a> itself is a function(al) whose <a href="sub-set-theory.html#sub:func">image</a> is the <a href="sub-continuity.html#sub:completeness">real number field</a>. Thus, the <strong>variational inequality</strong> may come out as a “dual” effect of some “differentiation” of the <a href="ch-vecMat.html#sub:vec">norm</a>.</p>
<p>Here are some technical details. First of all, notice that if <span class="math inline">\(\mathcal{V}\)</span> is a real-valued <a href="ch-representation.html#sub:conjugacy">Hilbert space</a><label for="tufte-sn-386" class="margin-toggle sidenote-number">386</label><input type="checkbox" id="tufte-sn-386" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">386</span> To attain this inequality, we need to explicitly restrict our attention to the real-valued inner product, as the complex-valued inner product distorts the ordering structure.</span> and <span class="math inline">\(\mathcal{Y}\subset\mathcal{V}\)</span>, then the <a href="ch-optApp.html#sub:appSys">metric projection</a> (of the subset <span class="math inline">\(\mathcal{Y}\)</span>) <span class="math display">\[\mathbf{P}_{\mathcal{Y}}(f)=\arg\min_{g\in\mathcal{Y}}\|f-g\|, \mbox{ for } f\in\mathcal{V}\]</span> shares the same property of the <a href="ch-representation.html#sub:conjugacy">projection operator</a> defined for the whole <a href="ch-representation.html#sub:conjugacy">Hilbert space</a> <span class="math inline">\(\mathcal{V}\)</span> (<span class="math inline">\(\mathbf{P}_{\mathcal{V}}\)</span> in chapter <a href="ch-representation.html#sub:conjugacy">14.3</a>), namely <span class="math display">\[\mathbf{P}_{\mathcal{Y}}\mathbf{P}_{\mathcal{Y}}=\mathbf{P}_{\mathcal{Y}}.\]</span>
So the projection of some object onto a subset in the Hilbert space is about finding the minimum distance between the object and this subset.<label for="tufte-sn-387" class="margin-toggle sidenote-number">387</label><input type="checkbox" id="tufte-sn-387" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">387</span> If <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}\mathbf{P}_{\mathcal{Y}}\neq \mathbf{P}_{\mathcal{Y}}\)</span>, there would be more than one value for a single projection. It contradicts the uniqueness requirement for the minimum operation. Assume that <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}f=g_1^{*}\)</span> and <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}\mathbf{P}_{\mathcal{Y}}f=g_2^{*}\)</span> are two different projection points. Then there would be
<span class="math display">\[\|f-g_1^*\| \neq \|f-g^*_2\|.\]</span>
We have either
<span class="math display">\[\|f-g_1^*\| &gt; \|f-g^*_2\|\\ \mbox{or } \|f-g_1^*\| &lt; \|f-g^*_2\|\]</span> If <span class="math inline">\(\|f-g_1^*\| &gt; \|f-g^*_2\|\)</span>, then <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}(f)=g_2^{*}\)</span> contradicts with <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}(f)=g_1^{*}\)</span>. A similar argument holds
for the other case.</span> The <a href="ch-optApp.html#sub:appSys">metric projection</a> is also a <a href="ch-optApp.html#sub:appSys">hat operator</a> because it preserves the norm of the projected object (<span class="math inline">\(\|\mathbf{P}_{\mathcal{Y}}\|=1\)</span>).</p>
<p>Secondly, we want to see a minimum in the real-valued <a href="ch-representation.html#sub:conjugacy">Hilbert space</a> can be obtained by a <strong>variational inequality</strong> if the neighborhood of the minimum is convex. For a <strong>convex</strong> subset <span class="math inline">\(\mathcal{Y}\)</span> of the real-valued <a href="ch-representation.html#sub:conjugacy">Hilbert space</a> <span class="math inline">\(\mathcal{V}\)</span>, let <span class="math inline">\(f\in\mathcal{V}\)</span> and <span class="math inline">\(g\in\mathcal{Y}\)</span>, and let <span class="math inline">\(\hat{f}=\mathbf{P}_{\mathcal{Y}}(f)\in\mathcal{Y}\)</span> be the <a href="ch-representation.html#sub:conjugacy">projection operator</a>, then the following two definitions are equivalent:</p>
<ol style="list-style-type: decimal">
<li><p><a href="ch-optApp.html#sub:appSys">metric projection operator</a>: <span class="math inline">\(\hat{f}=\mathbf{P}_{\mathcal{Y}}(f)=\arg\min_{g\in\mathcal{Y}}\|f-g\|\)</span>.</p></li>
<li><p><strong>variational inequality</strong>: <span class="math inline">\(\langle f-\hat{f},\, \hat{f}-g\rangle\geq0\)</span> or say <span class="math inline">\(\langle f-\hat{f},\, \hat{f}\rangle\geq \langle f-\hat{f},\, g\rangle\)</span></p></li>
</ol>
<div class="solution">
<p class="solution-begin">
Proof <span id="sol-start-91" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-91', 'sol-start-91')"></span>
</p>
<div id="sol-body-91" class="solution-body" style="display: none;">
<p><span class="newthought">Equivalence of 1. and 2. </span></p>
<p>From 2. to 1.</p>
<p>The inequality <span class="math inline">\(\langle g- \hat{f},\, f-\hat{f}\rangle\leq0\)</span> holds for <span class="math inline">\(g\in\mathcal{Y}\)</span>, then
<span class="math display">\[\begin{align*}
\|f-\hat{f}\|^{2}&amp;=\langle f-\hat{f},\: f-\hat{f}\rangle\\
&amp;=\langle f-g,\:f-\hat{f} \rangle+\langle g-\hat{f},\: f-\hat{f}\rangle\\
&amp;\leq\langle f-g,\: f-\hat{f} \rangle\leq\|f-g\|\|f-\hat{f}\|.
\end{align*}
\]</span>
Hence <span class="math inline">\(\|f-\hat{f}\|\leq\|f-g\|\)</span>, so <span class="math inline">\(\hat{f}=\mathbf{P}_{\mathcal{Y}}(f)=\min_{g\in\mathcal{Y}}\|f-g\|\)</span>.</p>
<p>From 1. to 2.</p>
<p>Suppose the inequality fails, namely <span class="math inline">\(\langle g- \hat{f},\, f-\hat{f}\rangle &gt; 0\)</span> for some <span class="math inline">\(g\)</span>. Let <span class="math inline">\(g_{\alpha}=\alpha g+(1-\alpha)\hat{f}\)</span>. If <span class="math inline">\(0&lt;\alpha&lt;1\)</span>, then the <strong>convexity</strong> tells that <span class="math inline">\(g_{\alpha}\in\mathcal{Y}\)</span>
and
<span class="math display">\[\begin{align*}
\|f-g_{\alpha}\|^{2} &amp;=\langle f-g_{\alpha},\: f-g_{\alpha}\rangle\\
&amp;=\langle f-\alpha g-(1-\alpha)\hat{f},\: f-\alpha g-(1-\alpha)\hat{f}\rangle\\
&amp;=\|f-\hat{f}\|^{2} - 2\alpha\langle g-\hat{f},\: f-\hat{f}\rangle+\alpha^{2}\|g-\hat{f}\|^{2}
\end{align*}\]</span>
Note that <span class="math inline">\(\langle g- \hat{f},\, f-\hat{f}\rangle &gt; 0\)</span> for some <span class="math inline">\(g\)</span>. So the term <span class="math display">\[-2\alpha\langle g-\hat{f},\: f-\hat{f}\rangle+\alpha^{2}\|g-\hat{f}\|^{2}\]</span> can be negative if <span class="math inline">\(\alpha\)</span> is sufficiently small, e.g. <span class="math display">\[0&lt;\lambda&lt;\frac{2\langle g-\hat{f},\: f-\hat{f}\rangle}{\|g-\hat{f}\|^{2}}.\]</span> In this case, we have <span class="math inline">\(\|f-\hat{f}\|&gt;\|f-g_{\alpha}\|\)</span> hence <span class="math inline">\(\hat{f}\)</span> cannot be <span class="math inline">\(\min_{g\in\mathcal{Y}}\|f-g\|\)</span>, namely <span class="math inline">\(\hat{f}\neq\mathbf{P}_{\mathcal{Y}}(f)\)</span>.</p>
<p><span class="newthought">Derivation of the variational inequality </span></p>
<p>Consider <span class="math inline">\(\|f-g\|^2\)</span> that has a quadratic form. Let <span class="math inline">\(f^{*}\)</span> be the minimum.
The (functional) gradient evaluated at <span class="math inline">\(f^{*}\)</span> is <span class="math inline">\(2(f^{*}-g)\)</span>. the <strong>variational inequality</strong> says
<span class="math display">\[\left\langle f^{*}-g ,\:f - f^{*} \right\rangle = \left\langle f - f^{*} ,\: f^{*} - g \right\rangle  \geq 0 \\
\mbox{or } \left\langle g - f^{*} ,\:f - f^{*} \right\rangle \leq 0\]</span></p>
<p>The inequality also tells that the minimum is unique. Suppose there are two minima <span class="math inline">\(\mathbf{f}_1\)</span> and <span class="math inline">\(\mathbf{f}_2\)</span>.
The inequality implies
<span class="math inline">\(\left\langle g-f_1^{*} ,\:f^{*}_2 - f_1^{*} \right\rangle\)</span> and
<span class="math inline">\(\left\langle g-f_2^{*} ,\:f^{*}_1 - f_2^{*} \right\rangle\)</span>.
Adding up two inequalities, we have
<span class="math display">\[\left\langle f^{*}_1-f_2^{*} ,\:f^{*}_1 - f_2^{*} \right\rangle = \|f^{*}_1-f^{*}_2\|\leq 0\]</span>
which only holds at <span class="math inline">\(f^{*}_1=f^{*}_2\)</span>.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The above statement deduces that the <a href="ch-optApp.html#sub:appSys">metric projection operator</a> is <a href="sub-continuity.html#sub:Cauchy">Lipschitz continuous</a> with the <a href="sub-continuity.html#sub:Cauchy">Lipschitz constant</a> of one, called <em>non-expansive</em>:<label for="tufte-sn-388" class="margin-toggle sidenote-number">388</label><input type="checkbox" id="tufte-sn-388" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">388</span> Also, the <a href="ch-optApp.html#sub:appSys">metric projection operator</a> is <a href="sub-continuity.html#sub:completeness">monotone</a>, in the sense that
<span class="math display">\[\langle f_1-f_2, \mathbf{P}_{\mathcal{Y}}(f_1)- \mathbf{P}_{\mathcal{Y}}(f_2) \rangle\geq 0\]</span>
for all <span class="math inline">\(f_1,f_2\in\mathcal{V}\)</span>. The monotonicity means if <span class="math inline">\(f_1(\mathbf{x})\geq f_2(\mathbf{x})\)</span>, the inequality holds under the projection, namely
<span class="math inline">\(\mathbf{P}_{\mathcal{Y}}(f_1)(\mathbf{x}) \geq \mathbf{P}_{\mathcal{Y}}(f_2)(\mathbf{x})\)</span>.</span>
<span class="math display">\[\| \mathbf{P}_{\mathcal{Y}}(f_1)- \mathbf{P}_{\mathcal{Y}}(f_2) \|\leq \|f_1 -f_2\|\]</span>
for all <span class="math inline">\(f_1,f_2\in\mathcal{V}\)</span>.
This result serves as the foundation in many practical approximation exercises. As in practice, instead of approximating the “ideal” element <span class="math inline">\(f\)</span>, one often approximates the element <span class="math inline">\(f+\delta f\)</span>, where <span class="math inline">\(\delta f\)</span> is some “variation of <span class="math inline">\(f\)</span>.” The <strong>non-expansivity</strong> says that
<span class="math display">\[\| \mathbf{P}_{\mathcal{Y}}(f + \delta f)- \mathbf{P}_{\mathcal{Y}}(f) \|\leq \|\delta f\|\]</span> so that the error incurred in the approximation/projection is no larger than the error in the original variation. This is a desirable property for recursively approximating the object. Because in each step of the iteration, the projection will not blow up the whole scheme.</p>
<div class="solution">
<p class="solution-begin">
Monotonicity and non-expansivity <span id="sol-start-92" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-92', 'sol-start-92')"></span>
</p>
<div id="sol-body-92" class="solution-body" style="display: none;">
<p>The <strong>variational inequality</strong> tells that
<span class="math display">\[\langle f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1}),\mathbf{P}_{\mathcal{Y}}(f_{1})-g\rangle\geq0\;\mbox{for any }g\in\mathcal{Y}.\]</span>
By choosing <span class="math inline">\(g=\mathbf{P}_{\mathcal{Y}}(f_{2})\)</span>, we have <span class="math display">\[\langle f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1}),\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\rangle\geq0.\]</span>
By the same argument, we have
<span class="math display">\[\langle\mathbf{P}_{\mathcal{Y}}(f_{1})-f_{2},\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\rangle\geq0.\]</span></p>
<p>Now we consider
<span class="math display">\[\begin{align*}
\langle f_{1}-f_{2},\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\rangle  &amp;=\langle f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1}),\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\rangle\\
&amp;   +\langle\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2}),\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\rangle\\
&amp;   +\langle\mathbf{P}_{\mathcal{Y}}(f_{1})-f_{2},\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\rangle.
\end{align*}
\]</span>
We know that the first and the third terms on the right are non-negative. The second term is <span class="math display">\[\|\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\|^{2}\]</span>
that is always non-negative. Thus the result of monotonicity follows.</p>
<p>Using the monotonicity result, we have
<span class="math display">\[
\begin{align*}
\|f_{1}-f_{2}\|^{2} &amp;=  \|f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1})+\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})+\mathbf{P}_{\mathcal{Y}}(f_{2})-f_{2}\|^{2}\\
&amp;=  \|\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\|^{2}+\left\Vert (f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1}))-(f_{2}-\mathbf{P}_{\mathcal{Y}}(f_{2}))\right\Vert ^{2}\\
&amp;   +2\left\langle \mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2}),\: f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1})-\left(f_{2}-\mathbf{P}_{\mathcal{Y}}(f_{2})\right)\right\rangle \\
&amp;=  \|\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\|^{2}+\left\Vert (f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1}))-(f_{2}-\mathbf{P}_{\mathcal{Y}}(f_{2}))\right\Vert ^{2}\\
&amp;   +2\left\langle \mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2}),\: f_{1}-f_{2}\right\rangle -2\|\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\|^{2}\\
&amp;\geq   \|\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\|^{2}+\left\Vert (f_{1}-\mathbf{P}_{\mathcal{Y}}(f_{1}))-(f_{2}-\mathbf{P}_{\mathcal{Y}}(f_{2}))\right\Vert ^{2}.
\end{align*}
\]</span>
where the inequality comes from
<span class="math display">\[\left\langle \mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2}),\: f_{1}-f_{2}\right\rangle \ge\|\mathbf{P}_{\mathcal{Y}}(f_{1})-\mathbf{P}_{\mathcal{Y}}(f_{2})\|^{2}.\]</span>
So the result follows.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>In particular, if the projection is orthogonal, namely <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}\)</span> is <a href="ch-representation.html#sub:conjugacy">self-adjoint</a>:
<span class="math display">\[\langle f_1, \mathbf{P}_{\mathcal{Y}}f_2 \rangle = \langle \mathbf{P}_{\mathcal{Y}} f_1, f_2 \rangle\]</span>
then the <a href="ch-optApp.html#sub:appSys">metric projection operator</a> <span class="math inline">\(\hat{f}=\mathbf{P}_{\mathcal{Y}} f\)</span> has the following properties<label for="tufte-sn-389" class="margin-toggle sidenote-number">389</label><input type="checkbox" id="tufte-sn-389" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">389</span> The projection property <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}\mathbf{P}_{\mathcal{Y}}=\mathbf{P}_{\mathcal{Y}}\)</span> tells that <span class="math inline">\(\|\mathbf{P}_{\mathcal{Y}}\|=1\)</span>. By using this result, we have
<span class="math display">\[
\begin{align*}
\langle  \mathbf{P}_{\mathcal{Y}}f, f \rangle &amp;= \langle \mathbf{P}_{\mathcal{Y}} \mathbf{P}_{\mathcal{Y}} f, f \rangle\\
&amp;= \langle \mathbf{P}_{\mathcal{Y}}  f, \mathbf{P}_{\mathcal{Y}} f \rangle \\
&amp;=\|\mathbf{P}_{\mathcal{Y}}f\|^2 =\|f\|^2.
\end{align*}\]</span></span>
<span class="math display">\[\mbox{1. } \langle  \hat{f}, f \rangle = \|\hat{f}\|^2=\|f\|^2,\,\, \mbox{2. }\langle f-\hat{f},\, \hat{f}\rangle = 0\]</span>
for any <span class="math inline">\(f\in\mathcal{V}\)</span>. The first says the norm of the hat operator is exactly the same as that of the original object. The second says that the error of the projection <span class="math inline">\(f-\hat{f}\)</span> and the projection <span class="math inline">\(\hat{f}\)</span> should be orthogonal to each other.<label for="tufte-sn-390" class="margin-toggle sidenote-number">390</label><input type="checkbox" id="tufte-sn-390" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">390</span> The way of having an orthogonal projection for a <strong>convex set</strong> <span class="math inline">\(\mathcal{Y}\)</span> in the Hilbert space is about having a conical shape of such <strong>convex set</strong> <span class="math inline">\(\mathcal{Y}\)</span>.</span></p>
<div class="solution">
<p class="solution-begin">
Definition and remark about the cone <span id="sol-start-93" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-93', 'sol-start-93')"></span>
</p>
<div id="sol-body-93" class="solution-body" style="display: none;">
<p>Notice that the derivative is a <a href="ch-MatComp.html#sub:vecSpaces">functional</a>, and the <a href="ch-vecMat.html#sub:linearity">gradient</a> is from the <a href="ch-optApp.html#sub:appSys">dual norm space</a>.
Consider a function <span class="math inline">\(f:\mathcal{Y}\rightarrow \mathbb{R}\)</span>. The <a href="ch-vecMat.html#sub:vec">inner product</a> of the <strong>variational inequality</strong>, i.e. <span class="math inline">\(\left\langle \nabla f(\mathbf{y}^{*}),\:\mathbf{y} - \mathbf{y}^{*} \right\rangle \geq 0\)</span>, consists of a <em>dual pair</em> such that <span class="math display">\[\langle\cdot,\cdot\rangle:\mathcal{Y}^{*}\times \mathcal{Y} \rightarrow \mathbb{R}.\]</span>
The inequality of the <strong>dual pair</strong> closely relate to the geometric interpretation about the <strong>cone</strong> in the <a href="ch-representation.html#sub:conjugacy">Hilbert space</a>.<label for="tufte-sn-391" class="margin-toggle sidenote-number">391</label><input type="checkbox" id="tufte-sn-391" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">391</span> 
In <a href="ch-optApp.html#sub:appSys">Banach space</a>, we can use a nested sequence of <a href="sub-continuity.html#sub:continuousFunc">balls</a> to define <strong>cone</strong>. Consider the following sequence
<span class="math display">\[\mathcal{B}_{r_1}(f_1)\subseteq \mathcal{B}_{r_2}(f_2)\cdots \]</span>where the radius <span class="math inline">\(r_n\)</span> goes to infinity. The union of these <a href="sub-continuity.html#sub:continuousFunc">balls</a> <span class="math inline">\(\cup_{i=1}^{\infty}\mathcal{B}_{r_{i}}\)</span> is called a <em>cone</em>. See figure <a href="ch-optApp.html#fig:Cone">15.1</a>.
It is known that if the <a href="ch-optApp.html#sub:appSys">Banach space</a> <span class="math inline">\(\mathcal{V}\)</span> is constructed by the union of the nested sequence of <a href="sub-continuity.html#sub:continuousFunc">balls</a>, then its <a href="ch-optApp.html#sub:appSys">dual norm space</a> <span class="math inline">\(\mathcal{V}\)</span> is always <strong>convex</strong>.
But the multiple-valued projection in the <a href="ch-optApp.html#sub:appSys">Banach space</a> loses almost all the properties we learned so far, so we’d better focus on the Hilbert space cases.</span></p>
<p>For a subset <span class="math inline">\(\mathcal{Y}\)</span> in a real-valued vector space <span class="math inline">\(\mathcal{V}\)</span> whose dual space is <span class="math inline">\(\mathcal{V}^*\)</span>, the set
<span class="math display">\[\left\{f\in \mathcal{V}^{*}:\langle f,g\rangle \geq 0\quad \forall g\in \mathcal{Y}\right\},\]</span>
is called the <em>dual cone</em> of <span class="math inline">\(\mathcal{Y}\)</span>. The <strong>dual one</strong> is always <strong>convex</strong>. Therefore, it is a <strong>convex cone</strong>.</p>
<p>For the orthogonal projection, we know that
<span class="math display">\[\langle f-\hat{f},\, \hat{f}\rangle = 0.\]</span>
With the <strong>variational inequality</strong>
<span class="math display">\[\langle f-\hat{f},\, \hat{f}-g\rangle\geq0,\]</span>
we know that if <span class="math inline">\(\hat{f}\)</span> is from an orthogonal projection, then <span class="math display">\[\langle f-\hat{f},\: g\rangle\leq0\quad\mbox{for all }g\in\mathcal{Y}\]</span>
forms a <strong>dual cone</strong>. In other words, the variational inequality specifies a <strong>convex cone</strong> structure on <span class="math inline">\(\mathcal{V}^{*}\)</span> that is similar to a <a href="ch-MatComp.html#sub:vecSpaces">subspace</a> of <span class="math inline">\(\mathcal{V}^{*}\)</span>.</p>
<table>
<colgroup>
<col width="55%">
<col width="44%">
</colgroup>
<thead><tr class="header">
<th align="left"><a href="ch-MatComp.html#sub:vecSpaces">Subspace</a></th>
<th align="left"><em>Convex cone</em></th>
</tr></thead>
<tbody><tr class="odd">
<td align="left">A subset <span class="math inline">\(\mathcal{Y}\)</span> of <span class="math inline">\(\mathcal{V}\)</span> is a sub-space if <span class="math inline">\(\alpha f_1 + \beta f_2 \in\mathcal{Y}\)</span> whenever <span class="math inline">\(f_1,f_2\in\mathcal{Y}\)</span> and <span class="math inline">\(\alpha,\beta\in\mathbb{R}\)</span>
</td>
<td align="left">A subset <span class="math inline">\(\mathcal{Y}\)</span> of <span class="math inline">\(\mathcal{V}\)</span> is a <strong>convex cone</strong> if <span class="math inline">\(\alpha f_1 + \beta f_2 \in\mathcal{Y}\)</span> whenever <span class="math inline">\(f_1,f_2\in\mathcal{Y}\)</span> and <span class="math inline">\(\alpha,\beta \geq 0\)</span>
</td>
</tr></tbody>
</table>
<p>You can see that every <a href="ch-MatComp.html#sub:vecSpaces">subspace</a> is a <strong>convex cone</strong>, but not conversely.</p>
<p>Therefore, constructing an orthogonal projection in the real-valued Hilbert space is about projecting onto a set whose dual is a <strong>dual cone</strong> (or a <a href="ch-MatComp.html#sub:vecSpaces">subspace</a>). Perhaps the simplest way of having an orthogonal projection is to project the object onto a <strong>convex cone</strong> or a <a href="ch-MatComp.html#sub:vecSpaces">subspace</a> (so that <span class="math inline">\(\mathcal{Y}\)</span> is either a <strong>convex cone</strong> or a <a href="ch-MatComp.html#sub:vecSpaces">subspace</a> of <span class="math inline">\(\mathcal{V}\)</span>) because, in this case, the dual of <span class="math inline">\(\mathcal{Y}\)</span> is always a <strong>convex cone</strong> (the dual in a Hilbert space is itself).</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
</div>
<div id="sub:Proj1" class="section level2">
<h2>
<span class="header-section-number">15.3</span> Miscellaneous Examples: Part 1</h2>
<p><span class="newthought">Multiple linear regression and hyperplane </span></p>
<p>Consider the <span class="math inline">\(n\)</span>-length data vectors from an <a href="ch-eigen.html#sub:matNorms">AR(2)</a> model
<span class="math display">\[\mathbf{x}_T = c_1\mathbf{x}_{T-1} + c_2\mathbf{x}_{T-2} + \mathbf{e}\]</span>
where <span class="math inline">\(\mathbf{e}\in\mathbb{R}^{n}\)</span> is a vector of errors.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>); time =<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">50</span></a>
<a class="sourceLine" id="cb107-2" data-line-number="2">xT.model =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(time)); xT.model[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>) <span class="co"># At t=1,2, give the initials random values </span></a>
<a class="sourceLine" id="cb107-3" data-line-number="3"></a>
<a class="sourceLine" id="cb107-4" data-line-number="4"><span class="co"># An "explosive" AR(2)</span></a>
<a class="sourceLine" id="cb107-5" data-line-number="5"><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(time)<span class="op">-</span><span class="dv">2</span>)){ </a>
<a class="sourceLine" id="cb107-6" data-line-number="6">  e =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb107-7" data-line-number="7">  <span class="co"># A single law of motion / dynamical law</span></a>
<a class="sourceLine" id="cb107-8" data-line-number="8">  xT.model[t<span class="op">+</span><span class="dv">2</span>] =<span class="st"> </span>xT.model[t<span class="op">+</span><span class="dv">1</span>] <span class="op">-</span><span class="st"> </span><span class="fl">1.2</span><span class="op">*</span><span class="st"> </span>xT.model[t] <span class="op">+</span><span class="st"> </span>e </a>
<a class="sourceLine" id="cb107-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb107-10" data-line-number="10">xT =<span class="st"> </span>xT.model[<span class="dv">3</span><span class="op">:</span><span class="kw">length</span>(time)];  <span class="co"># x_T</span></a>
<a class="sourceLine" id="cb107-11" data-line-number="11">xT.lag =<span class="st"> </span>xT.model[<span class="dv">2</span><span class="op">:</span>(<span class="kw">length</span>(time)<span class="op">-</span><span class="dv">1</span>)]; <span class="co"># x_{T-1} </span></a>
<a class="sourceLine" id="cb107-12" data-line-number="12">xT.lag2 =<span class="st"> </span>xT.model[<span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(time)<span class="op">-</span><span class="dv">2</span>)] <span class="co"># x_{T-2}</span></a></code></pre></div>
<p>The <a href="ch-eigen.html#sub:matNorms">AR(2)</a> model tells us that <span class="math inline">\(\mathbf{x}_T\)</span> is “generated” by two “older” vectors <span class="math inline">\(\mathbf{x}_{T-1}\)</span> and <span class="math inline">\(\mathbf{x}_{T-2}\)</span>. Therefore, it is natural to think that <span class="math inline">\(\mathbf{x}_T\)</span> must be in a kind of subspace of the space “generated” by <span class="math inline">\(\mathbf{x}_{T-1}\)</span> and <span class="math inline">\(\mathbf{x}_{T-2}\)</span>. Also, you should not be surprised if I project the <span class="math inline">\(\mathbf{x}_T\)</span> onto such a space.</p>
<p>By considering <span class="math inline">\([\mathbf{x}_{T-1},\mathbf{x}_{T-2}]^{\top}\)</span> as an <span class="math inline">\(n \times 2\)</span> matrix <span class="math inline">\(\mathbf{X}\)</span>, we can form the <a href="ch-representation.html#sub:conjugacy">projection matrix</a> <span class="math display">\[\mathbf{P}_{\mathbf{X}}=\mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}.\]</span> The projection property <span class="math inline">\(\mathbf{P}_{\mathbf{X}}\mathbf{P}_{\mathbf{X}}=\mathbf{P}_{\mathbf{X}}\)</span> can be easily verified.
The projection of <span class="math inline">\(\mathbf{x}_T\)</span> gives<label for="tufte-sn-392" class="margin-toggle sidenote-number">392</label><input type="checkbox" id="tufte-sn-392" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">392</span> Note that <span class="math display">\[\begin{align*} &amp; \min_{\mathbf{c}\in\mathbb{R}^2}  \|\mathbf{x}_T -\mathbf{X}\mathbf{c}^{\top}\|^2 \\ &amp;=\|(\mathbf{I}-\mathbf{P}_{\mathbf{X}})\mathbf{x}_{T}\|^2.\end{align*}\]</span> The <a href="ch-representation.html#sub:conjugacy">projection matrix</a> comes from <a href="sub-calculus.html#sub:opt">Fermat’s theorem</a> for the derivative: <span class="math display">\[\frac{\partial \|\mathbf{x}_T -\mathbf{X}\mathbf{c}^{\top}\|^2}{\partial \mathbf{c}}= 0\]</span> whose solution is
<span class="math inline">\(\mathbf{X}^{\top}\mathbf{X}\hat{\mathbf{c}}^{\top}-\mathbf{X}^{\top}\mathbf{x}_{T}=0\)</span>. We will receive more details about the meaning (and the specific derivation) of this solution. For the moment, we only need to know that <span class="math display">\[\mathbf{X}\hat{\mathbf{c}}^{\top}=\mathbf{X}(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{x}_{T}\]</span> minimizes the norm, namely forming the <a href="ch-optApp.html#sub:appSys">metric projection</a>.</span>
<span class="math display">\[\mathbf{P}_{\mathbf{X}}\mathbf{x}_{T} = \hat{\mathbf{x}}_T = \mathbf{X}\hat{\mathbf{c}}^{\top} = \hat{c}_1\mathbf{x}_{T-1} + \hat{c}_2\mathbf{x}_{T-2}\]</span>
where these equalities are simply another way of presenting the <a href="ch-representation.html#sub:conjugacy">Riesz representation</a> for the projection matrix (operator).<label for="tufte-sn-393" class="margin-toggle sidenote-number">393</label><input type="checkbox" id="tufte-sn-393" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">393</span> The <a href="ch-optApp.html#sub:appSys">hat operator</a> <span class="math display">\[\hat{\mathbf{c}}^{\top}=(\mathbf{X}^{\top}\mathbf{X})^{-1}\mathbf{X}^{\top}\mathbf{x}_{T}\]</span> is analogous to the previous <a href="ch-vecMat.html#sub:linearity">least square estimator</a> in the simple <a href="ch-vecMat.html#sub:linearity">linear regression</a>. Indeed, this <a href="ch-eigen.html#sub:matNorms">AR(2)</a> is a <em>multiple linear regression</em> model where the <em>regressors</em>, the variables to be regressed on, have a number more than one. The <strong>regressors</strong> in this <a href="ch-eigen.html#sub:matNorms">AR(2)</a> model are <span class="math inline">\(\mathbf{x}_{T-1}\)</span> and <span class="math inline">\(\mathbf{x}_{T-2}\)</span>.</span></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" data-line-number="1">X =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(xT.lag,xT.lag2),<span class="dt">ncol=</span><span class="dv">2</span>);</a>
<a class="sourceLine" id="cb108-2" data-line-number="2"><span class="co"># An estimate of c(1, -1.2)</span></a>
<a class="sourceLine" id="cb108-3" data-line-number="3">chat =<span class="st"> </span><span class="kw">solve</span>(<span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>xT; chat</a></code></pre></div>
<pre><code>##            [,1]
## [1,]  0.9973927
## [2,] -1.1978226</code></pre>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:projR2"></span>
<img src="fig/Part4/projR2.png" alt="Project the 3-dimensional data points onto a 2-dimensional hyperplane" width="100%"><!--
<p class="caption marginnote">-->Figure 15.3: Project the 3-dimensional data points onto a 2-dimensional hyperplane<!--</p>-->
<!--</div>--></span>
</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" data-line-number="1"><span class="co"># plot</span></a>
<a class="sourceLine" id="cb110-2" data-line-number="2"><span class="kw">library</span>(scatterplot3d)</a>
<a class="sourceLine" id="cb110-3" data-line-number="3">p =<span class="st"> </span><span class="kw">scatterplot3d</span>(xT, xT.lag,xT.lag2, <span class="dt">type=</span><span class="st">"h"</span>, <span class="dt">angle=</span><span class="dv">45</span>, <span class="dt">color=</span><span class="st">"blue"</span>, <span class="dt">highlight.3d=</span><span class="ot">TRUE</span>, <span class="dt">pch =</span> <span class="dv">16</span>)</a>
<a class="sourceLine" id="cb110-4" data-line-number="4">p<span class="op">$</span><span class="kw">plane3d</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="kw">t</span>(chat)), <span class="dt">draw_polygon =</span> <span class="ot">TRUE</span>) <span class="co"># The approximating plane for the points in R^3 </span></a></code></pre></div>
<p>Although <span class="math inline">\(\mathbf{x}_{T}\)</span>, <span class="math inline">\(\mathbf{x}_{T-1}\)</span>, and <span class="math inline">\(\mathbf{x}_{T-2}\)</span> are three <span class="math inline">\(n\)</span>-length vectors, the entires of these vectors are merely “randomized” observations generated by a single deterministic <a href="ch-DE.html#ch:DE">dynamical law</a> <span class="math display">\[x_{t} = C_1 x_{t-1} + C_{2}x_{t-2}\]</span> that gives the deterministic dynamical relation amongst three successive periods <span class="math inline">\(t\)</span>, <span class="math inline">\(t-1\)</span>, and <span class="math inline">\(t-2\)</span> for the process <span class="math inline">\(\{x_t\}\)</span>. The error of each period contaminates the law. Therefore one only observes the real values of the system given by the data vectors rather than dynamical law.<label for="tufte-sn-394" class="margin-toggle sidenote-number">394</label><input type="checkbox" id="tufte-sn-394" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">394</span> Recall that a vector of data may come from a single function. Similarly, one can view each of the three vectors of this process as a “point” in some <a href="ch-representation.html#sub:conjugacy">Hilbert space</a>. We will come back to it in ch[?].</span></p>
<p>Figure <a href="ch-optApp.html#fig:projR2">15.3</a> shows the projection of <span class="math inline">\(\mathbf{x}_{T}\)</span> locates closely to the plane <span class="math inline">\(x_t = \hat{c}_1x_{t-1} + \hat{c}_2 x_{t-2}\)</span> given by the <a href="ch-DE.html#ch:DE">dynamical law</a>. Although the law consists of three variables, <span class="math inline">\(x_t\)</span> is <a href="ch-MatComp.html#sub:vecSpaces">linearly dependent</a> on <span class="math inline">\(x_{t-1}\)</span> and <span class="math inline">\(x_{t-2}\)</span>. Thus, two variables are sufficient to represent the plane. Basically, the <strong>multiple linear regression</strong> conducts a projection onto the space one dimensional lower than the original space.<label for="tufte-sn-395" class="margin-toggle sidenote-number">395</label><input type="checkbox" id="tufte-sn-395" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">395</span> Usually, people write a multiple linear regression as <span class="math display">\[Y = \sum_{i=1}^{k} \beta_i X_i +\varepsilon.\]</span> The variable <span class="math inline">\(Y\)</span> together with <span class="math inline">\(k-1\)</span> <strong>regressors</strong> <span class="math inline">\(\{X_i\}_{i=1}^{k}\)</span> forms a <span class="math inline">\(k\)</span>-dimensional regression problem. We can understand that such a linear regression is to reduce some situation from <span class="math inline">\(k\)</span>-dimension to <span class="math inline">\((k-1)\)</span>-dimension by explaining one selected variable <span class="math inline">\(Y\)</span> in terms of a <a href="ch-vecMat.html#sub:vec">linear combination</a> of <span class="math inline">\((k-1)\)</span> <strong>regressors</strong>.</span></p>
<p>Geometrically speaking, a set that is one dimensional lower than the original space and formed by a continuous linear <a href="ch-MatComp.html#sub:vecSpaces">function(al)</a> is called the <strong>hyperplane</strong>. Let <span class="math inline">\(\mathcal{V}\)</span> be a vector space. Given a linear function(al) <span class="math inline">\(g\in \mathcal{V}\)</span> and a scalar <span class="math inline">\(a\)</span> from the <a href="ch-MatComp.html#sub:vecSpaces">scalar field</a> <span class="math inline">\(\mathbb{F}\)</span>, the set
<span class="math display">\[\mathcal{S}=\{g\in\mathcal{V}:\langle f, \,g\rangle=a, a\in \mathbb{F} \}\]</span> is a <em>hyperplane</em> in <span class="math inline">\(\mathcal{V}\)</span> determined by <span class="math inline">\(f\)</span> and <span class="math inline">\(a\)</span>. In the previous example, the <strong>hyperplane</strong> is <span class="math display">\[\mathcal{S}=\left\{\left[\begin{array}{c}
x_{t}\\
x_{t-1}\\
x_{t-2}
\end{array}\right]\in\mathbb{R}^{3}:\, \left\langle \left[\begin{array}{c}
-1\\
\hat{c}_{1}\\
\hat{c}_{2}
\end{array}\right]\,,\,\left[\begin{array}{c}
x_{t}\\
x_{t-1}\\
x_{t-2}
\end{array}\right]\right\rangle =0 \right\},\]</span>
a <span class="math inline">\(2\)</span>-dimensional plane in <span class="math inline">\(\mathbb{R}^{3}\)</span> determined by the <span class="math inline">\([-1, \hat{c}_{1},\hat{c}_{2}]^{\top}\)</span> and <span class="math inline">\(0\)</span>.</p>
<p><span class="newthought">Separation and non-arbitrage </span></p>
<p>When the <a href="ch-MatComp.html#sub:vecSpaces">scalar field</a> <span class="math inline">\(\mathbb{F}\)</span> of the <strong>hyperplane</strong> is restricted to <span class="math inline">\(\mathbb{R}\)</span>, one can use inequalities to illustrate how a hyperplane separates the space into two, i.e. <span class="math inline">\(\{f\in\mathcal{V}:\langle f, \,g\rangle \leq a \}\)</span> and <span class="math inline">\(\{f\in\mathcal{V}:\langle f, \,g\rangle &gt; a \}\)</span>.<label for="tufte-sn-396" class="margin-toggle sidenote-number">396</label><input type="checkbox" id="tufte-sn-396" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">396</span> These two sets are called the <em>half-spaces</em> determined by the <strong>hyperplane</strong> <span class="math inline">\(\mathcal{S}\)</span>. If a subset belongs to one of this half-space, then this subset is on one side of the <strong>hyperplane</strong>.</span></p>
<p>The separation is about forming a dichotomy between the objects of interest and the rest. For example, assume that <span class="math inline">\(\mathcal{V}=\mathbb{R}^{n}\)</span>. Let <span class="math inline">\(\mathcal{Y}\in\mathcal{V}\)</span> be a <a href="ch-optApp.html#sub:Optimization">convex set</a>. Let <span class="math inline">\(\mathbf{z}\in\mathcal{V}\)</span> and <span class="math inline">\(\mathbf{z}\notin\mathcal{Y}\)</span>. Then exist non-zero vector <span class="math inline">\(\mathbf{p}\in\mathcal{V}\)</span> and a real number <span class="math inline">\(a\in\mathbb{R}\)</span> such that
<span class="math display">\[\mathbf{p}^{\top} \mathbf{y} \geq a&gt; \mathbf{p}^{\top}\mathbf{z},\]</span>
for any <span class="math inline">\(\mathbf{y}\in\mathcal{Y}\)</span>.</p>
<p>Here the <strong>hyperplane</strong> <span class="math inline">\(\mathcal{S}=\{\mathbf{y}\in\mathbb{R}^{n}:\langle \mathbf{p}, \,\mathbf{y} \rangle=a \}\)</span> strictly separates <span class="math inline">\(\mathbf{z}\)</span> and <span class="math inline">\(\mathcal{Y}\)</span>. This result comes from the <a href="ch-optApp.html#sub:Optimization">variational inequality</a>.<label for="tufte-sn-397" class="margin-toggle sidenote-number">397</label><input type="checkbox" id="tufte-sn-397" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">397</span> Let <span class="math inline">\(\hat{\mathbf{z}}\)</span> be the projection of <span class="math inline">\(\mathbf{z}\)</span> on the set <span class="math inline">\(\mathcal{Y}\)</span>, such that <span class="math inline">\(\mathbf{P}_{\mathcal{Y}}\mathbf{z}=\hat{\mathbf{z}}\in\mathcal{Y}\)</span>. The <a href="ch-optApp.html#sub:Optimization">variational inequality</a> becomes <span class="math display">\[(\hat{\mathbf{z}}-\mathbf{z})^\top (\mathbf{y}-\hat{\mathbf{z}})\geq0\]</span>
for all <span class="math inline">\(\mathbf{y}\in\mathcal{Y}\)</span>. Let <span class="math inline">\(\mathbf{p}=\hat{\mathbf{z}}-\mathbf{z}\)</span> and consider non-zero <span class="math inline">\(\mathbf{p}\)</span>. Let <span class="math inline">\(\mathbf{p}^{\top}\hat{\mathbf{z}}=a\)</span>. Then the inequality gives
<span class="math display">\[\mathbf{p}^{\top}(\mathbf{y}-\hat{\mathbf{z}})\geq0\Leftrightarrow \mathbf{p}^{\top} \mathbf{y} \geq a.\]</span>
On the other hand, <span class="math display">\[\begin{align*}a- \mathbf{p}^{\top}\mathbf{z} &amp;=\mathbf{p}^{\top}(\hat{\mathbf{z}}-\mathbf{z})\\
&amp;=\|\hat{\mathbf{z}}-\mathbf{z}\|^{2}&gt;0\end{align*}\]</span> implies <span class="math inline">\(a&gt;\mathbf{p}^{\top}\mathbf{z}\)</span>.
The result follows.</span></p>
<p>In economics, the vector <span class="math inline">\(\mathbf{p}\)</span> in the above inequalities is often interpreted as a price vector; and the set <span class="math inline">\(\mathcal{Y}\)</span> is treated as a feasible set for production while <span class="math inline">\(\mathbf{z}\notin\mathcal{Y}\)</span> is a non-feasible plan, i.e., the non-profitable production allocation.<label for="tufte-sn-398" class="margin-toggle sidenote-number">398</label><input type="checkbox" id="tufte-sn-398" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">398</span> In this context, the price vector <span class="math inline">\(\mathbf{p}=\hat{\mathbf{z}}-\mathbf{z}\)</span> can be understood as the gain (or the residual) in the projection of some impossibility onto some possibility (of course, the possible output <span class="math inline">\(\hat{\mathbf{z}}\)</span> should be larger than the impossible <span class="math inline">\(\mathbf{z}\)</span> to attain a positive price). Let <span class="math inline">\(a=0\)</span>, the result says
<span class="math display">\[\mathbf{p}^{\top}\hat{\mathbf{z}}=(\hat{\mathbf{z}}-\mathbf{z})^{\top}\hat{\mathbf{z}}=0,\]</span> either <span class="math inline">\(\mathbf{p}=0\)</span> or <span class="math inline">\(\hat{\mathbf{z}}=0\)</span>.</span></p>
<p>The development of these inequalities touches the core of the pricing theory in economics and finance. The basic idea is that if the price vector is “generated” by a convex set, a <strong>hyperplane</strong> consisting of this price vector and a vector of the pricing commodities should be able to separate some infeasible situations regarding those commodities from the feasible ones.</p>
<p>One typical “infeasible” or “unpleasant”" case in the financial market is the <strong>arbitrage</strong> (making something from nothing).
Let <span class="math inline">\(\mathbf{A}\in\mathbb{R}^{n\times m}\)</span>, <span class="math inline">\(\mathbf{p},\mathbf{y}\in\mathbb{R}^{n}\)</span>, <span class="math inline">\(\mathbf{x}\in\mathbb{R}^{m}\)</span>, and <span class="math inline">\(\mathbf{x} \succeq \mathbf{0}\)</span>. Here <span class="math inline">\(\mathbf{x} \succeq \mathbf{0}\)</span> means all the entries of the vector <span class="math inline">\(\mathbf{x}\)</span> are non-negative. Suppose we assume that the price vector has a <a href="#">representation</a> <span class="math inline">\(\mathbf{p}=\mathbf{A}\mathbf{x}\)</span> with the positive value “basis” vector <span class="math inline">\(\mathbf{x}\)</span> over <span class="math inline">\(m\)</span> states. In that case, the matrix <span class="math inline">\(\mathbf{A}\in\mathbb{R}^{n\times m}\)</span> can be defined as the pricing plan for <span class="math inline">\(n\)</span> commodities under <span class="math inline">\(m\)</span> states, or in the financial market, it can be defined as the units of <span class="math inline">\(n\)</span> securities under <span class="math inline">\(m\)</span> states.<label for="tufte-sn-399" class="margin-toggle sidenote-number">399</label><input type="checkbox" id="tufte-sn-399" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">399</span> The matrix <span class="math inline">\(\mathbf{A}\)</span> is also known as the pricing kernel.</span></p>
<p>Let <span class="math inline">\(\mathbf{y} \in \mathbb{R}^{n}\)</span> be a production plan or a portfolio of <span class="math inline">\(n\)</span> commodities (or securities). Having an <em>arbitrage</em> means have the following two cases simultaneously:
<span class="math display">\[\begin{align*}
\mbox{Case I, negative profit (or negative market value): }&amp; \quad \mathbf{p}^{\top}\mathbf{y}&lt;0,\\
\mbox{Case II, profitable production plan (or positive payoff): }&amp;\quad \mathbf{A}^{\top}\mathbf{y}\succeq 0.
\end{align*}\]</span></p>
<p>One fundamental theory about the financial market is that there is no <strong>arbitrage</strong> when the market is efficient.
In our quantitative context, this statement means if the price vector <span class="math inline">\(\mathbf{p}\)</span> can be efficiently linearly represented by some positive vector <span class="math inline">\(\mathbf{x}\)</span> under the linear transformation <span class="math inline">\(\mathbf{A}\)</span>, then there can only be a dichotomy between case I and case II.</p>
<p>This dichotomy actually comes from the following <strong>Farkas’ lemma</strong> (another dichotomy).</p>
<ul>
<li>
<em>Farkas’ lemma</em> : The system I and the system II
<span class="math display">\[\begin{align*}
\mbox{system I: }&amp; \quad \left\{\mathbf{x} : \mathbf{A}\mathbf{x}=\mathbf{p},\,  \mathbf{x}\succeq \mathbf{0}\right\}\\
\mbox{system II: }&amp;\quad \left\{\mathbf{y} : \mathbf{A}^{\top}\mathbf{y} \succeq \mathbf{0}, \, \mathbf{p}^{\top}\mathbf{y}&lt;0\right\}
\end{align*}
\]</span> cannot be solved simultaneously.<label for="tufte-sn-400" class="margin-toggle sidenote-number">400</label><input type="checkbox" id="tufte-sn-400" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">400</span> That is, if system I has a solution for <span class="math inline">\(\mathbf{x}\)</span>, then system II will have no solution for <span class="math inline">\(\mathbf{y}\)</span>, vice versa.</span>
</li>
</ul>
<p>As you can see, <strong>Farkas’ lemma</strong> says if system I is true, then the condition <span class="math inline">\(\mathbf{p}^{\top}\mathbf{y}&lt;0\)</span> and <span class="math inline">\(\mathbf{A}^{\top}\mathbf{y}\succeq\mathbf{0}\)</span> cannot both be true at the same.<label for="tufte-sn-401" class="margin-toggle sidenote-number">401</label><input type="checkbox" id="tufte-sn-401" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">401</span> One can rule out the <strong>arbitrage</strong> opportunity if system I is true. While if system II is true, it violates the <strong>arbitrage</strong> definition. Based on these deductions, one can claim that the price given by <span class="math inline">\(\mathbf{p}=\mathbf{A}\mathbf{x}\)</span> is a <strong>non-arbitrage price</strong> (also known as the <em>fundamental theorem in asset pricing</em>). There are many variations of this non-arbitrage claim, but they basically follow the same primitive logic as above.</span></p>
<p>The result behind the <strong>non-arbitrage pricing</strong> and <strong>Farkas’ lemma</strong> is a <strong>hyperplane</strong> <span class="math inline">\(\mathcal{S}=\{\mathbf{y}\in\mathbb{R}^{n}:\langle \mathbf{p}, \,\mathbf{y} \rangle=0\}\)</span> separating system I and system II.
Because system I is, in fact, equivalent to
<span class="math display">\[\mbox{system I': } \quad \left\{\mathbf{y}:\,\mathbf{A}^{\top}\mathbf{y} \succeq \mathbf{0}, \, \mathbf{p}^{\top}\mathbf{y}\geq 0\right\}.\]</span></p>
<div class="solution">
<p class="solution-begin">
Equivalence of system I and system I’ <span id="sol-start-94" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-94', 'sol-start-94')"></span>
</p>
<div id="sol-body-94" class="solution-body" style="display: none;">
<p>Let <span class="math inline">\(\mathcal{Y} = \left\{\mathbf{A}\mathbf{x} : \mathbf{x}\succeq 0 \right\}\)</span>. Notice that <span class="math inline">\(\mathcal{Y}\)</span> is a <a href="ch-optApp.html#sub:Optimization">convex set</a>.<label for="tufte-sn-402" class="margin-toggle sidenote-number">402</label><input type="checkbox" id="tufte-sn-402" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">402</span> In fact, the set <span class="math inline">\(\mathcal{Y}\)</span> is a <a href="ch-optApp.html#sub:Optimization">convex cone</a> as any element from <span class="math inline">\(\mathcal{Y}\)</span> is a <em>conical sum</em> <span class="math inline">\(\sum_{i=1}^{m}\mathbf{a}_i x_i\)</span>, a sum of columns vectors <span class="math inline">\(\mathbf{a}_i\)</span> of <span class="math inline">\(\mathbf{A}\)</span> with positive coefficients <span class="math inline">\(\{x_i\}_{i=1}^{m}\)</span>, which coincides with the previous definition of the <a href="ch-optApp.html#sub:Optimization">convex cone</a>.</span> The previous separation inequalities tell us that for any <span class="math inline">\(\mathbf{p}_0 \notin \mathcal{Y}\)</span>, there exist <span class="math inline">\(\mathbf{y}\in\mathbb{R}^n\)</span> and <span class="math inline">\(a\in\mathbb{R}\)</span> such that
<span class="math display">\[\mathbf{y}^{\top} \mathbf{p}_1 \geq a&gt; \mathbf{y}^{\top}\mathbf{p}_0,\mbox{ for any }\mathbf{p}_1\in\mathcal{Y} .\]</span></p>
<p>By restricting our attention to the <strong>hyperplane</strong> <span class="math inline">\(\mathcal{S}=\{\mathbf{y}\in\mathbb{R}^{n}:\langle \mathbf{p}, \,\mathbf{y} \rangle=0\}\)</span>, we have<label for="tufte-sn-403" class="margin-toggle sidenote-number">403</label><input type="checkbox" id="tufte-sn-403" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">403</span> Notice that the inner product <span class="math inline">\(\langle \mathbf{p}, \mathbf{y} \rangle = a\)</span> has the “sandwich form” expressions. <span class="math display">\[\langle \mathbf{A}\mathbf{x}, \mathbf{y} \rangle = \langle \mathbf{x}, \mathbf{A}^{\top}\mathbf{y} \rangle = a.\]</span>
We will come back to this “sandwich form” in sec[?].</span>
<span class="math display">\[\mathbf{p}_1^{\top} \mathbf{y} = \langle \mathbf{A}\mathbf{x}_1, \mathbf{y} \rangle = \langle \mathbf{x}_1, \mathbf{A}^{\top}\mathbf{y} \rangle  \geq 0 &gt; \mathbf{p}_0^{\top}\mathbf{y}=0\,\mbox{ for any }\mathbf{p}_1\in\mathcal{C} \mbox{ and }\mathbf{p}_0\notin \mathcal{C}.\]</span>
Thus, if <span class="math inline">\(\mathbf{p}\in \mathcal{C}\)</span>, then <span class="math inline">\(\mathbf{p}\)</span> must behave like <span class="math inline">\(\mathbf{p}_1\)</span>, so <span class="math inline">\(\mathbf{p}^{\top} \mathbf{y}\geq 0\)</span>, and since <span class="math inline">\(\mathbf{x}\succeq 0\)</span> we have <span class="math inline">\(\mathbf{A}^{\top}\mathbf{y}\succeq 0\)</span>. Otherwise, for <span class="math inline">\(\mathbf{p}\notin\mathcal{C}\)</span>, <span class="math inline">\(\mathbf{p}\)</span> must behave like <span class="math inline">\(\mathbf{p}_0\)</span> such that <span class="math inline">\(\mathbf{p}\neq \mathbf{A}\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{p}^{\top} \mathbf{y}&lt;0\)</span>.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
</div>
<div id="sub:Proj2" class="section level2">
<h2>
<span class="header-section-number">15.4</span> * Miscellaneous Examples: Part 2</h2>
<p><span class="newthought">‘Free’ market and mathematical programming </span></p>
<p>You probably realize that the previous pricing formula <span class="math inline">\(\mathbf{p}=\mathbf{A}\mathbf{x}\)</span> does not attribute a proper economic meaning to <span class="math inline">\(\mathbf{x}\)</span>. To avoid stirring your doubts that the formula seemingly builds the price vector on top of an “<span class="math inline">\(\mathbf{x}\)</span>”-cloud, a bunch of economists came up with a marvelous system to explain the relation between <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{p}\)</span>.<label for="tufte-sn-404" class="margin-toggle sidenote-number">404</label><input type="checkbox" id="tufte-sn-404" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">404</span> To me, it is the most, if it is not the only, elegant and beautiful narration of the economic system that I have ever heard.</span> Endowing a proper economic meaning to <span class="math inline">\(\mathbf{x}\)</span> is to model <span class="math inline">\(\mathbf{x}\)</span> as a variable in some economic activities. To achieve this goal, the economists decided to parameterize both systems by adding another vector <span class="math inline">\(\mathbf{c}\)</span>, called the cost vector.</p>
<p>Let’s recall that
<span class="math display">\[\begin{align*}
\mbox{System I :}&amp; \quad    \left\{ \mathbf{x}:\:\mathbf{A}\mathbf{x}=\mathbf{p},\,\mathbf{x}\succeq\mathbf{0}\right\},\\
\mbox{System I' :}&amp; \quad   \left\{ \mathbf{y}:\:\mathbf{A}^{\top}\mathbf{y}\succeq\mathbf{0},\,\mathbf{p}^{\top}\mathbf{y}\geq\mathbf{0}\right\} 
\end{align*}\]</span>
are two equivalent systems that both locate on one side of the <a href="#sub:proj1">half-space</a> created by <span class="math inline">\(\mathcal{S}=\{\mathbf{y}:\,\mathbf{p}^{\top}\mathbf{y}=0\}\)</span>. After adding the cost vector <span class="math inline">\(\mathbf{c}\)</span>, the systems become
<span class="math display">\[
\begin{align*}
\mbox{Cost system :} &amp;\quad \left\{ \mathbf{x}:\:\mathbf{A}\mathbf{x}=\mathbf{p},\,\mathbf{c}^{\top}\mathbf{x}\geq\mathbf{0}\right\},\\
\mbox{Profit system :} &amp; \quad  \left\{ \mathbf{y}:\:\mathbf{c}\succeq\mathbf{A}^{\top}\mathbf{y}\succeq\mathbf{0},\,\mathbf{p}^{\top}\mathbf{y}\geq\mathbf{0}\right\}
\end{align*}\]</span>
where the meaning of <span class="math inline">\(\mathbf{c}^{\top}\mathbf{x}\)</span> becomes the total expenditure of <span class="math inline">\(\mathbf{x}\)</span> units, and the meaning of <span class="math inline">\(\mathbf{A}^{\top}\mathbf{y}\preceq\mathbf{c}\)</span> is that the profitable production plan should be less expensive than the cost vector (for every entity).</p>
<p>Due to the parameterization, the cost and the profit system are not necessarily equivalent. The following inequality<label for="tufte-sn-405" class="margin-toggle sidenote-number">405</label><input type="checkbox" id="tufte-sn-405" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">405</span> 
<span class="math display">\[\begin{align*}
\left\langle \mathbf{c},\mathbf{x}\right\rangle &amp;=\left\langle \mathbf{x},\mathbf{c}\right\rangle \geq\langle\mathbf{x},\mathbf{A}^{\top}\mathbf{y}\rangle \\ &amp;=\langle\mathbf{A}\mathbf{x},\mathbf{y}\rangle=\langle\mathbf{p},\mathbf{y}\rangle\geq0.
\end{align*}\]</span></span> <span class="math display">\[\mathbf{p}^{\top}\mathbf{y}\leq\mathbf{x}^{\top}\mathbf{c}\]</span> basically says that the cost system’s expenditure <span class="math inline">\(\mathbf{x}^{\top}\mathbf{c}\)</span> is at least not less than the income <span class="math inline">\(\mathbf{p}^{\top}\mathbf{y}\)</span> created by the profit system. So the sole purpose (for the producers) of continuing to produce goods is to make the profit and the expenditure equivalent.<label for="tufte-sn-406" class="margin-toggle sidenote-number">406</label><input type="checkbox" id="tufte-sn-406" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">406</span> Such motivation becomes a baseline doctrine of those who are in favor of the competitive market.</span></p>
<p>Given the price and the cost vector, we consider inner products <span class="math display">\[\mathbf{p}^{\top}\mathbf{y}^{*}=(\mathbf{x}^{*})^{\top}\mathbf{c}\]</span> to be equal at <span class="math inline">\(\mathbf{y}^{*}\)</span> and <span class="math inline">\(\mathbf{x}^{*}\)</span>. In other words, given <span class="math inline">\(\mathbf{p}^{\top}\mathbf{y}^{*}\)</span> and <span class="math inline">\(\mathbf{c}\)</span>, the decrease of <span class="math inline">\(\mathbf{x}\)</span> will make the cost system approach to the profit system. Similarly, given <span class="math inline">\((\mathbf{x}^{*})^{\top}\mathbf{c}\)</span> and <span class="math inline">\(\mathbf{p}\)</span>, increasing the units of <span class="math inline">\(\mathbf{y}\)</span> will make the profit system approach to the cost system. To summarize, we have
<span class="math display">\[\begin{cases}
\mbox{decrease }\mathbf{x}\,: &amp; \mathbf{p}^{\top}\mathbf{y}^{*}=(\mathbf{x}-\epsilon \delta\mathbf{x})^{\top}\mathbf{c},\\
\mbox{increase }\mathbf{y}\,: &amp; \mathbf{p}^{\top}(\mathbf{y}+\epsilon\delta\mathbf{y})=(\mathbf{x}^{*})^{\top}\mathbf{c},
\end{cases}\]</span>
where <span class="math inline">\(\epsilon&gt;0\)</span> is an arbitrary small number; <span class="math inline">\(\delta\mathbf{x}=(\mathbf{x}-\mathbf{x}^{*})/\epsilon\succeq0\)</span> and <span class="math inline">\(\delta\mathbf{y}=(\mathbf{y}^{*}-\mathbf{y})/\epsilon\succeq0\)</span> are also known as the <em>feasible directions</em> of <a href="ch-optApp.html#sub:Optimization">optimizing</a> the cost system and the profit system.<label for="tufte-sn-407" class="margin-toggle sidenote-number">407</label><input type="checkbox" id="tufte-sn-407" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">407</span> The <strong>feasible direction</strong> of <span class="math inline">\(\mathbf{x}\)</span> consists of ‘small’ movements starting from <span class="math inline">\(\mathbf{x}\)</span>, and by moving along these directions, the system can have better off situations. Technically speaking, the set of all feasible directions of <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are in the <a href="ch-optApp.html#sub:Optimization">convex cones</a>, and we are interested in the descent directions of the cone of <span class="math inline">\(\mathbf{x}\)</span> and the ascent directions of the cone of <span class="math inline">\(\mathbf{y}\)</span>.</span></p>
<p>By forming the sequential movements along the <strong>feasible directions</strong> as <a href="ch-optApp.html#sub:Optimization">metric projections</a> through the minimization and maximization operators, we have<label for="tufte-sn-408" class="margin-toggle sidenote-number">408</label><input type="checkbox" id="tufte-sn-408" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">408</span> The sequences <span class="math inline">\(\{\mathbf{x}_{i}\}\)</span> and <span class="math inline">\(\{\mathbf{y}_{i}\}\)</span>
satisfying
<span class="math display">\[\begin{align*}
\lim_{i\rightarrow \infty}\mathbf{c}^{\top}\mathbf{x}_{i}\rightarrow &amp; \min_{\mathbf{x}}\mathbf{c}^{\top}\mathbf{x}^{*}\\
\lim_{i\rightarrow \infty}\mathbf{p}^{\top}\mathbf{y}_{i}\rightarrow &amp; \max_{\mathbf{y}}\mathbf{p}^{\top}\mathbf{y}^{*}
\end{align*}\]</span> are in the <strong>feasible direction</strong> of the two systems in terms of the <a href="ch-optApp.html#sub:appSys">infimum norm</a> <a href="ch-optApp.html#eq:norm-4">(15.4)</a> and the <a href="ch-optApp.html#sub:appSys">supremum norm</a> <a href="ch-optApp.html#eq:norm-2">(15.2)</a>, respectively:
<span class="math display">\[
\begin{align*}
\min_{0\leq\mathbf{T}(\mathbf{y})\leq\mathbf{c}^{\top}\mathbf{x}} &amp; \quad \mathbf{c}^{\top}\mathbf{x},\\
\max_{\mathbf{0}\preceq\mathbf{y}} &amp; \quad \mathbf{T}(\mathbf{y}),
\end{align*}\]</span>
where <span class="math inline">\(\mathbf{T}(\mathbf{y})=\langle\mathbf{p},\mathbf{y}\rangle=\langle\mathbf{A}\mathbf{x},\mathbf{y}\rangle\)</span>. The solutions of the problems preserve the norm of the linear function <span class="math inline">\(\mathbf{T}(\cdot)\)</span>. Thus, they are also <a href="ch-optApp.html#sub:Optimization">hat operators</a>. Moreover, the equivalence of <a href="ch-optApp.html#eq:norm-4">(15.4)</a> and <a href="ch-optApp.html#eq:norm-2">(15.2)</a> tells that these two sequences are <a href="ch-optApp.html#sub:appSys">dual</a>.</span>
<span class="math display">\[
\begin{split}\mbox{Cost : }\begin{cases}
\min_{\mathbf{x}} &amp; \mathbf{c}^{\top}\mathbf{x},\\
\mbox{s.t. } &amp; \mathbf{A}\mathbf{x}=\mathbf{p},\\
 &amp; \mathbf{x}\succeq\mathbf{0}.
\end{cases} &amp; \quad\mbox{Profit : }\begin{cases}
\max_{\mathbf{y}} &amp; \mathbf{p}^{\top}\mathbf{y},\\
\mbox{s.t. } &amp; \mathbf{0}\preceq\mathbf{A}^{\top}\mathbf{y}\preceq\mathbf{c},\\
 &amp; \mathbf{p}^{\top}\mathbf{y}\geq0.
\end{cases}\end{split}
\]</span>
Minimizing the cost and maximizing the income both tend to decrease the <em>gap</em> <span class="math display">\[\mathbf{x}^{\top}\mathbf{c}-\mathbf{p}^{\top}\mathbf{y}\geq 0\]</span> to zero. One can solve one of them and solve the other as a by-product. On the other hand, if either problem has been solved, then so does the other. Therefore, these two optimizations are dual and simply aim to the same target (of reducing the gap).<label for="tufte-sn-409" class="margin-toggle sidenote-number">409</label><input type="checkbox" id="tufte-sn-409" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">409</span> Once the dual exists, and it is intrinsically connected to the primal problem. The dual problem typically forms an adversary problem with the same set of data. They provide a certificate of the optimality to each other.</span></p>
<p>Now since the cost minimization with respect to <span class="math inline">\(\mathbf{x}\)</span> corresponds to the profit maximization with respect to <span class="math inline">\(\mathbf{y}\)</span>, we establish a concrete relation for <span class="math inline">\(\mathbf{x}\)</span>. Under this relationship, the meaning of <span class="math inline">\(\mathbf{x}\)</span> serves as a <a href="ch-representation.html#ch:representation">dual</a> variable of the portfolio <span class="math inline">\(\mathbf{y}\)</span>. If the portfolio is interpreted as a plan regarding the demand, then <span class="math inline">\(\mathbf{x}\)</span> would be about a corresponding plan for the supply.<label for="tufte-sn-410" class="margin-toggle sidenote-number">410</label><input type="checkbox" id="tufte-sn-410" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">410</span> Cost minimization and profit maximization are often assumed the features in competitive markets.</span></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:LP"></span>
<img src="fig/Part4/LP.gif" alt="Solving the income maximization problem by moving along the feasible direction" width="100%"><!--
<p class="caption marginnote">-->Figure 15.4: Solving the income maximization problem by moving along the feasible direction<!--</p>-->
<!--</div>--></span>
</p>
<p>The above problems of selecting optimal solutions from some specified sets are known as <em>mathematical programming</em> problems. A typical mathematical programming problem consists of a real-valued <em>objective function</em> and some equality and/or inequality <em>constraints</em>. The <strong>constraints</strong> specified a feasible set, and the <strong>objective function</strong> provides the guides for moving towards the optimal solution along the <strong>feasible directions</strong> within the set. When both the objective function and the constraints are linear, the problem becomes a <em>linear programming</em> problem.<label for="tufte-sn-411" class="margin-toggle sidenote-number">411</label><input type="checkbox" id="tufte-sn-411" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">411</span> In economics, for various purposes, the <strong>objective functions</strong> are often assumed to be non-linear. For example, a famous <strong>mathematical programming</strong> problem is about utility maximization
<span class="math display">\[\mbox{Utility: }\begin{cases}
\max_{\mathbf{y}} &amp; f(\mathbf{y}),\\
\mbox{s.t. } &amp; \mathbf{0}\preceq\mathbf{A}^{\top}\mathbf{y}\preceq\mathbf{c},\\
 &amp; f(\mathbf{y})\geq0.
\end{cases}\]</span>
where <span class="math inline">\(f(\cdot):\mathbb{R}^{n}\rightarrow\mathbb{R}^{+}\)</span> is a continuous real-valued function called <em>utility function</em>. To maintain the <strong>feasible set</strong> as a <a href="#sub:">convex set</a>, one has to impose some additional assumption on the function <span class="math inline">\(f(\cdot)\)</span>. One common choice is to assume that the second derivative of <span class="math inline">\(f(\cdot)\)</span> is non-positive (see <a href="sub-calculus.html#sub:opt">optimality condition</a>).
The <strong>feasible direction</strong> of the problem is given by some linearization of <span class="math inline">\(f(\cdot)\)</span>, i.e.,
<span class="math display">\[f(\mathbf{y})\approx f(\mathbf{y}_{0})+\underset{\delta \mathbf{y}\geq0}{\underbrace{\left\langle \nabla f(\mathbf{y}_{0}),\,(\mathbf{y}-\mathbf{y}_{0})\right\rangle }},\]</span>
so that the <strong>feasible direction</strong> <span class="math inline">\(\delta \mathbf{y}\)</span> is still contained in some cone (called the linearizing cone), and some standard <strong>linear programming</strong> techniques can solve the problem.</span></p>
<div class="solution">
<p class="solution-begin">
Solving mathematical programming problems <span id="sol-start-95" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-95', 'sol-start-95')"></span>
</p>
<div id="sol-body-95" class="solution-body" style="display: none;">
<p>There is no closed-form expression for the solutions of <strong>mathematical programming</strong> problems because the solutions are simply the convergent results of some optimizing sequences. For example, figure <a href="ch-optApp.html#fig:LP">15.4</a> shows the mechanism of solving a <strong>linear programming</strong> (income maximization) problem. The solution is from the iterative sequence <span class="math display">\[\mathbf{p}^{\top}\mathbf{y}_n = \mathbf{p}^{\top}(\mathbf{y}_{n-1}) + \delta \mathbf{y}\]</span> where the iteration consists of an initial vector <span class="math inline">\(\mathbf{y}_0\)</span> and a stepwise incremental movement <span class="math inline">\(\delta \mathbf{y}\)</span> alone the feasible direction.</p>
<p>Figure <a href="ch-optApp.html#fig:LP">15.4</a> considers the following problem
<span class="math display">\[\begin{cases}
\max_{\mathbf{y}} &amp; \left[\begin{array}{c}
4\\
3
\end{array}\right]^{\top}\left[\begin{array}{c}
y_1\\
y_2
\end{array}\right],\\
\mbox{s.t. } &amp; \left[\begin{array}{c}
0\\
0\\
0
\end{array}\right]\preceq\left[\begin{array}{ccc}
180 &amp; 40 &amp; 120\\
100 &amp; 90 &amp; 150
\end{array}\right]^{\top}\left[\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right]\preceq\left[\begin{array}{c}
2000\\
800\\
1500
\end{array}\right].
\end{cases}\]</span></p>
<p>There are many available solvers for solving linear programming problems. Here is one example.</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" data-line-number="1"><span class="kw">library</span>(lpSolve)</a>
<a class="sourceLine" id="cb111-2" data-line-number="2"></a>
<a class="sourceLine" id="cb111-3" data-line-number="3"><span class="co"># Coefficients of the objective function</span></a>
<a class="sourceLine" id="cb111-4" data-line-number="4">LP.obj =<span class="st"> </span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb111-5" data-line-number="5"> </a>
<a class="sourceLine" id="cb111-6" data-line-number="6"><span class="co"># Left hand side coefficients of constraints by rows</span></a>
<a class="sourceLine" id="cb111-7" data-line-number="7">LP.con =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">180</span>, <span class="dv">100</span>,</a>
<a class="sourceLine" id="cb111-8" data-line-number="8">                  <span class="dv">40</span>, <span class="dv">90</span>,</a>
<a class="sourceLine" id="cb111-9" data-line-number="9">                  <span class="dv">120</span>, <span class="dv">150</span>), <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb111-10" data-line-number="10"></a>
<a class="sourceLine" id="cb111-11" data-line-number="11"><span class="co"># Set unequality signs for the constraints</span></a>
<a class="sourceLine" id="cb111-12" data-line-number="12">LP.dir =<span class="st"> </span><span class="kw">c</span>(<span class="st">"&lt;="</span>,</a>
<a class="sourceLine" id="cb111-13" data-line-number="13">          <span class="st">"&lt;="</span>,</a>
<a class="sourceLine" id="cb111-14" data-line-number="14">          <span class="st">"&lt;="</span>)</a>
<a class="sourceLine" id="cb111-15" data-line-number="15"></a>
<a class="sourceLine" id="cb111-16" data-line-number="16"><span class="co"># Set right hand side coefficients</span></a>
<a class="sourceLine" id="cb111-17" data-line-number="17">LP.rhs =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2000</span>,</a>
<a class="sourceLine" id="cb111-18" data-line-number="18">           <span class="dv">800</span>,</a>
<a class="sourceLine" id="cb111-19" data-line-number="19">           <span class="dv">1500</span>)</a>
<a class="sourceLine" id="cb111-20" data-line-number="20"></a>
<a class="sourceLine" id="cb111-21" data-line-number="21"><span class="co"># Final value </span></a>
<a class="sourceLine" id="cb111-22" data-line-number="22"><span class="kw">lp</span>(<span class="st">"max"</span>, LP.obj, LP.con, LP.dir, LP.rhs)</a></code></pre></div>
<pre><code>## Success: the objective function is 46</code></pre>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" data-line-number="1"><span class="co"># Optimal y_1 and y_2 </span></a>
<a class="sourceLine" id="cb113-2" data-line-number="2"><span class="kw">lp</span>(<span class="st">"max"</span>, LP.obj, LP.con, LP.dir, LP.rhs)<span class="op">$</span>solution</a></code></pre></div>
<pre><code>## [1] 10  2</code></pre>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>As you can see, getting an optimal solution from <strong>mathematical programming</strong> is to identify the optimality sequentially. The whole procedure does not rely on any external forces but merely the movements along the <strong>feasible directions</strong>. This situation is analogous to the <a href="ch-DE.html#sub:stab">Tâtonnement mechanism</a> that can dynamically adjust the price based on the demand and supply gap (see chapter <a href="ch-DE.html#sub:stab">8.4</a>). Suppose pricing adjustment is about the movements of the macro-object - price. The <strong>mathematical programming</strong> provides an interpretation of the <a href="#sub:">equilibrium</a> regarding the movements of the micro-objects - individual supply and demand’s quantities given the constant price and the cost vectors.<label for="tufte-sn-412" class="margin-toggle sidenote-number">412</label><input type="checkbox" id="tufte-sn-412" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">412</span> We will consolidate these two types of mechanisms under Aristotle’s law in CH[?].</span> Under the laissez-faire (free-market) doctrine, this optimality principle, namely moving towards the optimum within the feasible region, is considered a natural rule governing the individual’s decisions.</p>
<p><span class="newthought">* Imaginary forces and the ‘complete market’ </span></p>
<p>It is known that a linear <a href="ch-DE.html#sub:ode">ordinary differential equation</a> with high order differential terms can be converted to an equivalent system of <a href="ch-DE.html#sub:ode">ordinary differential equations</a> with only first-order differential terms. Let’s consider
<span class="math display">\[
\begin{align*}
\mbox{2th order DE :} &amp;\quad
\frac{\mbox{d}^{2}x(t)}{\mbox{d}t^{2}}+c_{1}\frac{\mbox{d}x(t)}{\mbox{d}t}+c_{2}x(t)=0 \\
\mbox{ODE system : } &amp;\quad
\begin{cases}
\frac{\mbox{d}x(t)}{\mbox{d}t}= &amp; y(t)\\
\frac{\mbox{d}y(t)}{\mbox{d}t}= &amp; -c_{1}y(t)-c_{2}x(t)
\end{cases}
\end{align*}
\]</span>
where the 2nd-order differential term is converted to the variable <span class="math inline">\(y(t)\)</span> in the new system. Two differential equations in the new system are both 1st-ordered, although the infinitesimal change of <span class="math inline">\(x\)</span>, <span class="math inline">\(\mbox{d}x(t)/\mbox{d}t\)</span>, is driven by <span class="math inline">\(y(t)\)</span>.</p>
<div class="solution">
<p class="solution-begin">
Second-order differentiations and bivariate systems <span id="sol-start-96" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-96', 'sol-start-96')"></span>
</p>
<div id="sol-body-96" class="solution-body" style="display: none;">
<p>One way of studying the high order differential terms is to represent them into a system of first-order differential equations.</p>
<p>Consider the system<span class="math display">\[\begin{cases}
\frac{\mbox{d}x(t)}{\mbox{d}t}= &amp; c_{11}x(t)+c_{12}y(t),\\
\frac{\mbox{d}y(t)}{\mbox{d}t}= &amp; c_{21}x(t)+c_{22}y(t).
\end{cases}\]</span>
We can take the first equation and then take another differentiation of it with respect to <span class="math inline">\(t\)</span>:
<span class="math display">\[\begin{align*}\frac{\mbox{d}^{2}x(t)}{\mbox{d}t^{2}}&amp;=c_{11}\frac{\mbox{d}x(t)}{\mbox{d}t}+c_{12}\frac{\mbox{d}y(t)}{\mbox{d}t}\\
&amp;=c_{11}\frac{\mbox{d}x(t)}{\mbox{d}t}+c_{12}(c_{21}x(t)+c_{22}y(t)).\end{align*}\]</span>
By rewriting the above equation, we have <span class="math display">\[\frac{\mbox{d}^{2}x(t)}{\mbox{d}t^{2}}-c_{11}\frac{\mbox{d}x(t)}{\mbox{d}t}=c_{12}(c_{21}x(t)+c_{22}y(t)).\]</span>
Therefore, we have a new system of equation<label for="tufte-sn-413" class="margin-toggle sidenote-number">413</label><input type="checkbox" id="tufte-sn-413" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">413</span> This trick can be applied to some non-linear systems<span class="math display">\[\begin{cases}
\frac{\mbox{d}x}{\mbox{d}t}= &amp; f(x,y,t),\\
\frac{\mbox{d}y}{\mbox{d}t}= &amp; g(x,y,t).
\end{cases}\]</span>
Similarly, we take the first equation and then take another differentiation of it with respect to <span class="math inline">\(t\)</span>:
<span class="math display">\[\begin{align*}\frac{\mbox{d}^{2}x}{\mbox{d}t^{2}} &amp;=  \frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}\frac{\mbox{d}x}{\mbox{d}t}+\frac{\partial f}{\partial y}\frac{\mbox{d}y}{\mbox{d}t}
\\
&amp;=  \frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}f(x,y,t)+\frac{\partial f}{\partial y}g(x,y,t).\end{align*}\]</span>
Let <span class="math display">\[\frac{\partial f}{\partial t}+\frac{\partial f}{\partial x}f(x,y,t)+\frac{\partial f}{\partial y}g(x,y,t)=F(x,y,t).\]</span>
Then we have the system
<span class="math display">\[\begin{cases}
\frac{\mbox{d}x}{\mbox{d}t} &amp; =f(x,y,t),\\
\frac{\mbox{d}^{2}x}{\mbox{d}t^{2}} &amp; =F(x,y,t).
\end{cases}\]</span></span>
<span class="math display">\[\begin{cases}
\frac{\mbox{d}x(t)}{\mbox{d}t} &amp; =c_{11}x(t)+c_{12}y(t),\\
\frac{\mbox{d}^{2}x(t)}{\mbox{d}t^{2}}-c_{11}\frac{\mbox{d}x(t)}{\mbox{d}t} &amp; =c_{12}(c_{21}x(t)+c_{22}y(t)).
\end{cases}\]</span></p>
<p>To solve this system, we notice that the system is exactly the same as
<span class="math display">\[\left[\begin{array}{cc}
1 &amp; 0\\
1 &amp; -c_{11}
\end{array}\right]\left[\begin{array}{c}
\frac{\mbox{d}x}{\mbox{d}t}\\
\frac{\mbox{d}^{2}x}{\mbox{d}t^{2}}
\end{array}\right]=\left[\begin{array}{cc}
c_{11} &amp; c_{12}\\
c_{12}c_{21} &amp; c_{12}c_{22}
\end{array}\right]\left[\begin{array}{c}
x\\
y
\end{array}\right].\]</span>
Under the matrix expression, there is
<span class="math display">\[\mathbf{A}\left[\begin{array}{c}
\frac{\mbox{d}x}{\mbox{d}t}\\
\frac{\mbox{d}^{2}x}{\mbox{d}t^{2}}
\end{array}\right]=\mathbf{C}\left[\begin{array}{c}
x\\
y
\end{array}\right]\Leftrightarrow\left[\begin{array}{c}
x\\
y
\end{array}\right]=\mathbf{C}^{-1}\mathbf{A}\left[\begin{array}{c}
\frac{\mbox{d}x}{\mbox{d}t}\\
\frac{\mbox{d}^{2}x}{\mbox{d}t^{2}}
\end{array}\right]=\mathbf{B}\left[\begin{array}{c}
\frac{\mbox{d}x}{\mbox{d}t}\\
\frac{\mbox{d}^{2}x}{\mbox{d}t^{2}}
\end{array}\right]\]</span>
if <span class="math inline">\(\mathbf{C}\)</span> is invertible. Therefore, the new system can be written as <span class="math display">\[\begin{cases}
x &amp; =b_{11}\frac{\mbox{d}x}{\mbox{d}t}+b_{12}\frac{\mbox{d}^{2}x}{\mbox{d}t},\\
y &amp; =b_{21}\frac{\mbox{d}x}{\mbox{d}t}+b_{22}\frac{\mbox{d}^{2}x}{\mbox{d}t}.
\end{cases}\]</span>
Because both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> depend on the first and the second differentiations of <span class="math inline">\(x\)</span>, solving the system is about separably solving these second-order differential equations.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>Following the idea of the above conversion, we can derive a similar procedure for an equivalent system of a <a href="ch-UnMulti.html#sub:Markov">stochastic process</a> with the <a href="ch-eigen.html#sub:matNorms">AR(2)</a> specification.<label for="tufte-sn-414" class="margin-toggle sidenote-number">414</label><input type="checkbox" id="tufte-sn-414" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">414</span> From a technical aspect, one has to realize that the continuous-time counterpart of the <a href="ch-eigen.html#sub:matNorms">AR(2)</a> is not exactly the 2nd order differential equation, as the discrete counterpart of a differential operator <span class="math inline">\(\mbox{d}(\cdot)/\mbox{d}t\)</span> corresponds to <span class="math inline">\((1-\mathbf{L})\)</span> with the lag operator <span class="math inline">\(\mathbf{L}\)</span>. In the second system, we are working on the operator <span class="math inline">\((1-\mathbf{L}/\lambda)\)</span> including a fraction, the corresponding differential operator should be something about the fractional differentiation, but this technical concern is beyond our scope for the moment.</span>
<span class="math display">\[
\begin{align*}
\mbox{AR(2) Process : } &amp;\quad  X_{t}(\omega)-\phi_{1}X_{t-1}(\omega)-\phi_{2}X_{t-2}(\omega)=\varepsilon(\omega).\\
\mbox{System of AR(1) : } &amp;\quad    \begin{cases}
Y_{t}(\omega) &amp; =\lambda_{1}^{-1}Y_{t-1}(\omega)+\varepsilon(\omega),\\
X_{t}(\omega) &amp; =\lambda_{2}^{-1}X_{t-1}(\omega)+Y_{t}(\omega).
\end{cases}
\end{align*}
\]</span>
In this expression, the error random variable <span class="math inline">\(\varepsilon(\omega)\)</span> has zero population mean and constant variance; the <a href="ch-eigen.html#sub:det">eigenvalues</a> <span class="math inline">\(\lambda_{1}\)</span> and <span class="math inline">\(\lambda_{2}\)</span> are the roots of the polynomial of the <a href="ch-eigen.html#sub:matNorms">lagged operator</a> <span class="math display">\[\left(1-\phi_{1}\mathbf{L}-\phi_{2}\mathbf{L}^{2}\right)=\left(\lambda_{1}-\mathbf{L}\right)\left(\lambda_{2}-\mathbf{L}\right)=0\]</span>
such that <span class="math inline">\(\mathbf{L}X_{t}(\omega)=\lambda_{i}X_{t}(\omega)\)</span> where the process <span class="math inline">\(X_{t}(\omega)\)</span> can be thought of as an “<a href="ch-representation.html#sub:innerProd">eigenfunction</a>.”<label for="tufte-sn-415" class="margin-toggle sidenote-number">415</label><input type="checkbox" id="tufte-sn-415" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">415</span> The meaning of this “eigenfunction” will become clear when we consider these processes from a <a href="ch-representation.html#sub:conjugacy">Hilbert space</a>’s perspective, see Ch[?].</span></p>
<p>The “concomitance” of these two systems comes from the following factorization
<span class="math display">\[\begin{align*}
\left(1-\phi_{1}\mathbf{L}-\phi_{2}\mathbf{L}^{2}\right)X_{t}(\omega) &amp;=    \left(1-\frac{\mathbf{L}}{\lambda_{1}}\right)\left(1-\frac{\mathbf{L}}{\lambda_{2}}\right)X_{t}(\omega)\\
&amp;=  \left(1-\frac{\mathbf{L}}{\lambda_{1}}\right)Y_{t}(\omega)\\
&amp;=  Y_{t}(\omega)-\lambda^{-1}_{1}Y_{t-1}(\omega)=\varepsilon(\omega), 
\end{align*}\]</span>
where the second equality comes from the substitution <span class="math display">\[Y_{t}(\omega)=(1-\lambda_{2}^{-1}\mathbf{L})X_{t}(\omega).\]</span></p>
<p>We say the system of AR(1) processes is the “concomitance” of the AR(2) process because they are two systems working as two clocks perfectly in accord while they are essentially different.<label for="tufte-sn-416" class="margin-toggle sidenote-number">416</label><input type="checkbox" id="tufte-sn-416" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">416</span> Leibniz described “concomitance” as “deux horloges ou deux montres, qui s’accordent parfaitement”.</span> If one observes an <span class="math inline">\(X_t(\omega)\)</span> from either of them, one cannot tells where the <span class="math inline">\(X_t(\omega)\)</span> comes from. Although there is one “insignificant” difference that <span class="math inline">\(\phi_{1},\phi_{2}\in\mathbb{R}\)</span> and <span class="math inline">\(\lambda_{1},\lambda_{2}\in\mathbb{C}\)</span>, this insignificance plays no role for real-valued realizations/observations of the process <span class="math inline">\(X_t(\omega)\)</span>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:goldPrice"></span>
<img src="fig/Part4/goldPrice.png" alt="Modeling the gold price by an AR(2)" width="100%"><!--
<p class="caption marginnote">-->Figure 15.5: Modeling the gold price by an AR(2)<!--</p>-->
<!--</div>--></span>
</p>
<p>Now let’s consider one application of <a href="ch-eigen.html#sub:matNorms">AR(2)</a>. Many asset prices from the stock market can be modeled as <a href="ch-eigen.html#sub:matNorms">AR(2)</a> processes. Figure <a href="ch-optApp.html#fig:goldPrice">15.5</a> shows the fluctuations in the gold price around eight months. The mean of the process as a constant over these eight months has been extracted.
The model follows
<span class="math display">\[\mbox{Gold Price}_t = 1.2\mbox{Gold Price}_{t-1} - 0.2\mbox{Gold Price}_{t-1}\]</span> where the increment of <span class="math inline">\(t\)</span> is one day. The probabilities of having zeros for the estimated coefficients are rather small.</p>
<div class="solution">
<p class="solution-begin">
Estimate AR(2) <span id="sol-start-97" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-97', 'sol-start-97')"></span>
</p>
<div id="sol-body-97" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" data-line-number="1"><span class="kw">library</span>(Quandl); <span class="kw">library</span>(xts); <span class="kw">library</span>(lubridate); <span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb115-2" data-line-number="2"><span class="co"># NASDAQ Commodity Gold Index</span></a>
<a class="sourceLine" id="cb115-3" data-line-number="3">gold =<span class="st">  </span><span class="kw">Quandl</span>(<span class="st">"NASDAQOMX/NQCIGCER"</span>, <span class="dt">type =</span> <span class="st">"xts"</span>, <span class="dt">collapse =</span> <span class="st">"daily"</span>, <span class="dt">start_date=</span><span class="st">"2019-09-01"</span>, <span class="dt">end_date=</span><span class="st">"2020-04-01"</span>)</a>
<a class="sourceLine" id="cb115-4" data-line-number="4">gold =<span class="st"> </span><span class="kw">xts</span>(gold<span class="op">$</span><span class="st">"Index Value"</span>); </a></code></pre></div>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1">time=<span class="kw">length</span>(gold); </a>
<a class="sourceLine" id="cb116-2" data-line-number="2">gold.T=gold[<span class="dv">3</span><span class="op">:</span>time];  <span class="co"># X_t</span></a>
<a class="sourceLine" id="cb116-3" data-line-number="3">gold.lag=gold[<span class="dv">2</span><span class="op">:</span>(time<span class="dv">-1</span>)]; <span class="co"># X_{t-1}</span></a>
<a class="sourceLine" id="cb116-4" data-line-number="4">gold.lag2=gold[<span class="dv">1</span><span class="op">:</span>(time<span class="dv">-2</span>)]; <span class="co"># X_{t-2}</span></a>
<a class="sourceLine" id="cb116-5" data-line-number="5"></a>
<a class="sourceLine" id="cb116-6" data-line-number="6"><span class="co"># AR(2) estimation with p-values</span></a>
<a class="sourceLine" id="cb116-7" data-line-number="7"><span class="kw">summary</span>(<span class="kw">lm</span>(gold.T <span class="op">~</span><span class="st"> </span><span class="dv">0</span><span class="op">+</span>gold.lag <span class="op">+</span><span class="st"> </span>gold.lag2));</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = gold.T ~ 0 + gold.lag + gold.lag2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -42.334  -3.714   1.035   4.352  46.754 
## 
## Coefficients:
##           Estimate Std. Error t value Pr(&gt;|t|)    
## gold.lag   1.16729    0.08245  14.158   &lt;2e-16 ***
## gold.lag2 -0.16734    0.08246  -2.029   0.0443 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 11.12 on 143 degrees of freedom
## Multiple R-squared:  0.9998, Adjusted R-squared:  0.9998 
## F-statistic: 4.365e+05 on 2 and 143 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1"><span class="co"># Estimate the mean of AR(2):  X_t = mean + X_{t-1} + X_{t-2} + e </span></a>
<a class="sourceLine" id="cb118-2" data-line-number="2">r=<span class="kw">arima</span>(gold.T,<span class="dt">order=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>));</a>
<a class="sourceLine" id="cb118-3" data-line-number="3">mean.rev =r<span class="op">$</span>coef[<span class="dv">3</span>];</a>
<a class="sourceLine" id="cb118-4" data-line-number="4"><span class="co"># Mean reversion </span></a>
<a class="sourceLine" id="cb118-5" data-line-number="5">gold.T=gold.T<span class="op">-</span>mean.rev; gold.lag=gold.lag<span class="op">-</span>mean.rev; gold.lag2=gold.lag2<span class="op">-</span>mean.rev</a></code></pre></div>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" data-line-number="1"><span class="co"># plot</span></a>
<a class="sourceLine" id="cb119-2" data-line-number="2">gold=<span class="kw">fortify</span>(gold.T)</a>
<a class="sourceLine" id="cb119-3" data-line-number="3"><span class="kw">ggplot</span>(gold, <span class="kw">aes</span>(<span class="dt">x=</span>Index, <span class="dt">y=</span><span class="st">`</span><span class="dt">Index Value</span><span class="st">`</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>( <span class="dt">color=</span><span class="st">"steelblue"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"year"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Gold Price with mean reversion"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:SimAR2"></span>
<img src="fig/Part4/SimAR2.png" alt="Simulate the AR(2) with the concomitant systems, adding imaginary forces to the second system" width="100%"><!--
<p class="caption marginnote">-->Figure 15.6: Simulate the AR(2) with the concomitant systems, adding imaginary forces to the second system<!--</p>-->
<!--</div>--></span>
</p>
<p>The usual utilization of the estimated stochastic model is to simulate other models for understanding the quantitative contributions better. If quantitative structures can recreate the empirical patterns of interests, then the structures should incorporate some intrinsic dynamical matters about the object. Otherwise, we may doubt that some principal components may be missing in the quantification procedure.<label for="tufte-sn-417" class="margin-toggle sidenote-number">417</label><input type="checkbox" id="tufte-sn-417" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">417</span> When we review the data in figure <a href="ch-optApp.html#fig:goldPrice">15.5</a>, we can find that there are many small fluctuations, a <span class="math inline">\(3\)</span>-months mild decline since September 2019, then a slow climbing trend for about <span class="math inline">\(4\)</span>-months before a steep descend and then a quick reversion at the end of March. (Global stock markets crash on March 12th due to continued concerns over COVID-19.)</span></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">20201231</span>)</a>
<a class="sourceLine" id="cb120-2" data-line-number="2">model.time=<span class="st"> </span><span class="dv">200</span>;  </a>
<a class="sourceLine" id="cb120-3" data-line-number="3"><span class="co"># At time=(200-k), introduce the imaginary price</span></a>
<a class="sourceLine" id="cb120-4" data-line-number="4">k=<span class="dv">50</span>; </a>
<a class="sourceLine" id="cb120-5" data-line-number="5"><span class="co"># Store the AR(2) estimate result of the gold price for phi_1 and phi_2</span></a>
<a class="sourceLine" id="cb120-6" data-line-number="6">ar=<span class="kw">arima</span>(gold.T,<span class="dt">order=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>)); </a>
<a class="sourceLine" id="cb120-7" data-line-number="7"><span class="co"># At t=1,2, use stock values as initials </span></a>
<a class="sourceLine" id="cb120-8" data-line-number="8">xT.model =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, model.time); xT.model[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] =<span class="st"> </span>gold.T[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] </a>
<a class="sourceLine" id="cb120-9" data-line-number="9"><span class="co"># Initials in model 2 coincide with model 1</span></a>
<a class="sourceLine" id="cb120-10" data-line-number="10">xT.model2 =<span class="st"> </span>dxT.model2 =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, model.time); xT.model2[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] =<span class="st"> </span>xT.model[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]; dxT.model2[<span class="dv">1</span>]=xT.model[<span class="dv">2</span>]<span class="op">-</span>xT.model[<span class="dv">1</span>];</a>
<a class="sourceLine" id="cb120-11" data-line-number="11"></a>
<a class="sourceLine" id="cb120-12" data-line-number="12"><span class="co"># Factorization of (1-phi_1 L - phi_2 L^2) = 0</span></a>
<a class="sourceLine" id="cb120-13" data-line-number="13">c=<span class="kw">polyroot</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="op">-</span>ar<span class="op">$</span>coef[<span class="dv">1</span>], <span class="op">-</span>ar<span class="op">$</span>coef[<span class="dv">2</span>])); c </a></code></pre></div>
<pre><code>## [1] 1.117310+0i 4.369572-0i</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1"><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(model.time<span class="dv">-2</span>)){ </a>
<a class="sourceLine" id="cb122-2" data-line-number="2">  e =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="dv">5</span>) <span class="co"># The random force of both systems</span></a>
<a class="sourceLine" id="cb122-3" data-line-number="3">  <span class="co"># System one: X_{t} = phi_1 X_{t-1} + phi_2 X_{t-2} + e_t</span></a>
<a class="sourceLine" id="cb122-4" data-line-number="4">  xT.model[t<span class="op">+</span><span class="dv">2</span>] =<span class="st"> </span>ar<span class="op">$</span>coef[<span class="dv">1</span>]<span class="op">*</span>(xT.model[t<span class="op">+</span><span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span>ar<span class="op">$</span>coef[<span class="dv">2</span>]<span class="op">*</span><span class="st"> </span>xT.model[t] <span class="op">+</span><span class="st"> </span>e;</a>
<a class="sourceLine" id="cb122-5" data-line-number="5">  <span class="co"># System two: </span></a>
<a class="sourceLine" id="cb122-6" data-line-number="6">  <span class="cf">if</span> (t<span class="op">==</span><span class="dv">1</span>) {dxT.model2[<span class="dv">2</span>]=xT.model[<span class="dv">3</span>]<span class="op">-</span>xT.model[<span class="dv">2</span>]};</a>
<a class="sourceLine" id="cb122-7" data-line-number="7">  <span class="co"># no imaginary force before the emergence</span></a>
<a class="sourceLine" id="cb122-8" data-line-number="8">    i =<span class="dv">0</span>;</a>
<a class="sourceLine" id="cb122-9" data-line-number="9">  <span class="co"># emergence of an imaginary force in a four-days window </span></a>
<a class="sourceLine" id="cb122-10" data-line-number="10">    <span class="cf">if</span> ((model.time<span class="op">-</span>k)<span class="op">&lt;</span>t <span class="op">&amp;&amp;</span><span class="st"> </span>t<span class="op">&lt;</span>(model.time<span class="op">-</span>(k<span class="dv">-5</span>))) {i=<span class="dv">2</span>}</a>
<a class="sourceLine" id="cb122-11" data-line-number="11">  <span class="co"># Y_{t} = (lambda_{1}^{-1} + imaginary force) Y_{t-1} + e_{t},</span></a>
<a class="sourceLine" id="cb122-12" data-line-number="12">  dxT.model2[t<span class="op">+</span><span class="dv">1</span>] =<span class="st"> </span>((<span class="dv">1</span><span class="op">/</span>c[<span class="dv">2</span>])<span class="op">+</span><span class="st"> </span><span class="kw">complex</span>(<span class="dt">real =</span> <span class="dv">0</span>, <span class="dt">imaginary =</span> i))<span class="op">*</span>dxT.model2[t] <span class="op">+</span><span class="st"> </span>e ;</a>
<a class="sourceLine" id="cb122-13" data-line-number="13">  <span class="co"># X_{t} = lambda_{2}^{-1}(X_{t-1})+Y_{t},</span></a>
<a class="sourceLine" id="cb122-14" data-line-number="14">  xT.model2[t<span class="op">+</span><span class="dv">1</span>] =<span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>c[<span class="dv">1</span>])<span class="op">*</span>(xT.model2[t]) <span class="op">+</span><span class="st"> </span>dxT.model2[t<span class="op">+</span><span class="dv">1</span>];</a>
<a class="sourceLine" id="cb122-15" data-line-number="15">}</a>
<a class="sourceLine" id="cb122-16" data-line-number="16"><span class="co"># adjust the last observation</span></a>
<a class="sourceLine" id="cb122-17" data-line-number="17">xT.model2 =<span class="st"> </span>xT.model2[<span class="dv">1</span><span class="op">:</span>(model.time<span class="dv">-1</span>)]; xT.model =<span class="st"> </span>xT.model[<span class="dv">2</span><span class="op">:</span>(model.time)] </a>
<a class="sourceLine" id="cb122-18" data-line-number="18"><span class="co"># Combine the simulates data</span></a>
<a class="sourceLine" id="cb122-19" data-line-number="19">Sys2 =<span class="st"> </span><span class="kw">Re</span>(xT.model2); Sys1=xT.model; Time =<span class="st"> </span><span class="dv">1</span><span class="op">:</span>(model.time<span class="dv">-1</span>); dat=<span class="kw">data.frame</span>(Time, Sys1, Sys2)</a></code></pre></div>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb123-1" data-line-number="1"><span class="co"># plot</span></a>
<a class="sourceLine" id="cb123-2" data-line-number="2"><span class="kw">ggplot</span>(dat, <span class="kw">aes</span>(<span class="dt">x=</span>Time, <span class="dt">y=</span>Sys2)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="dt">col=</span><span class="st">"steelblue"</span>) <span class="op">+</span><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">y=</span>Sys1, <span class="dt">col=</span><span class="st">"royalblue"</span>, <span class="dt">alpha=</span><span class="fl">0.2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"System I (points) System II (line) "</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Simulated values"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<div id="htmlwidget-6f702a747ed8da1bf111" style="width:55%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6f702a747ed8da1bf111">{"x":{"filter":"none","caption":"<caption>Simulated two concomitant systems <\/caption>","autoHideNavigation":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72","73","74","75","76","77","78","79","80","81","82","83","84","85","86","87","88","89","90","91","92","93","94","95","96","97","98","99","100","101","102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","126","127","128","129","130","131","132","133","134","135","136","137","138","139","140","141","142","143","144","145","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","167","168","169","170","171","172","173","174","175","176","177","178","179","180","181","182","183","184","185","186","187","188","189","190","191","192","193","194","195","196","197","198","199"],[-7.76264836705138,-8.91671923912245,-0.492194302329928,1.05401044597675,-4.23311857517955,-3.62713224191516,-4.50377378464338,-6.60648551551529,-1.40419220974611,3.7555323516175,5.48929879853632,-0.347582285630367,0.182422227052289,-6.94420710203946,-9.17912010576122,-10.7702173554376,-5.76155602719262,-13.7806217995428,-23.7175204172784,-15.6096430428534,-15.9111021295564,-13.6774928793696,-13.5578868086207,-16.3618291729559,-15.0620785671695,-17.0012503698142,-9.90769054518163,-2.74231752171457,1.71340542072842,3.67755585085572,4.72066671692584,8.74795919346073,11.8446017021076,15.3225649208024,8.00952293567171,14.2829552787114,26.8026889132619,23.7724935795487,16.0633090137417,14.8076677988691,22.9369998326565,17.3992067553126,12.158958497303,18.9349209362779,14.132920928997,13.1359167528323,8.06093401468788,3.56717720054174,-1.50489999460898,-0.960673576427719,-1.01727391596618,5.95553124269492,2.90281051771577,-2.54421756246287,-1.5319131764538,-5.25915013421976,-9.58416627089993,-12.7177705228517,-14.039801514477,-11.002190032816,-13.3011864093756,-16.2151228483279,-14.4036371330094,-11.3305755031877,-9.58184680490701,-7.29287936821076,-2.46456232358128,-6.24330799421165,-1.71908327539073,-9.50394279923951,-7.80446932317746,-9.44528449714797,-9.3897016218639,-17.7868807354214,-23.9815159325914,-23.7724137161802,-23.8274316106336,-25.4888350573707,-20.8606765118449,-24.5825575954678,-19.2580528608889,-17.8009957068734,-12.2413315784419,-6.65282418815711,8.73259252456638,10.7483700270463,6.10075043694521,2.66483364745122,-1.52814640599195,3.77146945270454,4.3668302692462,8.31282498055397,6.10297185817838,8.97376850100041,6.40924031914415,5.76956165991046,13.9336409937804,16.8870523360836,15.862103272222,12.7152386714075,9.77970913840032,12.0847410125126,6.7612731674841,10.7093026098178,14.9346524958438,15.519467383284,11.6279234411533,15.5885303026801,19.3532810620187,16.6822623208569,23.2064499516924,29.6148100792384,23.6591496335645,22.2800725729517,15.2909352156137,17.1239508113268,11.5031603629899,9.85175738955092,10.6150246864422,8.37434314628157,13.3896027760567,8.44737103978934,13.2230872953015,16.8291266314077,10.5937389017555,14.2122350033316,11.3435255925121,10.4060782303191,9.51610420959612,13.7164728975941,18.0865162504604,16.3313832859411,11.4019352657694,8.83594855881086,19.7720278408074,16.0751793383004,16.5741759577701,25.2072829000392,23.70573044199,26.3410947431426,27.7246078590822,26.904728082803,20.1387807881062,14.3653031539748,10.5843349676975,3.96189789795484,8.41092611369722,2.30036083267262,0.347325007382197,-1.7930255886349,-5.72048832326929,-3.41216403771748,-5.70147232844628,-9.63080213841174,-17.3610426687209,-3.62444213537316,-4.52645552373095,-3.58671654114114,-8.81055144909528,-14.6130421649675,-11.4513400335989,-3.49921381639519,0.282851897275562,-5.44728699549846,-5.66800282279925,0.603669512357634,9.82806709880733,10.1523896445327,7.29868609737984,5.92491801055151,6.31676549271871,10.8238942035369,14.575244110722,14.4011712561825,17.9658506933057,11.7416122962272,6.70045773534954,12.0118291655929,7.16903381832613,3.15537007162948,6.80235895852421,0.62952433725301,-9.53444912235048,0.217467076736742,4.55673709783446,-3.06878593778426,-6.30594133603482,-7.24799036967212,-6.5537274704724,-1.01672779694198,2.46849941601934,4.30167726712051,0.102879414896852,0.159966138054154,1.98444732083818,3.30854274516768,8.33089616423557,13.8441784091657,6.57115071370273],[-2.11264836705141,-3.80916850572731,4.09071486654361,5.15840319816517,-0.55905143919957,-0.33867859234338,-1.56055413892982,-3.97227716271961,0.953443366917148,5.86563217632257,7.37785219261455,1.34268551954535,1.69522310258125,-5.59024030645939,-7.9673108636252,-9.68564006454411,-4.7908521746587,-12.911835427906,-22.9399508654838,-14.9137131484438,-15.2882402687556,-13.1200273921751,-13.0589515085633,-15.9152787777087,-14.6624130083836,-16.6435470499208,-9.58754370678138,-2.4557839827801,1.96985483420556,3.90707977296735,4.92609214608635,8.93181631195863,12.0091550398345,15.4698412469968,8.14133622221423,14.400929042439,26.9082762124874,23.8669949110777,16.1478883308209,14.8833668473571,23.0047509819904,17.4598444823084,12.2132296642333,18.983493989819,14.1763941333476,13.1748255584092,8.0957576531575,3.59834458741685,-1.47700497710613,-0.935707351167864,-0.994928979145044,5.97553010901708,2.92070963541624,-2.52819773367386,-1.51757532367668,-5.24631766110374,-9.5726811225424,-12.7074912390689,-14.0306014874683,-10.9939559477622,-13.2938168487635,-16.2085270428121,-14.397733843425,-11.3252920199447,-9.57711805244114,-7.28864710346134,-2.46077441862358,-6.2399177942081,-1.71604902395294,-9.50122712412358,-7.80203877597773,-9.44310914132008,-9.38775466400252,-17.7851381952514,-23.979956347608,-23.7710178772994,-23.8261823255983,-25.4877169389969,-20.8596757885011,-24.5816619414528,-19.2572512446184,-17.8002782550066,-12.2406894542733,-6.65224948277688,8.73310688968481,10.748830387231,6.10116246235697,2.66520241292128,-1.52781635845595,3.77176484743335,4.36709464948324,8.31306160261563,6.10318363648939,8.97395804399017,6.40940996137426,5.76971349082898,13.9337768834572,16.8871739582435,15.8622121248599,12.7153360952387,9.77979633337389,12.0848190525909,6.76134301387058,10.7093651227959,14.9347084453728,15.5195174584827,11.6279682587874,15.5885704147591,19.3533169625948,16.6822944521101,23.2064787093765,29.6148358175559,23.6591726695289,22.2800931902921,15.2909536682698,17.123967326576,11.5031751442471,9.85177061887396,10.6150365267738,8.37435374345668,13.3896122605985,8.44737952851699,13.2230948927689,16.8291334311912,10.5937449876066,14.2122404502086,11.343530467503,10.4060825934682,9.51610811464341,13.7164763926372,18.0865193785471,16.3313860855993,11.4019377714819,8.83595080144013,19.7720298479754,16.075181134729,16.5741775655855,25.2072843390445,23.7057317299092,26.3410958958388,27.7246088907528,26.9047290061549,20.1387816145122,14.3653038936135,10.584335629679,3.96189849043261,8.41092664396872,2.30036130726909,0.347325432149171,-1.79302520846565,-5.72048798301529,-3.41216373318787,10.7614021686095,5.8079699280793,-59.3443169311366,-53.9701259202462,-52.508744516308,-47.2000282475258,-47.9978229205913,-49.7209400871345,-42.8811579481194,-31.6309435577299,-24.895652268315,-27.982310935149,-25.8370203653477,-17.4477396892066,-6.32806474327928,-4.30745553065478,-5.6429710825153,-5.65795082045466,-4.04997876362707,1.54558949163217,6.27109999437948,6.96890731948689,11.3139252870753,5.78809503864672,1.37202039251627,7.24284248291427,2.9007591786412,-0.664763976122743,3.38331370611445,-2.43054378912703,-12.2732303454089,-2.23376024173828,2.3628724268446,-5.03230933618201,-8.06330777118318,-8.82084495847211,-7.9614427357866,-2.27664227492978,1.34086762075783,3.2924393482774,-0.800395201082357,-0.648470620651508,1.26089107198023,2.66095511431875,7.75130094922574,13.3254368562705,6.10687359109813]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Sys1<\/th>\n      <th>Sys2<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script><p>The result of the simulations is given above.<label for="tufte-sn-418" class="margin-toggle sidenote-number">418</label><input type="checkbox" id="tufte-sn-418" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">418</span> The “concomitance” gradually becomes more significant after <span class="math inline">\(t=20\)</span>. Before the introduction of imaginary force at <span class="math inline">\(t=151\)</span>, the precision of the difference between the two systems goes to <span class="math inline">\(10^{-5}\)</span>. However, we should notice that the eigenvalues <span class="math inline">\(\lambda_{1}\)</span> and <span class="math inline">\(\lambda_{2}\)</span> correspond to the <a href="ch-eigen.html#sub:matNorms">lag operators</a> under the “eigenfunction” <span class="math inline">\(X_{t}(\omega)\)</span>. In practice, we can only have data vector <span class="math inline">\(\mathbf{x}_{T}\)</span> as a time series rather than the underlying dynamical law intrigued by <span class="math inline">\(X_{t}(\omega)\)</span> (recall the discussion in chapter <a href="ch-UnMulti.html#sub:WLLN">13.4</a>). Therefore, <span class="math inline">\(\lambda_{1}\)</span> and <span class="math inline">\(\lambda_{2}\)</span> cannot simulate the exact data given in the first system, because the simulated data, the “eigenvector,” in the second system are the discretized realizations of the “eigenfunction” <span class="math inline">\(X_{t}(\omega)\)</span>, not the realizations of the first system.</span> We can see that the standard AR(2) simulation (points in figure <a href="ch-optApp.html#fig:SimAR2">15.6</a>), although it can generate some persistent short trends and small fluctuations, cannot generate the sharp variation that occurred in figure <a href="ch-optApp.html#fig:goldPrice">15.5</a>. However, in the second simulated system, an “imaginary forced” <span class="math inline">\(2\mbox{i}\)</span> was added on four days such that
<span class="math display">\[Y_{t}(\omega)= (\lambda^{-1}_{1}+2\mbox{i)} Y_{t-1}(\omega) + \varepsilon(\omega), \mbox{ when } 151&lt;t&lt;156.\]</span>
The simulated sharp variation (line in figure <a href="ch-optApp.html#fig:SimAR2">15.6</a>) is made by the four-days long “imaginary force.” The meaning of this force will be given in CH[?]. For the moment, it worth noting that the real-valued parts of these two systems are exactly concomitance at any time period, excluding the propagations caused by <span class="math inline">\(2\mbox{i}Y_{t-1}(\omega)\)</span>.</p>
<p>For an observer who only restricts the attention to the <a href="sub-continuity.html#sub:completeness">real numbers</a>, these two systems are “identical” because the <a href="ch-eigen.html#sub:det">imaginary number</a> is illegitimate in his/her “complete real vision.” Since this observer cannot detect the observations from which system, if the data is generated by the the second system, the observer has to be “blind” to the emergence of the imaginary force. Furthermore, even though the imaginary force started to have real-valued influences over the process after the first period (emergence), the observer is not able to explore the source of the variations. This finding can illuminate the “incompleteness” of the “free market.”</p>
<p>Let’s set back the imaginary numbers and reflect on the components of the real-valued “free” market. Recall that we firstly confronted trouble to interpret the meaning of <span class="math inline">\(\mathbf{x}\)</span> in the pricing formula <span class="math inline">\(\mathbf{A}\mathbf{x}=\mathbf{p}\)</span>, then we resolved the problem by relating <span class="math inline">\(\mathbf{x}\)</span> to <span class="math inline">\(\mathbf{y}\)</span> through their dual roles in a <strong>mathematical programming</strong> setting where the unknown <span class="math inline">\(\mathbf{x}\)</span> became the dual of the production output vector <span class="math inline">\(\mathbf{y}\)</span>, namely an input vector of the production. Now, if we make a quick summary of available market-related concepts, we will find out a seemingly “complete loop.” Starting with some “input” <span class="math inline">\(\mathbf{x}\)</span>, we calculate the price <span class="math inline">\(\mathbf{p}\)</span>, then under the price vector <span class="math inline">\(\mathbf{p}\)</span> and its dual cost vector <span class="math inline">\(\mathbf{c}\)</span>, the optimality doctrine (the <a href="ch-DE.html#sub:MecWorld">invisible hand</a>) in the micro-level guides the individual participants to dismiss the supply-demand gap (the <strong>duality gap</strong>), while on the macro-level the <a href="ch-DE.html#sub:stab">Tâtonnement mechanism</a> plays a similar role; afterward, the system will confront the adjusted “<span class="math inline">\(\mathbf{x}\)</span>,” and the corresponding relabelled prices, so things are back to the beginning.<label for="tufte-sn-419" class="margin-toggle sidenote-number">419</label><input type="checkbox" id="tufte-sn-419" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">419</span>  To me, it is the most, if it is not the only, profound and delicate loop in the real economics that I have ever seen.</span></p>
<p>The “loop” is <a href="sub-axioms.html#sub:axSet">self-referential</a>, so is the theory of the “free” market. It gives a self-consistent axiomatic framework to describe market phenomena.
The change of some market variables must rely on some other change of happened in the loop, and any “unexpected” event can be attributed to some disturbances caused by the coarse medium of the transmission, which the market will eventually absorb or adapt to. In other words, the model is able to consistently explain any evidence for its variables because all these variables are <a href="sub-axioms.html#sub:axSet">self-referential</a>.</p>
<p>As we saw in chapter <a href="sub-continuity.html#sub:selfFixedPoint">6.5</a>, a self-referential framework is a double-edged razor blade. It may be a powerful solver but also can lead to a paradoxical conclusion.<label for="tufte-sn-420" class="margin-toggle sidenote-number">420</label><input type="checkbox" id="tufte-sn-420" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">420</span> Indeed, we can find out much evidence from various debates regarding economic-social issues.</span> One useful remedy to the self-referential framework is to find out where the paradox can occur.</p>
<p><a href="sub-incomplete.html#sub:incomplete">Gödel’s incompleteness theorem</a> tells us that we the paradox occurs as an inferential outcome on a set of jointly inconsistent logical deduction. The simulation example of the <a href="ch-eigen.html#sub:matNorms">AR(2)</a> price processes gave us such a set.</p>
<blockquote>
<p>I: “System I and System II are identical.”</p>
</blockquote>
<blockquote>
<p>II: “The price process follows one of these two systems.”</p>
</blockquote>
<blockquote>
<p>Outcome: “The price process is inconsistent with one of these two systems.”</p>
</blockquote>
<p>The predicate I and II cannot match the outcome. Therefore, a paradox occurs.
However, once we enlarge our vision to the <a href="ch-eigen.html#sub:det">complex number field</a>, we know that two systems are merely “identical” in the real-valued realm but perform differently in the imaginary-valued realm. Unfortunately, the observers in the real-valued “free” market cannot explore the causality of these “imaginary” changes.</p>
<div class="solution">
<p class="solution-begin">
Leibniz’s two clocks (the third case) <span id="sol-start-98" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-98', 'sol-start-98')"></span>
</p>
<div id="sol-body-98" class="solution-body" style="display: none;">
<p>"Figurez-vous deux horloges ou deux montres, qui s’accordent parfaitement. Or, cela se peut faire de trois façons. La première consiste dans l’influence mutuelle d’une horloge sur l’autre; la seconde, dans le soin d’un homme qui y prend garde; la troisième, dans leur propre exactitude.</p>
<p>…</p>
<p>Enfin la troisième manière sera de faire d’abord ces deux pendules avec tant d’art et de justesse qu’on se puisse assurer de leur accord dans la suite; et c’est la voie du consentement préétabli.</p>
<p>…</p>
<p>Mettez maintenant l’âme et le corps à la place de ces deux horloges. Leur accord ou sympathie arrivera aussi par une de ces trois façons. La voie de l’influence est celle de la philosophie vulgaire ; mais, comme on, ne saurait concevoir des particules matérielles ni des espèces ou qualités immatérielles qui puissent passer de l’une de ces substances dans l’autre, on est oblige d’abandonner ce sentiment. La voie de l’assistance est celle du système des causes occasionnelles ; mais je tiens que c’est faire venir Deus ex machina dans une chose naturelle et ordinaire, où selon la raison il ne doit intervenir que de la manière dont il concourt à toutes les autres choses de la nature. Ainsi il ne reste que mon hypothèse, c’est-à-dire que la voie de l’harmonie préétablie par un artifice divin prévenant, lequel dès le commencement a formé chacune de ces substances d’une manière si parfaite, si réglée avec tant d’exactitude qu’en ne suivant que ses propres lois qu’elles a reçues avec son être elle s’accorde pourtant avec l’autre ; tout comme s’il y avait une influence mutuelle, ou comme si Dieu y mettait toujours la main au delà de son concours général." - <span class="citation">Leibniz (<a href="bibliography.html#ref-Leibniz1696">1696</a>)</span></p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
</div>
</div></body></html>

<p style="text-align: center;">
<a href="ch-representation.html"><button class="btn btn-default">Previous</button></a>
<a href="ch-randomization.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2021-03-10
</p>
</div>
</div>



</body>
</html>
