<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="13 Uncertainty in Multiple Dimensions | Project XXII" />
<meta property="og:type" content="book" />





<meta name="author" content="Zhengyuan Gao" />

<meta name="date" content="2020-10-04" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="13 Uncertainty in Multiple Dimensions | Project XXII">

<title>13 Uncertainty in Multiple Dimensions | Project XXII</title>

<link href="libs/tufte-css/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>



</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Project XXII<p><p class="author">Zhengyuan Gao</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BA; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Preface</a>
<a href="part-i-inference-based-upon-logic-and-logical-computation.html">PART I: Inference Based upon Logic and Logical Computation</a>
<a href="sub-logic.html"><span class="toc-section-number">1</span> Logic</a>
<a href="sub-set-theory.html"><span class="toc-section-number">2</span> Set Theory</a>
<a href="sub-axioms.html"><span class="toc-section-number">3</span> Axioms</a>
<a href="sub-inferknow.html"><span class="toc-section-number">4</span> Inference and Knowledge</a>
<a href="sub-incomplete.html"><span class="toc-section-number">5</span> Incompleteness</a>
<a href="part-ii-infinitesimal-changes-and-their-consequences.html">PART II: Infinitesimal Changes and their Consequences</a>
<a href="sub-continuity.html"><span class="toc-section-number">6</span> Continuity</a>
<a href="sub-calculus.html"><span class="toc-section-number">7</span> Calculus</a>
<a href="ch-DE.html"><span class="toc-section-number">8</span> Differential Equations</a>
<a href="ch-CalUn.html"><span class="toc-section-number">9</span> Calculus under Uncertainty</a>
<a href="part-iii-emergence-of-abstract-interactions.html">PART III: Emergence of Abstract Interactions</a>
<a href="ch-vecMat.html"><span class="toc-section-number">10</span> Vector and Matrix</a>
<a href="ch-MatComp.html"><span class="toc-section-number">11</span> Matrix Computation</a>
<a href="ch-eigen.html"><span class="toc-section-number">12</span> Eigenvalues and Eigenvectors</a>
<a id="active-page" href="ch-UnMulti.html"><span class="toc-section-number">13</span> Uncertainty in Multiple Dimensions</a><ul class="toc-sections">
<li class="toc"><a href="#sub:MultiVar"> Multivariate Distributions</a></li>
<li class="toc"><a href="#sub:Markov"> Stochastic Process and Markov’s Principle</a></li>
<li class="toc"><a href="#sub:rw"> Example: Forward and Backward Transitions and Random Walks</a></li>
<li class="toc"><a href="#sub:WLLN"> Miscellaneous: Statistical Inductive Inference, Law of Large Numbers, Bayes’ Law, and Falsifiability</a></li>
</ul>
<a href="part-iv-three-masons-to-illuminate-the-dual-world.html">PART IV: Three Masons to Illuminate the Dual World</a>
<a href="ch-representation.html"><span class="toc-section-number">14</span> Representation</a>
<a href="bibliography.html">Bibliography</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="ch:UnMulti" class="section level1">
<h1>
<span class="header-section-number">13</span> Uncertainty in Multiple Dimensions</h1>
<p>Our states are somehow dependent on and co-varies with our experiences, epistemic and aesthetic norms, or, more generally, our changeable roles in this world. On the other hand, the world has various paradigms, cultures, and belief systems that attribute different values to an individual’s state. Interference with the world could make one’s state an uncertain object.</p>
<p>In reality, when we consider the uncertainty of multiple <a href="sub-incomplete.html#sub:beyond2">random events</a> ahead that co-vary with each other, we tend to find out a law to characterize these events in a unified way. It turns out that vectors and matrices are indispensable to construct the characterizations for this joint venture.</p>
<div id="sub:MultiVar" class="section level2">
<h2>
<span class="header-section-number">13.1</span> Multivariate Distributions</h2>
<p>The previous examples in section <a href="ch-eigen.html#sub:matNorms">12.4</a> of data vectors didn’t involve any discussion about uncertainty.
In reality, most datasets contain (more or less) some random features. When uncertainty enters one’s concern, one may think that behind all the uncertain random events lie certain probabilities laws. The event which one actually observes in a single instance could always be referred to as a collection of events that might have happened. In other words, if one observes a single event, say <span class="math inline">\(x_t\)</span> at time <span class="math inline">\(t\)</span> from a random experiment, it is possible that at time <span class="math inline">\(t\)</span> the experiment can generate a set of possible outcomes. It is by chance that the value <span class="math inline">\(x_t\)</span> was generated, but if the experiment runs in a “parallel” world at time <span class="math inline">\(t\)</span>, the outcome <span class="math inline">\(x_t\)</span> could be different from the current one.<label for="tufte-sn-245" class="margin-toggle sidenote-number">245</label><input type="checkbox" id="tufte-sn-245" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">245</span> This argument relates to the <strong>many-worlds interpretation</strong> or <strong>many-minds interpretation</strong> in quantum mechanics where nondeterministic observations root in the system that “selects” a single value in the range of possible values.</span></p>
<p>By this argument, we can treat <span class="math inline">\(x_t\)</span> at every time <span class="math inline">\(t\)</span> as a realization of a random variable <span class="math inline">\(X_t(\omega)\)</span>. And since the time series data vector contains a series of realizations, say <span class="math inline">\([x_1,\dots,x_T]^\top\)</span>, we have to consider this whole vector to be a realization from a <em>random vector</em> <span class="math inline">\(\mathbf{X}(\omega) =[X_1(\omega),\dots,X_T(\omega)]^\top\)</span>.<label for="tufte-sn-246" class="margin-toggle sidenote-number">246</label><input type="checkbox" id="tufte-sn-246" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">246</span> The <span class="math inline">\(\omega\)</span>, as the use in chapter <a href="ch-CalUn.html#sub:conProb">9.4</a>, stands for a deeper invisible state that generates the outcome of the random variable.</span> Any attempt to understand the underlying law of such data vectors becomes an attempt to understand the underlying <a href="ch-CalUn.html#sub:conProb">joint probability</a> law of <span class="math inline">\(X_1(\omega),\dots,X_T(\omega)\)</span>, namely <span class="math inline">\(\mathbb{P}(X_1,\dots,X_T)\)</span>.</p>
<p>The <a href="ch-CalUn.html#sub:rv">probability distribution</a> referring to a joint probability of a <strong>random vector</strong> is called the <em>multivariate distribution</em>. We explore some of the <strong>multivariate distribution</strong> properties through one of the most important multivariate distributions, the <strong>multivariate normal (Gaussian) distribution</strong>. Recall that a <a href="ch-CalUn.html#sub:divRV">standard normal random variable</a> <span class="math inline">\(X\sim \mathcal{N}(0,1)\)</span> has the density function <span class="math inline">\(f(x)=\frac{1}{\sqrt{2\pi}}\exp(x^2)\)</span> for <span class="math inline">\(x\in\mathbb{R}\)</span>. Now let <span class="math inline">\(X_1(\omega),\dots X_T(\omega) \sim \mathcal{N}(0,1)\)</span> be <a href="ch-CalUn.html#sub:divRV">independent random variables</a>. The <strong>joint density</strong> of such a vector <span class="math inline">\(\mathbf{X}(\omega)=[X_1(\omega),\dots,X_T(\omega)]^\top\)</span> is
<span class="math display">\[
\begin{align*}
f(\mathbf{x})&amp;=\prod_{t=1}^{T}f(x_{t})=\frac{1}{(2\pi)^{T/2}}\exp\left\{ -\frac{1}{2}\sum_{t=1}^{T}x_{t}\right\} \\ &amp;=\frac{1}{(2\pi)^{T/2}}\exp\left\{ -\frac{1}{2}\mathbf{x}^{\top}\mathbf{x}\right\}.
\end{align*}
\]</span> which is the <em>standard multivariate normal density</em>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:mvn3D"></span>
<img src="fig/Part3/mvn3D.png" alt="Joint density of two independent normal random variables " width="100%"><!--
<p class="caption marginnote">-->Figure 13.1: Joint density of two independent normal random variables <!--</p>-->
<!--</div>--></span>
</p>
<p>The <a href="#sub:divRv">independence</a> property splits the joint density into the product of individual densities <span class="math inline">\(f(\mathbf{x})=\prod_{t=1}^{T}f(x_{t})\)</span>. The assumption of independence may be violated in many situations. In the dynamical environments, an event <span class="math inline">\(X_{t}(\omega)\)</span> is followed by another event <span class="math inline">\(X_{t+1}(\omega)\)</span>, so it is natural to think that the <a href="sub-inferknow.html#sub:dyn">arrow of time</a> attaches some kind of the dependent chain between these two successive events. From another perspective, when one suspects that interaction happened between <span class="math inline">\(Y(\omega)\)</span> and <span class="math inline">\(X(\omega)\)</span>, it is natural to treat <span class="math inline">\(Y(\omega)\)</span> and <span class="math inline">\(X(\omega)\)</span> jointly as a vector and assume some degree of dependence between these two random elements.<label for="tufte-sn-247" class="margin-toggle sidenote-number">247</label><input type="checkbox" id="tufte-sn-247" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">247</span> Essentially, since we consider that the variables <span class="math inline">\(\{X_1(\omega),\dots,X_T(\omega)\}\)</span> or <span class="math inline">\(\{Y(\omega), X(\omega)\}\)</span> depend on the same invisible state <span class="math inline">\(\omega\)</span>, the dependence may come with the underlying features that are shared by all the variables generated by <span class="math inline">\(\omega\)</span>.</span> For example, the <a href="ch-CalUn.html#sub:conProb">conditional structure</a> <span class="math inline">\(Y|X\)</span> used in <a href="ch-CalUn.html#sub:conProb">probabilistic causation</a> simply assumes the dependence exists.<label for="tufte-sn-248" class="margin-toggle sidenote-number">248</label><input type="checkbox" id="tufte-sn-248" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">248</span> If <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are independent, then the conditional probability <span class="math display">\[
\begin{align*}
\mathbb{P}(Y|X)= \frac{\mathbb{P}(X,Y)}{\mathbb{P}(X)}\\
=\frac{\mathbb{P}(X)\mathbb{P}(Y)}{\mathbb{P}(X)}=\mathbb{P}(Y)
\end{align*}
\]</span> will not reveal any convincing <a href="ch-CalUn.html#sub:conProb">causal relation</a> between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>.</span></p>
<p><a href="#sub:divRv">Dependence</a> or <a href="#sub:divRv">independence</a> is a condition regarding the joint probability law. For any normal distributed random variable <span class="math inline">\(X\sim \mathcal{N}(\mu,\sigma^2)\)</span>, the whole distribution is characterized by the <a href="ch-CalUn.html#sub:ex">mean</a> <span class="math inline">\(\mu\)</span> and the <a href="ch-CalUn.html#sub:ex">variance</a> <span class="math inline">\(\sigma^2\)</span>, namely a first and a second order information criterion respectively. The <strong>covariance</strong> is a second order information criterion to depict the dependence between any two <a href="#sub:divRv">random variables</a>. Furthermore, the <strong>covariance matrix</strong> of any random vector <span class="math inline">\(\mathbf{X}(\omega)\)</span> gives a characterization of the <a href="#sub:divRv">dependence</a> amongst any two random variables <span class="math inline">\(X_i, X_j\)</span> of the vector <span class="math inline">\(\mathbf{X}(\omega)\)</span>.</p>
<ul>
<li>
<em>Covariance</em>, <em>correlation</em>, and <em>multivariate normal density</em> : Let <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_j\)</span> be random variables with means <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\mu_j\)</span> and variance <span class="math inline">\(\sigma_i^2\)</span> and <span class="math inline">\(\sigma_j^2\)</span>. The <strong>covariance</strong> between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_j\)</span> is given by
<span class="math display">\[\mbox{Cov} (X_i , X_j) = \mbox{Cov} (X_j , X_i) =\mathbb{E}[(X_i-\mu_i)(X_j-\mu_j)],\]</span>
and the <strong>correlation</strong> between <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_j\)</span> is defined by
<span class="math display">\[\rho_{ij} = \rho_{ji} = \frac{\mbox{Cov}(X_i,X_j)}{\sigma_i \sigma_j}.\]</span> The <strong>covariance matrix</strong> random vector <span class="math inline">\(\mathbf{X}(\omega)=[X_1, \dots, X_T]^\top\)</span> is given by
<span class="math display">\[
\begin{align*}
\mbox{Var}(\mathbf{X}(\omega))&amp;=\left[\begin{array}{cccc}
\mbox{Var}X_{1} &amp; \mbox{Cov}(X_{1},X_{2}) &amp; \cdots &amp; \mbox{Cov}(X_{1},X_{T})\\
\mbox{Cov}(X_{2},X_{1}) &amp; \mbox{Var}X_{2} &amp; \cdots &amp; \mbox{Cov}(X_{2},X_{T})\\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
\mbox{Cov}(X_{T},X_{1}) &amp; \mbox{Cov}(X_{T},X_{2}) &amp; \cdots &amp; \mbox{Var}X_{T}
\end{array}\right]
\\
&amp;=\left[\begin{array}{cccc}
\sigma_{1}^{2} &amp; \sigma_{12} &amp;  &amp; \sigma_{1T}\\
\sigma_{21} &amp; \sigma_{2}^{2} &amp;  &amp; \sigma_{2T}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\sigma_{T1} &amp; \sigma_{T2} &amp; \cdots &amp; \sigma_{T}^{2}
\end{array}\right]=\left[\begin{array}{ccc}
\sigma_{1}^{2} &amp; \rho_{12}\sigma_{1}\sigma_{2} &amp; \dots\\
\rho_{12}\sigma_{1}\sigma_{2} &amp; \sigma_{2}^{2} &amp; \dots\\
\vdots &amp; \vdots &amp; \ddots
\end{array}\right]=\Sigma
\end{align*}
\]</span>
</li>
</ul>
<p>Suppose any <span class="math inline">\(X_i\)</span> in <span class="math inline">\(\mathbf{X}(\omega)\)</span> is a normal random variable. In this case, <span class="math inline">\(\mathbf{X}(\omega)\)</span> follows the <em>multivariate normal distribution</em> such that
<span class="math inline">\(\mathbf{X}(\omega)\sim\mathcal{N}\left(\mathbf{\mu},\:\Sigma\right)\)</span>, where <span class="math inline">\(\mathbf{\mu}=[\mu_1,\dots,\mu_T]^\top\)</span> is the <em>mean vector</em>, namely <span class="math inline">\(\mathbf{\mu}\)</span>, and <span class="math inline">\(\Sigma\)</span> is the <strong>covariance matrix</strong>. The density function of <span class="math inline">\(\mathbf{X}(\omega)\)</span> is given by <span class="math display">\[f(\mathbf{x})=\frac{1}{(2\pi)^{T/2}|\Sigma|^{1/2}}\exp\left\{ -\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^{\top}\Sigma^{-1}(\mathbf{x}-\mathbf{\mu})\right\}.\]</span></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:mvn"></span>
<img src="fig/Part3/mvn.gif" alt="Correlation (dependence pattern) changes of a bivariate normal density " width="100%"><!--
<p class="caption marginnote">-->Figure 13.2: Correlation (dependence pattern) changes of a bivariate normal density <!--</p>-->
<!--</div>--></span>
</p>
<p>It is easy to show that for any real vector <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span> and the <strong>random vector</strong> <span class="math inline">\(\mathbf{X}(\omega) \sim \mathcal{N}(\mathbf{\mu}, \Sigma)\)</span>, the expectation and <strong>(co)variance</strong> operation for a <a href="ch-vecMat.html#sub:linearity">linear/affine transformation</a> have the following results <span class="math inline">\(\mathbb{E}[\mathbf{a}^\top \mathbf{X}(\omega) + \mathbf{b}]=\mathbf{a}^\top \mathbf{\mu} + \mathbf{b}\)</span>, and <span class="math inline">\(\mbox{Var}(\mathbf{a}^\top \mathbf{X}(\omega) + \mathbf{b})=\mathbf{a}^\top \Sigma \mathbf{a}\)</span>. These results are analogous to those in the scalar cases. One can extend the results for any real matrix <span class="math inline">\(\mathbf{A}\)</span>: <span class="math inline">\(\mathbb{E}[\mathbf{A} \mathbf{X}(\omega)]=\mathbf{A} \mathbf{\mu}\)</span>, and <span class="math inline">\(\mbox{Var}(\mathbf{A} \mathbf{X}(\omega))=\mathbf{A} \Sigma\mathbf{A}^\top\)</span>.
These relations indicate that it is possible to construct any <strong>multivariate normal distribution</strong> by the <strong>standard</strong> one. The idea is to decompose the covariance matrix as a product, i.e.,
<span class="math inline">\(\Sigma=\mathbf{A}\mathbf{A}^\top\)</span>. With this decomposition, we can represent any <span class="math inline">\(\mathbf{X}(\omega) \sim \mathcal{N}(\mathbf{\mu}, \Sigma)\)</span> by <span class="math display">\[ \mathbf{A}\mathbf{W}(\omega) + \mathbf{\mu},\,\, \mbox{ where } \mathbf{W}(\omega) \sim \mathcal{N}(0, \mathbf{I})\]</span>
where <span class="math inline">\(\mathbf{W}(\omega)\)</span> is the <strong>standard multivariate normal random vector</strong>. The decomposition <span class="math inline">\(\Sigma=\mathbf{A}\mathbf{A}^\top\)</span> utilizes several properties of the <strong>covariance matrix</strong>. We are going to examine these properties one by one.</p>
<p>A critical property of the variance is that <span class="math inline">\(\mbox{Var}(X)&gt;0\)</span> for any random variable <span class="math inline">\(X\)</span>. The covariance of any two random variables can be either positive or negative because the dependence can come from a positive or negative relation. So we cannot say that all entries of the covariance matrix <span class="math inline">\(\mbox{Var}(\mathbf{X}(\omega))\)</span> are positive. But <span class="math inline">\(\mathbf{a}^\top \Sigma \mathbf{a}\)</span> must be non-negative for any real non-zero vector <span class="math inline">\(\mathbf{a}\)</span>.<label for="tufte-sn-249" class="margin-toggle sidenote-number">249</label><input type="checkbox" id="tufte-sn-249" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">249</span> Otherwise, we may have <span class="math inline">\(a^2_i\mbox{Var}(X_i)&lt;0\)</span> at some entry <span class="math inline">\(X_i\)</span>. As <span class="math inline">\(a^2_i\)</span> is non-negative, we have <span class="math inline">\(\mbox{Var}(X_i)&lt;0\)</span> for a random variable <span class="math inline">\(X_i\)</span>. This result contradicts with the property of the variance operator.</span> Any matrix satisfying <span class="math inline">\(\mathbf{a}^\top \Sigma \mathbf{a}\geq 0\)</span> for non-zero real vector <span class="math inline">\(\mathbf{a}\)</span> is called a <em>positive semi-definite matrix</em>.<label for="tufte-sn-250" class="margin-toggle sidenote-number">250</label><input type="checkbox" id="tufte-sn-250" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">250</span>  If <span class="math inline">\(\mathbf{a}^\top \Sigma \mathbf{a}&gt; 0\)</span> for all non-zero <span class="math inline">\(\mathbf{a}\)</span>, then <span class="math inline">\(\Sigma\)</span> is <em>positive definite</em>.</span></p>
<p>The <a href="ch-eigen.html#sub:det">eigenvalues</a> of the <strong>positive (semi-)definite matrix</strong> are real positive numbers.
Let <span class="math inline">\(\lambda\)</span> be an eigenvalue of <span class="math inline">\(\Sigma\)</span>, and let <span class="math inline">\(\Sigma \mathbf{v}=\lambda \mathbf{v}\)</span> for some non-zero <a href="ch-eigen.html#sub:det">eigenvector</a> <span class="math inline">\(\mathbf{v}\)</span>. It is obvious to see that <span class="math display">\[\mathbf{v}^{\top}\Sigma\mathbf{v}=\mathbf{v}^{\top}\lambda \mathbf{v}=\lambda\|\mathbf{v}\|^{2}.\]</span> As <span class="math inline">\(\mathbf{v}^{\top}\Sigma\mathbf{v}\geq 0\)</span> by the definition of a <strong>positive (semi-)definite matrix</strong>, <span class="math inline">\(\lambda\|\mathbf{v}\|^{2}\geq 0\)</span>. Because <span class="math inline">\(\|\mathbf{v}\|^{2}\geq 0\)</span>, we can see that <span class="math inline">\(\lambda\)</span> is a real positive number.</p>
<p>In addition, we can see that the <strong>covariance matrix</strong> <span class="math inline">\(\Sigma\)</span> is <a href="#sub:">symmetric</a>. Recall that <a href="ch-eigen.html#sub:diag">eigenvalue-eigenvector decomposition</a> <span class="math inline">\(\Sigma=\mathbf{V}\Lambda \mathbf{V}^{-1}\)</span> where <span class="math inline">\(\Lambda\)</span> is the <a href="ch-eigen.html#sub:diag">diagonal eigenvalue matrix</a>. By the <a href="#sub:">transposed operations</a>, we have <span class="math display">\[\Sigma^\top=(\mathbf{V}\Lambda \mathbf{V}^{-1})^\top = (\mathbf{V}^{-1})^\top \Lambda (\mathbf{V})^\top\]</span> where <span class="math inline">\(\Lambda=\Lambda^\top\)</span> by the diagonal property. The symmetry of <span class="math inline">\(\Sigma\)</span> gives
<span class="math inline">\(\mathbf{V}\Lambda \mathbf{V}^{-1}=(\mathbf{V}^{-1})^\top \Lambda (\mathbf{V})^\top\)</span> or say
<span class="math display">\[\Lambda = \left(\mathbf{V}^{-1}(\mathbf{V}^{-1})^\top\right) \Lambda \left(\mathbf{V}^\top\mathbf{V}\right).\]</span> One can infer that <span class="math inline">\(\mathbf{V}^\top\mathbf{V}=\mathbf{I}\)</span> or <span class="math inline">\(\mathbf{V}^\top =\mathbf{V}^{-1}\)</span>. In other words, for a symmetric square matrix of real-valued entries, the eigenvector matrix <span class="math inline">\(\mathbf{V}\)</span> is <em>orthonormal</em>
<span class="math inline">\(\mathbf{V}^\top\mathbf{V}=\mathbf{I}\)</span>; namely, all vectors in <span class="math inline">\(\mathbf{V}\)</span> are mutually orthogonal and all of the unit length.<label for="tufte-sn-251" class="margin-toggle sidenote-number">251</label><input type="checkbox" id="tufte-sn-251" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">251</span> Any two vectors <span class="math inline">\(\mathbf{v}_i, \mathbf{v}_j\)</span> in the matrix <span class="math inline">\(\mathbf{V}\)</span> are <a href="ch-vecMat.html#sub:vec">orthogonal</a> <span class="math inline">\(\mathbf{v}_i^\top \mathbf{v}_j=\left\langle \mathbf{v}_{i},\mathbf{v}_{j}\right\rangle =0\)</span>. The norm of any vector in <span class="math inline">\(\mathbf{V}\)</span> is one: <span class="math inline">\(\|\mathbf{v}_i\|=\sqrt{\left\langle \mathbf{v}_{i},\mathbf{v}_{i}\right\rangle}=1\)</span>.</span></p>
<p>Now we can rewrite <span class="math inline">\(\Sigma=\mathbf{V}\Lambda \mathbf{V}^{-1}\)</span> as <span class="math inline">\(\Sigma=\mathbf{V}\Lambda \mathbf{V}^\top\)</span>. Since <span class="math inline">\(\Lambda\)</span> is a diagonal matrix with real positive entries <span class="math inline">\(\{\lambda_i\}\)</span>, we can represent <span class="math inline">\(\Lambda\)</span> by <span class="math inline">\(\Lambda=\mathbf{S}\mathbf{S}\)</span> where <span class="math inline">\(\mathbf{S}\)</span> is also a diagonal matrix with real positive entries <span class="math inline">\(\{\sqrt{\lambda_i}\}\)</span>. Then the covariance matrix becomes
<span class="math display">\[\Sigma=\mathbf{V}\mathbf{S}\mathbf{S}^\top \mathbf{V}^\top=(\mathbf{V}\mathbf{S})(\mathbf{V}\mathbf{S})^\top.\]</span> Let’s denote <span class="math inline">\(\mathbf{V}\mathbf{S}\)</span> by <span class="math inline">\(\mathbf{A}\)</span>. We have the desired result <span class="math inline">\(\Sigma=\mathbf{A}\mathbf{A}^\top\)</span>. The result is called the <em>Cholesky decomposition</em>. It says that any symmetric <strong>positive semi-definite</strong> matrix <span class="math inline">\(\Sigma\)</span> can be decomposed as a product of one matrix <span class="math inline">\(\mathbf{A}\)</span> and its transpose <span class="math inline">\(\mathbf{A}^\top\)</span>.<label for="tufte-sn-252" class="margin-toggle sidenote-number">252</label><input type="checkbox" id="tufte-sn-252" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">252</span> Such a matrix <span class="math inline">\(\mathbf{A}\)</span> is analogous to the matrix version square root of a “positive” <span class="math inline">\(\Sigma\)</span>. Unlike a real positive number, whose expression of a square root is unique, the “square root” of <span class="math inline">\(\Sigma\)</span> does not have a unique representation. For example, if one selects an <strong>orthonormal</strong> matrix <span class="math inline">\(\mathbf{U}\)</span> such that <span class="math inline">\(\mathbf{U}\mathbf{U}^\top = \mathbf{I}\)</span>, then <span class="math display">\[\Sigma = \mathbf{A}\mathbf{A}^\top=\mathbf{A}\mathbf{I}\mathbf{A}^\top=(\mathbf{A}\mathbf{U})(\mathbf{A}\mathbf{U})^\top\]</span> is also a valid representation for <span class="math inline">\(\Sigma\)</span>.</span></p>
<p>The multivariate normal distribution of <span class="math inline">\(\mathbf{X}(\omega)\)</span> gives a full description of the dependent structure amongst all normal random variables in the random vector <span class="math inline">\(\mathbf{X}(\omega)\)</span>. With the joint probability law, we can derive other useful dependent structures. For example, the <a href="ch-CalUn.html#sub:conProb">conditional probability</a> can induce the <a href="ch-CalUn.html#sub:conProb">probabilistic causal relation</a> as the conditional probability law implicitly treats the conditions as the (probabilistic) cause.</p>
<p>The calculation of multivariate conditional probability is non-trivial. Take a <span class="math inline">\(2N\)</span>-dimensional <strong>multivariate normal random vector</strong> as an example. By splitting the vector into two subvectors, we have the following expression for the joint density
<span class="math display">\[
\begin{bmatrix}
 \mathbf{Y}(\omega) \\
 \mathbf{X}(\omega)
\end{bmatrix} \sim \mathcal{N} \left( \begin{bmatrix}
 \mathbf{\mu_y} \\
 \mathbf{\mu_x}
\end{bmatrix}
,  \begin{bmatrix}
 \Sigma_{11} &amp; \Sigma_{12} \\
 \Sigma_{21} &amp; \Sigma_{22}
\end{bmatrix}
 \right)
\]</span>
where <span class="math inline">\(\Sigma_{11}\)</span>, <span class="math inline">\(\Sigma_{22}\)</span> are the <strong>covariance matrices</strong> of the random vectors <span class="math inline">\(\mathbf{Y}(\omega)\)</span> and <span class="math inline">\(\mathbf{X}(\omega)\)</span>, respectively, and <span class="math inline">\(\Sigma_{12} = \Sigma_{21}\)</span> is <span class="math inline">\(\mbox{Cov}(\mathbf{Y}(\omega), \mathbf{X}(\omega))\)</span>.</p>
<p>If we want to calculate the conditional density <span class="math inline">\((\mathbf{Y}|\mathbf{X})(\omega)\)</span>, then in principle we need to compute <span class="math inline">\(f(\mathbf{y}|\mathbf{x})=f(\mathbf{y}, \mathbf{x})/f(\mathbf{x})\)</span>.<label for="tufte-sn-253" class="margin-toggle sidenote-number">253</label><input type="checkbox" id="tufte-sn-253" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">253</span> The full expression of the joint density function <span class="math inline">\(f(\mathbf{y}, \mathbf{x})\)</span> contains the term
<span class="math display">\[  \left[\begin{array}{c}
\mathbf{y}-\mathbf{\mu_{y}}\\
\mathbf{x}-\mathbf{\mu_{x}}
\end{array}\right]^\top\left[\begin{array}{cc}
\Sigma_{11} &amp; \Sigma_{12}\\
\Sigma_{21} &amp; \Sigma_{22}
\end{array}\right]^{-1}\left[\begin{array}{c}
\mathbf{y}-\mathbf{\mu_{y}}\\
\mathbf{x}-\mathbf{\mu_{x}}
\end{array}\right]
\]</span>
which requires to evaluate the inversion of the block matrices.</span> Rather than fully involved in the conditional density’s derivation, we give the direct
results of the <strong>conditional vector mean</strong> and <strong>conditional covariance matrix</strong>, and then consider why such results make sense.
<span class="math display">\[
\begin{align*}
\mathbb{E}[\mathbf{Y}(\omega) | \mathbf{X}(\omega)=\mathbf{x}]&amp;=
\mathbf{\mu_y} + \Sigma_{12} \Sigma_{22}^{-1}
\left(
 \mathbf{x} - \mathbf{\mu_x}
\right),\\
\mbox{Var}[\mathbf{Y}(\omega) | \mathbf{X}(\omega) =\mathbf{x}]
&amp;=
\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}.
\end{align*}
\]</span>
The results show that the conditioning vector <span class="math inline">\(\mathbf{x}\)</span> will adjust the first and the second-moment information criteria of dependent vector <span class="math inline">\(\mathbf{Y}(\omega)\)</span>.</p>
<p>This conditional covariance matrix <span class="math inline">\(\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1}\Sigma_{21}\)</span> is the <a href="ch-MatComp.html#sub:LU">Schur complement</a> of <span class="math inline">\(\Sigma_{22}\)</span>. Similar to the <a href="ch-MatComp.html#sub:LU">block LU factorization</a>, such a term is to eliminate the covariance blocks corresponding to the variables being conditioned upon. The main instrument <span class="math inline">\(\Sigma_{12} \Sigma_{22}^{-1}\)</span> is to eliminate the dependence caused by <span class="math inline">\(\mathbf{X}(\omega)\)</span>.</p>
<div class="solution">
<p class="solution-begin">
Proof of the elimination <span id="sol-start-56" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-56', 'sol-start-56')"></span>
</p>
<div id="sol-body-56" class="solution-body" style="display: none;">
<p>First, we show that the covariance <span class="math inline">\(\mbox{Var}[\mathbf{Y}(\omega) | \mathbf{X}(\omega)]=\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}\)</span> is the Schur complement. That is to show <span class="math inline">\(\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1}\Sigma_{21}= \mbox{Var}[\mathbf{Y}(\omega)+\Sigma_{12} \Sigma_{22}^{-1}\mathbf{X}(\omega)]\)</span>. To see this,
<span class="math display">\[
\begin{align*}
&amp;\mbox{Var}[\mathbf{Y}(\omega)+\Sigma_{12} \Sigma_{22}^{-1}\mathbf{X}(\omega)]\\
=&amp;\mbox{Var}(\mathbf{Y}(\omega))+\Sigma_{12} \Sigma_{22}^{-1}\mbox{Var}(\mathbf{X}(\omega))(\Sigma_{12} \Sigma_{22}^{-1})^{\top}\\
&amp;+\Sigma_{12} \Sigma_{22}^{-1}\mbox{Cov}(\mathbf{Y}(\omega),\,\mathbf{X}(\omega))+\mbox{Cov}(\mathbf{X}(\omega),\,\mathbf{Y}(\omega))(\Sigma_{12} \Sigma_{22}^{-1})^{\top}\\
=&amp; \Sigma_{11}+\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{22}\Sigma_{22}^{-1}\Sigma_{21}-2\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21} \\
=&amp; \Sigma_{11}+\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}-2\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21} \\
=&amp; \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1}\Sigma_{21}.
\end{align*}
\]</span>
On the other hand, we can see that
<span class="math display">\[
\begin{align*}\mbox{Cov}(\mathbf{Y}(\omega)+\Sigma_{12}\Sigma_{22}^{-1}\mathbf{X}(\omega),\:\mathbf{X}(\omega)) &amp; =\mbox{Cov}(\mathbf{Y}(\omega),\:\mathbf{X}(\omega))+\mbox{Cov}(\Sigma_{12}\Sigma_{22}^{-1}\mathbf{X}(\omega),\:\mathbf{X}(\omega))\\
 &amp; =\Sigma_{12}+\Sigma_{12}\Sigma_{22}^{-1}\mbox{Cov}(\mathbf{X}(\omega),\:\mathbf{X}(\omega))\\
 &amp; =\Sigma_{12}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{22}\\
 &amp; =0.
\end{align*}
\]</span>
So the term <span class="math inline">\(\mathbf{Y}(\omega)+\Sigma_{12}\Sigma_{22}^{-1}\mathbf{X}(\omega)\)</span> gets rid of the dependence of conditional vector <span class="math inline">\(\mathbf{X}(\omega)\)</span> by eliminating the effects of <span class="math inline">\(\Sigma_{22}\)</span> and <span class="math inline">\(\Sigma_{12}=\Sigma_{21}\)</span>.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The conditional results of the mean vector and covariance matrix serve the foundation of estimating a dynamical system adaptively. We will see in [?]. For now, a quick application is to use the conditional results to recover the joint density.<label for="tufte-sn-254" class="margin-toggle sidenote-number">254</label><input type="checkbox" id="tufte-sn-254" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">254</span> Any two dependent random variables <span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_1\)</span> have the expression
<span class="math display">\[\mathbb{P}(X_2, X_1)=\mathbb{P}(X_2\,|\,X_1)\mathbb{P}(X_1),\]</span>
which tells how to compute the joint by the conditionals.</span></p>
<div class="solution">
<p class="solution-begin">
Simulate the bivariate normal random vector <span id="sol-start-57" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-57', 'sol-start-57')"></span>
</p>
<div id="sol-body-57" class="solution-body" style="display: none;">
<p>If <span class="math inline">\(X_2\sim \mathcal{N}(\mu_2,\sigma_2^2)\)</span> and <span class="math inline">\(X_1 \sim \mathcal{N}(\mu_1,\sigma_1^2)\)</span> are normal random variables, then <span class="math inline">\(\mathbb{P}(X_2, X_1)=\mathbb{P}(X_2\,|\,X_1)\mathbb{P}(X_1)\)</span> becomes
<span class="math display">\[\mathcal{N}(\mu_\mbox{joint},\Sigma_\mbox{joint})=\mathcal{N}\left(\mu_2 + \frac{\rho\sigma_1}{\sigma_{2}}(x_1 - \mu_1),\, \sigma^2_{1}(1 - \rho^2)\right)\mathcal{N}(\mu_1,\sigma_1^2).\]</span>
Note that <span class="math inline">\(\Sigma_{11}=\sigma_1^2\)</span>, <span class="math inline">\(\Sigma_{12}=\Sigma_{21}=\rho\sigma_1\sigma_2\)</span>, <span class="math inline">\(\Sigma_{22}=\sigma_2^2\)</span>. We simplify the previous conditional mean and covariance expressions to the scalar case: the conditional mean
<span class="math display">\[\mu_2 + \rho\sigma_1\sigma_2 \sigma_{2}^{-2}(x_1 - \mu_1)=\mu_2 + \frac{\rho\sigma_1}{\sigma_{2}}(x_1 - \mu_1),\]</span>
and the conditional variance
<span class="math display">\[\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1}\Sigma_{21}= \sigma^2_{1} - (\rho\sigma_{1}\sigma_{2})^2 \sigma_{2}^{-2} =\sigma^2_{1}(1 - \rho^2).\]</span></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb40-2" data-line-number="2">rbvn=<span class="cf">function</span> (n, m1, s1, m2, s2, rho){</a>
<a class="sourceLine" id="cb40-3" data-line-number="3">     X1 =<span class="st"> </span><span class="kw">rnorm</span>(n, mu1, s1)</a>
<a class="sourceLine" id="cb40-4" data-line-number="4">     X2 =<span class="st"> </span><span class="kw">rnorm</span>(n, </a>
<a class="sourceLine" id="cb40-5" data-line-number="5">                mu2 <span class="op">+</span><span class="st"> </span>(s1<span class="op">/</span>s2) <span class="op">*</span><span class="st"> </span>rho <span class="op">*</span>(X1 <span class="op">-</span><span class="st"> </span>mu1), </a>
<a class="sourceLine" id="cb40-6" data-line-number="6">                <span class="kw">sqrt</span>((<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>rho<span class="op">^</span><span class="dv">2</span>)<span class="op">*</span>s1<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb40-7" data-line-number="7">     <span class="kw">cbind</span>(X1, X2)}</a>
<a class="sourceLine" id="cb40-8" data-line-number="8">mu1 =<span class="st"> </span><span class="dv">1</span>; sigma1 =<span class="st"> </span><span class="dv">2</span>; mu2 =<span class="st"> </span><span class="dv">4</span>; sigma2 =<span class="st"> </span><span class="dv">2</span></a>
<a class="sourceLine" id="cb40-9" data-line-number="9">rho =<span class="st"> </span><span class="fl">-0.2</span>; n =<span class="st"> </span><span class="dv">1000</span>;</a>
<a class="sourceLine" id="cb40-10" data-line-number="10">bvn =<span class="st"> </span><span class="kw">rbvn</span>(n,mu1,sigma1,mu2,sigma2,rho)</a>
<a class="sourceLine" id="cb40-11" data-line-number="11"></a>
<a class="sourceLine" id="cb40-12" data-line-number="12"></a>
<a class="sourceLine" id="cb40-13" data-line-number="13"><span class="co"># Plot</span></a>
<a class="sourceLine" id="cb40-14" data-line-number="14"></a>
<a class="sourceLine" id="cb40-15" data-line-number="15">bvn =<span class="st"> </span><span class="kw">data.frame</span>(bvn)</a>
<a class="sourceLine" id="cb40-16" data-line-number="16"></a>
<a class="sourceLine" id="cb40-17" data-line-number="17"><span class="kw">library</span>(ggplot2); <span class="kw">library</span>(gridExtra)</a>
<a class="sourceLine" id="cb40-18" data-line-number="18">htop =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>bvn, <span class="kw">aes</span>(<span class="dt">x=</span>X1)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-19" data-line-number="19"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..), <span class="dt">fill=</span><span class="st">"skyblue"</span>, <span class="dt">bins=</span><span class="dv">200</span>, <span class="dt">alpha=</span><span class="fl">0.8</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-20" data-line-number="20"><span class="st">  </span><span class="kw">stat_density</span>(<span class="dt">colour =</span> <span class="st">"blue"</span>, <span class="dt">geom=</span><span class="st">"line"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>())</a>
<a class="sourceLine" id="cb40-21" data-line-number="21"></a>
<a class="sourceLine" id="cb40-22" data-line-number="22">blank =<span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">colour=</span><span class="st">"white"</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb40-23" data-line-number="23"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks=</span><span class="kw">element_blank</span>(), <span class="dt">panel.background=</span><span class="kw">element_blank</span>(), <span class="dt">panel.grid=</span><span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb40-24" data-line-number="24">        <span class="dt">axis.text.x=</span><span class="kw">element_blank</span>(), <span class="dt">axis.text.y=</span><span class="kw">element_blank</span>(), <span class="dt">axis.title.x=</span><span class="kw">element_blank</span>(), <span class="dt">axis.title.y=</span><span class="kw">element_blank</span>())</a>
<a class="sourceLine" id="cb40-25" data-line-number="25"></a>
<a class="sourceLine" id="cb40-26" data-line-number="26">scatter =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>bvn, <span class="kw">aes</span>(<span class="dt">x=</span>X1, <span class="dt">y=</span>X2)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-27" data-line-number="27"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">col=</span><span class="st">"grey"</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-28" data-line-number="28"><span class="st">    </span><span class="kw">stat_ellipse</span>(<span class="dt">type =</span> <span class="st">"norm"</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb40-29" data-line-number="29"><span class="st">    </span><span class="kw">annotate</span>(<span class="dt">geom=</span><span class="st">"text"</span>, <span class="dt">x=</span><span class="dv">6</span>, <span class="dt">y=</span><span class="dv">8</span>, <span class="dt">label=</span><span class="st">"rho=-0.2"</span>,</a>
<a class="sourceLine" id="cb40-30" data-line-number="30">              <span class="dt">color=</span><span class="st">"red"</span>) <span class="op">+</span><span class="st">  </span><span class="kw">theme_minimal</span>()</a>
<a class="sourceLine" id="cb40-31" data-line-number="31"></a>
<a class="sourceLine" id="cb40-32" data-line-number="32">hright =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>bvn, <span class="kw">aes</span>(<span class="dt">x=</span>X2)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-33" data-line-number="33"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..), <span class="dt">fill=</span><span class="st">"skyblue"</span>, <span class="dt">bins=</span><span class="dv">200</span>, <span class="dt">alpha=</span><span class="fl">0.8</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-34" data-line-number="34"><span class="st">  </span><span class="kw">stat_density</span>(<span class="dt">colour =</span> <span class="st">"blue"</span>, <span class="dt">geom=</span><span class="st">"line"</span>) <span class="op">+</span><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">axis.title.y =</span> <span class="kw">element_blank</span>())</a>
<a class="sourceLine" id="cb40-35" data-line-number="35"></a>
<a class="sourceLine" id="cb40-36" data-line-number="36"><span class="kw">grid.arrange</span>(htop, blank, scatter, hright, <span class="dt">ncol=</span><span class="dv">2</span>, <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">widths=</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">1</span>), <span class="dt">heights=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>))</a>
<a class="sourceLine" id="cb40-37" data-line-number="37"></a>
<a class="sourceLine" id="cb40-38" data-line-number="38"></a>
<a class="sourceLine" id="cb40-39" data-line-number="39"><span class="co">### 3D plot</span></a>
<a class="sourceLine" id="cb40-40" data-line-number="40">x =<span class="st"> </span><span class="kw">seq</span>( <span class="dv">-3</span>, <span class="dv">3</span>, <span class="dt">length=</span><span class="dv">25</span> ); y =<span class="st"> </span><span class="kw">seq</span>( <span class="dv">-3</span>, <span class="dv">3</span>, <span class="dt">length=</span><span class="dv">25</span> )</a>
<a class="sourceLine" id="cb40-41" data-line-number="41">xy =<span class="st"> </span><span class="kw">outer</span>( x, y, <span class="cf">function</span>(x,y) <span class="kw">dnorm</span>(x,<span class="dv">0</span>,<span class="fl">0.75</span>)<span class="op">*</span><span class="kw">dnorm</span>(y,<span class="dv">0</span>,<span class="fl">0.5</span>) )</a>
<a class="sourceLine" id="cb40-42" data-line-number="42">plot<span class="fl">.3</span>D =<span class="st"> </span><span class="kw">persp</span>(x,y,xy, <span class="dt">theta=</span><span class="dv">120</span>, <span class="dt">zlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">4</span><span class="op">*</span><span class="kw">max</span>(z)), <span class="dt">box=</span><span class="ot">FALSE</span>, <span class="dt">shade=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb40-43" data-line-number="43"><span class="co">## unconditional density for x</span></a>
<a class="sourceLine" id="cb40-44" data-line-number="44"><span class="kw">lines</span>( <span class="kw">trans3d</span>( <span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="dt">length=</span><span class="dv">100</span>), <span class="dv">-3</span>, <span class="kw">dnorm</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="dt">length=</span><span class="dv">100</span>),<span class="dv">0</span>,.<span class="dv">75</span>), </a>
<a class="sourceLine" id="cb40-45" data-line-number="45">    plot<span class="fl">.3</span>D), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">'blue'</span> )</a>
<a class="sourceLine" id="cb40-46" data-line-number="46"><span class="co">## unconditional density for y</span></a>
<a class="sourceLine" id="cb40-47" data-line-number="47"><span class="kw">lines</span>( <span class="kw">trans3d</span>( <span class="dv">-3</span>, <span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="dt">length=</span><span class="dv">100</span>), <span class="kw">dnorm</span>(<span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="dt">length=</span><span class="dv">100</span>),<span class="dv">0</span>,<span class="fl">0.5</span>), </a>
<a class="sourceLine" id="cb40-48" data-line-number="48">    plot<span class="fl">.3</span>D), <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">'blue'</span> )</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
</div>
<div id="sub:Markov" class="section level2">
<h2>
<span class="header-section-number">13.2</span> Stochastic Process and Markov’s Principle</h2>
<p>The sequence of random variables <span class="math inline">\(X_{1}(\omega),\dots X_{t}(\omega)\)</span> refers to a <strong>stochastic process</strong> if one wants to emphasize that the index of the sequence indicates the successive steps.</p>
<ul>
<li>
<em>Filtered space</em>, <em>stochastic process</em> : <strong>Filtered space</strong> is <span class="math inline">\((\Omega,\mathcal{F},\{\mathcal{F}_{t}\},P)\)</span> where <span class="math inline">\((\Omega,\mathcal{F},P)\)</span> is a <a href="sub-incomplete.html#sub:beyond2">probability space</a>, <span class="math inline">\(\{\mathcal{F}_{t}:t\geq0\}\)</span> is called the <em>filtration</em>, that is, an increasing family of <span class="math inline">\(\sigma\)</span>-algebras of <span class="math inline">\(\mathcal{F}\)</span> such that
<span class="math display">\[\mathcal{F}_{s}\subseteq\mathcal{F}_{t}\cdots\subseteq\mathcal{F}\]</span>
for all <span class="math inline">\(s&lt;t\)</span>. A <strong>stochastic process</strong>, <span class="math inline">\(\{X(t,\omega),\, t\in\mathbb{R}^{+}\}\)</span> for the continuous-time or <span class="math inline">\(\{X_{t}(\omega),\, t\in\mathbb{N}\}\)</span> for the discrete-time, is a collection of random variables defined on a <strong>filtered space</strong> <span class="math inline">\((\Omega,\mathcal{F},\{\mathcal{F}_{t}\},P)\)</span>.<label for="tufte-sn-255" class="margin-toggle sidenote-number">255</label><input type="checkbox" id="tufte-sn-255" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">255</span> More precisely, <span class="math inline">\(X(t,\omega)\)</span> or <span class="math inline">\(X_{t}(\omega)\)</span> is <span class="math inline">\(\mathcal{F}_{t}\)</span>-measurable with the <strong>filtration</strong>
<span class="math display">\[\mathcal{F}_{t}=\underset{\mbox{continuous time}}{\underbrace{\sigma\left(\{X_{\tau}\}_{0&lt;\tau\leq t}\right)}}\;\mbox{or }\\\mathcal{F}_{t}=\underset{\mbox{discrete time}}{\underbrace{\sigma(X_{0},X_{1},\dots,X_{t})}}.\]</span>
We also say <span class="math inline">\(\{X(t,\omega),\, t\in\mathbb{R}^{+}\}\)</span> or <span class="math inline">\(\{X_{t}(\omega),\, t\in\mathbb{N}\}\)</span> is <em>adapted</em> to the <strong>filtered space</strong> <span class="math inline">\((\Omega,\mathcal{F},\{\mathcal{F}_{t}\},P)\)</span>.</span>
</li>
</ul>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:rw"></span>
<img src="fig/Part3/rw.gif" alt="Three processes generated by the same probability law and the same initials but different deeper invisible states" width="100%"><!--
<p class="caption marginnote">-->Figure 13.3: Three processes generated by the same probability law and the same initials but different deeper invisible states<!--</p>-->
<!--</div>--></span>
</p>
<ul>
<li>
<em>State space</em> : From the calculus perspective (differential/difference equations), given the underlying <span class="math inline">\(\omega\)</span>, each variable <span class="math inline">\(X(t, \cdot)\)</span> or <span class="math inline">\(X_{t}(\cdot)\)</span> of the process is a <a href="ch-DE.html#sub:ode">state variable</a> over time <span class="math inline">\(t\)</span>. At any time <span class="math inline">\(t\)</span>, all possible <a href="ch-DE.html#sub:ode">states</a> of <span class="math inline">\(X(t, \omega)\)</span> belong to the <strong>state space</strong> <span class="math inline">\((\mathcal{X}, \sigma(\mathcal{X}))\)</span> where <span class="math display">\[\mathcal{X}:=\left\{x\,|\,X(t,\omega)=x,\:\omega\in\Omega, t\in \mathbb{R}^{+}\right\}\]</span> is the set of all possible <a href="ch-DE.html#sub:ode">states</a> (realizations) for <span class="math inline">\(X(t,\omega)\)</span>.<label for="tufte-sn-256" class="margin-toggle sidenote-number">256</label><input type="checkbox" id="tufte-sn-256" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">256</span> For the discrete time <span class="math inline">\(X_{t}(\cdot)\)</span>, the <strong>state space</strong> <span class="math inline">\((\mathcal{X}, \sigma(\mathcal{X}))\)</span> has a similar form with <span class="math inline">\(\mathcal{X}:=\left\{x\,|\,X_t(\omega)=x,\:\omega\in\Omega, t\in \mathbb{N}\right\}\)</span>.</span>
</li>
</ul>
<div class="solution">
<p class="solution-begin">
Discussion about the filter <span id="sol-start-58" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-58', 'sol-start-58')"></span>
</p>
<div id="sol-body-58" class="solution-body" style="display: none;">
<p>We can rigorously define the <strong>filter</strong> by set theory. Let <span class="math inline">\(\mathcal{F}\)</span> belong to the <a href="sub-axioms.html#sub:axSet">power set</a> of a <a href="sub-set-theory.html#sub:order">partially ordered set</a> <span class="math inline">\(\mathcal{G}\)</span>, namely <span class="math inline">\(\mathcal{F}\subset2^{\mathcal{G}}\)</span>, then <span class="math inline">\(\mathcal{F}\)</span> is a <em>filter</em> on <span class="math inline">\(\mathcal{G}\)</span> if <span class="math inline">\(\mathcal{F}\)</span> satisfies</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\textrm{Ø}\notin\mathcal{F}\)</span>, <span class="math inline">\(\mathcal{G}\in\mathcal{F}\)</span>;</p></li>
<li><p>(intersection-closed) if <span class="math inline">\(\mathcal{F}_{m},\mathcal{F}_{f}\in\mathcal{F}\)</span>, then <span class="math inline">\(\mathcal{F}_{m}\cap\mathcal{F}_{f}\in\mathcal{F}\)</span>;</p></li>
<li><p>(upward-closed) if <span class="math inline">\(\mathcal{F}_{m}\subset\mathcal{F}_{j}\subset\mathcal{G}\)</span> and <span class="math inline">\(\mathcal{F}_{m}\in\mathcal{F}\)</span>, then <span class="math inline">\(\mathcal{F}_{j}\in\mathcal{F}\)</span>.</p></li>
</ol>
<p>In other words, a <strong>filter</strong> selects a <a href="sub-set-theory.html#sub:order">partially ordered</a> subset that satisfies some given criterion (intersection-closed and upward-closed).</p>
<p>In the stochastic process, the <strong>filtration</strong> is a <strong>filter</strong> of <span class="math inline">\(\sigma\)</span>-<a href="sub-incomplete.html#sub:beyond2">algebra</a> that gradually selects the historical information to make the information compatible. That is, the information at time <span class="math inline">\(t\)</span> needs to be compatible with the existing one, namely <span class="math inline">\(\mathcal{F}_{s}\subset\mathcal{F}_{t}\)</span> for any <span class="math inline">\(s&lt;t\)</span>. The compatible historical information excludes the possibility of predicting <span class="math inline">\(\mathcal{F}_{t'}\)</span> for any <span class="math inline">\(t'&gt;t\)</span>. Thus, a process that is adapted to <strong>filtration</strong> is also called non-anticipating, i.e., one that cannot see into the future beyond the existing historical framework.<label for="tufte-sn-257" class="margin-toggle sidenote-number">257</label><input type="checkbox" id="tufte-sn-257" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">257</span> In sociology, the <strong>filter</strong> also refers to a dating or mating selector that can construct a compatible (similar and complementary) group of candidates for the marriages. Using the language of set theory, we consider all acceptable matching patterns of two persons as the power set <span class="math inline">\(\mathcal{G}\)</span>. Let the social filter <span class="math inline">\(\mathcal{F}\)</span>, the male’s taste <span class="math inline">\(\mathcal{F}_m\)</span>, the female’s taste <span class="math inline">\(\mathcal{F}_f\)</span>, and their tastes with the complement <span class="math inline">\(\mathcal{F}_c\)</span>. The (ideal) filter <span class="math inline">\(\mathcal{F}\)</span> selects a set given the following criteria:
1. Being single is not a choice (<span class="math inline">\(\textrm{Ø}\notin\mathcal{F}\)</span>). And the filter doesn’t exclude any acceptable matching (<span class="math inline">\(\mathcal{G}\in\mathcal{F}\)</span>);
2. Both sides’ tastes are similar from the filter’s perspective (if <span class="math inline">\(\mathcal{F}_{m},\mathcal{F}_{f}\in\mathcal{F}\)</span>, then <span class="math inline">\(\mathcal{F}_{m}\cap\mathcal{F}_{f}\in\mathcal{F}\)</span>);
3. The acceptable complementary taste is preserved by the filter (if <span class="math inline">\(\mathcal{F}_{m}, \mathcal{F}_f\subset\mathcal{F}_{c}\subset\mathcal{G}\)</span> and <span class="math inline">\(\mathcal{F}_{m}, \mathcal{F}_f\in\mathcal{F}\)</span>, then <span class="math inline">\(\mathcal{F}_{c}\in\mathcal{F}\)</span>).</span></p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>Roughly speaking, a <strong>stochastic process</strong> is a collection of random variables indexed by time <span class="math inline">\(t\)</span>.
A <strong>discrete-time stochastic process</strong> <span class="math inline">\(\{X_{1},\dots,X_{T}\}\)</span> is simply a <a href="ch-UnMulti.html#sub:MultiVar">random vector</a> whose random entries emerge following the <a href="sub-inferknow.html#sub:dyn">arrow of time</a>, namely a time series with random entities. However, the flowing time illuminates that the index number <span class="math inline">\(t\)</span> can grow, and that the time series may not remain at a modest size. In this case, the joint probability law <span class="math inline">\(\mathbb{P}(X_{1},\dots,X_{T})\)</span> may need to be characterized by a rather high dimensional <a href="ch-UnMulti.html#sub:MultiVar">multivariate distribution</a> if <span class="math inline">\(t\)</span> grows to a large enough number.<label for="tufte-sn-258" class="margin-toggle sidenote-number">258</label><input type="checkbox" id="tufte-sn-258" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">258</span> For example, a <span class="math inline">\(10\)</span>-dimensional <a href="ch-eigen.html#sub:matNorms">multivariate normal</a> joint density needs to specify <span class="math inline">\(55\)</span> entries of its <a href="ch-eigen.html#sub:matNorms">covariance matrix</a> (half of the off-diagonal entries are identical). That is to say; the computational complexity will grow exponentially as the dimension grows. Nowadays, the length of a simple data vector can easily go beyond <span class="math inline">\(10^{3}\)</span>.</span> The specification of the <a href="ch-CalUn.html#sub:conProb">joint probability law</a> in a high dimensional space may be so complex (in both theoretical and applicable aspects) that we need an alternative method to interpret the law.</p>
<p>One method of fighting with the growing complexity is to keep the law in a tractable representation by using <a href="ch-CalUn.html#sub:conProb">conditioning</a>.<label for="tufte-sn-259" class="margin-toggle sidenote-number">259</label><input type="checkbox" id="tufte-sn-259" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">259</span>  We can see that the <strong>filtration</strong> <span class="math inline">\(\{\mathcal{F}_{t}:t\leq T\}\)</span> is generated by <span class="math inline">\(\{ X_t(\omega) \}_{0&lt;t\leq T}\)</span>. Thus the dependent structure of the series <span class="math inline">\(\{ X_t(\omega) \}_{0&lt;t\leq T}\)</span> also comes from the conditioning of the historical information generated by <span class="math inline">\(\{ X_t(\omega) \}_{0&lt;t&lt; T}\)</span>.</span> Recall that in the simulation of the <a href="ch-UnMulti.html#sub:MultiVar">bivariate normal</a> random vector, we use two one-dimensional random variables by splitting the joint probability law into the conditionals, i.e., <span class="math inline">\(\mathbb{P}(X_{2},X_{1})=\mathbb{P}(X_{2}\,|\, X_{1})\mathbb{P}(X_{1})\)</span>. For a <strong>discrete-time stochastic process</strong>, we can recursively apply the splittings to the joint probability<label for="tufte-sn-260" class="margin-toggle sidenote-number">260</label><input type="checkbox" id="tufte-sn-260" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">260</span> For a <strong>continuous-time stochastic process</strong>, the splitting trick generally does not work unless the probability law acquires some additional structure that behaves like an exponent, called semi-group. We will see it in sec[?].</span>
<span class="math display">\[\mathbb{P}(X_{1},\dots,X_{T})= \\ \mathbb{P}(X_{T}|X_{T-1},\dots X_{1})\mathbb{P}(X_{T-1}|X_{T-2},\dots X_{1})\cdots\mathbb{P}(X_{2}|X_{1})\mathbb{P}(X_{1}).\]</span>
The splitting works, but it does not completely resolve the complexity issue, as the conditional distributions <span class="math inline">\(\mathbb{P}(X_{T}|X_{T-1},\dots X_{1})\)</span>, <span class="math inline">\(\mathbb{P}(X_{T-1}|X_{T-2},\dots X_{1})\)</span>, etc., generally involve an intensive computation (like the one we saw in the multivariate normal case).</p>
<p>The splitting conditionals utilize the full history of the process up to the current step to determine the probability for the next step, which significantly complicates analysis. However, our sense of the passage of time leads us to arrange events in the following manner: the past of our memory just fades out when we proceed; our perceptions highly depend on our present feelings but not so much on the historical ones. Extending this idea to the conditionals, we can replace those long-term conditions by the short-term ones including one and only one <a href="ch-CalUn.html#sub:conProb">conditioning variable</a>:
<span class="math display">\[\mathbb{P}(X_{1},\dots,X_{T})=\mathbb{P}(X_{T}|X_{T-1})\mathbb{P}(X_{T-1}|X_{T-2})\cdots\mathbb{P}(X_{2}|X_{1})\mathbb{P}(X_{1}),\]</span>
where each conditional probability <span class="math inline">\(\mathbb{P}(X_{t+1}|X_{t})\)</span> is about “one-step” transition, namely
regarding the future evolution at time <span class="math inline">\(t\)</span> depends only on the current state <span class="math inline">\(X_{t}\)</span>.
The system is said to possess the <em>Markov’s principle</em>: a principle of alleviating the complicated long-term dependence by using the simple short-term substitutes. A <strong>stochastic process</strong> whose probability law satisfies the <strong>Markov’s principle</strong> is also called a <em>Markov process</em>.<label for="tufte-sn-261" class="margin-toggle sidenote-number">261</label><input type="checkbox" id="tufte-sn-261" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">261</span> The <strong>Markov’s principle</strong> is not restrict to stochastic models. Most dynamical problems of our interests satisfy this principle. For instance, the deterministic iterative model <span class="math inline">\(\mathbf{x}_{t+1}=\mathbf{A}\mathbf{x}_{t}\)</span>, and the nonlinear iterative model <span class="math inline">\(\mathbf{x}_{t+1}=f(\mathbf{x}_{t})\)</span> for some continous real-valued function <span class="math inline">\(f(\cdot)\)</span> are <strong>Markov’s models</strong> due to the fact that the dynamics depends on the current state <span class="math inline">\(\mathbf{x}_{t}\)</span>, and that all the previous state <span class="math inline">\(\mathbf{x}_{t-1},\dots,\mathbf{x}_{1}\)</span> are completely irrelevant in the current dynamical law. The <a href="ch-DE.html#sub:ode">automous ODE</a> <span class="math inline">\(\frac{\mbox{d}\mathbf{x}(t)}{\mbox{d}t}=f(\mathbf{x}(t))\)</span> also satisfies the principle for the differential <span class="math inline">\(\mbox{d}\mathbf{x}(t)/\mbox{d}t\)</span>. But the (solution) process <span class="math inline">\(\mathbf{x}(t)=\int_{0}^{t}f(\mathbf{x}(s))\mbox{d}s\)</span> does not.</span></p>
<p><strong>Markov’s principle</strong> views discrete-time dynamics as a <em>chain</em> of multiple <strong>transitions</strong>. Given the initial probability <span class="math inline">\(\mathbb{P}(X_1)\)</span>, the dynamics of the process <span class="math inline">\(\{ X_t(\omega) \}_{t=1,\dots, T}\)</span> is completely described by the <em>(one-step) transition probabilities</em>
<span class="math display">\[\mbox{P}_{t}(x,\mathcal{A})=\Pr(\mbox{transit from } x  \mbox{ to }\mathcal{A} \mbox{ at time }t)\\=\mathbb{P}\left(X_{t+1}(\omega)\in\mathcal{A}\,|\,X_{t}(\omega)=x\right)\]</span>
that are well defined for any appropriate initial <a href="ch-DE.html#sub:ode">state</a> (of the transition) <span class="math inline">\(x \in \mathcal{X}\)</span> and the target set (of the transition) <span class="math inline">\(\mathcal{A}\in \sigma(\mathcal{X})\)</span>, with <span class="math inline">\(\mbox{P}_{t}(x,\mathcal{X})=1\)</span> at time <span class="math inline">\(t=1,2,\dots, T-1\)</span>. Any multiple steps of the transition can be presented as the integral of the transition probabilities. For example, the conditional probability of a two-step ahead transition is
<span class="math display">\[\begin{align*}
\mathbb{P}(X_{t+2}\in \mathcal{A} | X_{t}=x) &amp;= \int_{x' \in \mathcal{X}} \mathbb{P}(X_{t+2}\in \mathcal{A} | X_{t+1}=x') \mathbb{P}(X_{t+1}\in dx' | X_{t}=x) 
\\ &amp;=  \int_{x' \in \mathcal{X}} \mbox{P}_{t+1}  (x',\mathcal{A}) \mbox{P}_{t} (x,dx'),
\end{align*}
\]</span>
where the intermediate step on the state variable <span class="math inline">\(X_{t+1}\)</span> is “integrated out.”<label for="tufte-sn-262" class="margin-toggle sidenote-number">262</label><input type="checkbox" id="tufte-sn-262" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">262</span> Note that the infinitesimal state <span class="math inline">\(dx'\)</span> is <a href="ch-CalUn.html#sub:rv">measurable</a> in <span class="math inline">\(\sigma (\mathcal{X})\)</span>.</span> The discrete-time <strong>Markov process</strong> is also known as the <em>Markov chain</em>. The above integral equation is called the <em>Chapman–Kolmogorov equation</em> that identifies the joint probability law via chaining up the transition probabilities.</p>
<p>The <strong>transition probability</strong> is <em>time-homogeneous</em> if <span class="math display">\[\mbox{P}_{t}(x,\mathcal{A})=\mbox{P}(x,\mathcal{A})\]</span>
for all <span class="math inline">\(t=1,\dots, T-1\)</span>. The identical transition probabilities then chain up the joint probability of the <strong>time-homogeneous Markov chain</strong>. The <span class="math inline">\((t+k)\)</span>-step ahead <strong>Chapman-Kolmogorov equation</strong> of the <strong>time-homogeneous Markov chain</strong> is
<span class="math display" id="eq:ck-2">\[
\begin{align*}
&amp; \mathbb{P}(X_{t+k}\in \mathcal{A} | X_{1}=x)  \\ 
&amp;= \int_{x'\in\mathcal{X}} \mathbb{P}(X_{t+k}\in \mathcal{A} | X_{t}=x')   \mathbb{P}(X_{t}\in \mbox{d}x' | X_{1}=x) \tag{13.1}  \\
&amp;= 
\int_{x_{t+k-1} \in \mathcal{X}}\cdots \int_{x_{2} \in \mathcal{X}} \mbox{P}(x_{t+k-1},\mathcal{A}) \cdots \mbox{P} (x_{2},\mbox{d}x_{3}) \mbox{P} (x,\mbox{d}x_{2}). \tag{13.2} 
\end{align*}
\]</span></p>
<p>Many practical stochastic models satisfy the <strong>Markov’s principle</strong>. For example, <a href="ch-eigen.html#sub:matNorms">AR(1) model</a> of random variables, <span class="math inline">\(X_{t+1}=\phi X_{t}+\varepsilon_{t}\)</span> is a <strong>Markov chain</strong>, as <span class="math inline">\(X_{t+1}\)</span> is independent of <span class="math inline">\(X_{t-1},X_{t-2},\dots\)</span>, given the current value <span class="math inline">\(X_{t}=x\)</span>.<label for="tufte-sn-263" class="margin-toggle sidenote-number">263</label><input type="checkbox" id="tufte-sn-263" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">263</span> The AR(<span class="math inline">\(k\)</span>) model is also a <strong>Markov chain</strong> in the general sense, but in our context, we only consider the (first-order) <strong>Markov’s principle</strong> with the one-step ahead rather than <span class="math inline">\(k\)</span>-step ahead transitions. However, we can always make an AR(<span class="math inline">\(k\)</span>) model <span class="math inline">\(X_{t+1}=\phi_{1}X_{t}+\cdots\phi_{k}X_{t-k+1}+\varepsilon_{t}\)</span> satisfy the (first-order) <strong>Markov’s principle</strong> by constructing a <em>vector AR(1)</em> model <span class="math inline">\(\mathbf{X}_{t+1} = \Phi \mathbf{X}_{t} +\mathbf{e}_t\)</span> in terms of the <a href="ch-UnMulti.html#sub:MultiVar">multivariate</a> vector <span class="math inline">\(\mathbf{X}_{t+1}=[X_{t+1}(\omega),\dots X_{t-k+1}(\omega)]^{\top}\)</span> where
<span class="math display">\[\Phi=\left[\begin{array}{cccc}
\phi_{1} &amp; \cdots &amp; \cdots &amp; \phi_{k}\\
1 &amp;  &amp; 0 &amp; 0\\
 &amp; \ddots &amp;  &amp; \vdots\\
0 &amp;  &amp; 1 &amp; 0
\end{array}\right]\]</span> and <span class="math inline">\(\mathbf{e}_t = [\varepsilon_{t}, 0, \dots ,0]^\top\)</span>.</span> Let’s consider a specific AR(1) model whose errors are <a href="ch-CalUn.html#sub:divRV">normal random variables</a> <span class="math inline">\(\varepsilon_t \sim \mathcal{N}(0,\sigma^2)\)</span>. Given the state value <span class="math inline">\(X_{t}(\omega)=x\)</span>, the linear representation of the normal random <span class="math inline">\(\varepsilon_t\)</span> tells that <span class="math inline">\(\phi x +\varepsilon_t \sim \mathcal{N}(\phi x, \sigma^2)\)</span>. So the conditional probability <span class="math inline">\(\mathbb{P}(X_{t+1} \in \mathcal{A}| X_{t}=x)\)</span> of this AR(1) has the <strong>transition probability</strong> <span class="math inline">\(\mbox{P}_t(x,\mathcal{A})=\Pr (\mathcal{N}(\phi x, \sigma^2)\in \mathcal{A})\)</span>.</p>
<p><strong>Markov’s principle</strong> will simplify a surprisingly wide variety of phenomena if we only consider the <strong>state space</strong> of <a href="ch-CalUn.html#sub:rv">discrete random variables</a>. That is, all possible states are <a href="ch-CalUn.html#sub:rv">discrete states</a>. Then the <strong>transition probability</strong> for the <strong>Markov chain</strong> can be expressed compactly by a <strong>probability transition matrix</strong>.</p>
<p>A <em>stochastic matrix</em> is a square matrix <span class="math inline">\(\mathbf{P}\)</span> with entries <span class="math inline">\(\{p_{ij}\}\)</span> such that <span class="math inline">\(p_{ij}\geq0\)</span> for all <span class="math inline">\(i,j\)</span>, and for each row <span class="math inline">\(i\)</span>, <span class="math inline">\(\sum_{j}p_{ij}=1\)</span>. This matrix becomes the <em>probability transition matrix</em> for the <strong>Markov chain</strong> if each entry represents the probability of a one-step transition amongst the states. Let’s illustrate this matrix through a social mobility model. Sociologists broadly categorize the population of a country into upper- (U), middle- (M), and lower (L)-class brackets. One of their concerns is to monitor the movement of successive generations among these three classes. We can model these three classes as three states. Let <span class="math inline">\(X_t(\omega)\)</span> be the class for the <span class="math inline">\(t\)</span>-th generation of a family. Then the state space of <span class="math inline">\(X_t(\omega)\)</span> is <span class="math inline">\((\mathcal{X}, \sigma(\mathcal{X}))\)</span> with <span class="math inline">\(\mathcal{X}=\{\mbox{L}, \mbox{M}, \mbox{U}\}\)</span>. <strong>Markov’s principle</strong> implies that the class of any generation does not depend on the ancestry but only on the class of its parent generation. If we assume that this the social mobility transition pattern holds for any generation <span class="math inline">\(t\)</span> in the family, then <span class="math inline">\(X_t(\omega)\)</span> is a <strong>time-homogeneous Markov chain</strong>. The <strong>time-homogeneous transition probabilities</strong> <span class="math inline">\(\mbox{P}(x,x')=\mathbb{P}\left(X_{t+1}(\omega)=x'\,|\,X_{t}(\omega)=x\right)\)</span> for <span class="math inline">\(x,x'\in \{\mbox{L}, \mbox{M}, \mbox{U}\}\)</span> is contained in the following table</p>
<table>
<thead><tr class="header">
<th align="center"><span class="math inline">\(X_{t} \backslash X_{t+1}\)</span></th>
<th align="center"><span class="math inline">\(\mbox{L}\)</span></th>
<th align="center"><span class="math inline">\(\mbox{M}\)</span></th>
<th align="center"><span class="math inline">\(\mbox{U}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mbox{L}\)</span></td>
<td align="center">0.45</td>
<td align="center">0.5</td>
<td align="center">0.05</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mbox{M}\)</span></td>
<td align="center">0.15</td>
<td align="center">0.65</td>
<td align="center">0.2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mbox{U}\)</span></td>
<td align="center">0</td>
<td align="center">0.5</td>
<td align="center">0.5</td>
</tr>
</tbody>
</table>
<p>In addition, if we label <span class="math inline">\(\mbox{L}=1\)</span>, <span class="math inline">\(\mbox{M}=2\)</span>, <span class="math inline">\(\mbox{U}=3\)</span>, then we can use a <strong>probability transition matrix</strong> to present the previous table:
<span class="math display">\[\mathbf{P}=[p_{ij}]_{1\leq i,j \leq 3} = \left[\begin{array}{ccc}
0.45 &amp; 0.5 &amp; 0.05\\
0.15 &amp; 0.65 &amp; 0.2\\
0 &amp; 0.5 &amp; 0.5
\end{array}\right]\]</span>
where <span class="math inline">\(p_{ij}=\mathbb{P}(X_{t+1}=j|X_{t}=i)\)</span> represents the probability of a one-step transition from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> at any generation <span class="math inline">\(t\)</span>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:socialM"></span>
<img src="fig/Part3/socialM.png" alt="Graphic representation of the probability transition matrix " width="100%"><!--
<p class="caption marginnote">-->Figure 13.4: Graphic representation of the probability transition matrix <!--</p>-->
<!--</div>--></span>
</p>
<p>Sometimes, it more straightforward to visualize the <strong>probability transition matrix</strong> through its graphic representation. The states are the nodes in the graph, and each probability entry is the flow between two nodes. That is, a (probabilistic) flow departs from the vertex <span class="math inline">\(i\)</span> and enters the vertex <span class="math inline">\(j\)</span> with the weight <span class="math inline">\(p_{ij}\)</span>.<label for="tufte-sn-264" class="margin-toggle sidenote-number">264</label><input type="checkbox" id="tufte-sn-264" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">264</span> The reason for existing graphic representation for each <strong>Markov chain</strong> is that any complete network is a <strong>chain</strong>. Recall that a graph or a network corresponds to a collection of order pairs <span class="math inline">\((\mathcal{V},\mathcal{E})\)</span>. In the set-theoretic sense, a <strong>chain</strong> means a <a href="sub-set-theory.html#sub:order">totally ordered set</a>. The completeness here refers to the fact that <span class="math inline">\((\mathcal{V},\mathcal{E})\)</span> gives a <a href="sub-set-theory.html#sub:order">totally ordered set</a>: namely, any two vertices in the network can be decided whether they are connected or not.</span></p>
<div class="solution">
<p class="solution-begin">
Code <span id="sol-start-59" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-59', 'sol-start-59')"></span>
</p>
<div id="sol-body-59" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1">P=<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.45</span>,<span class="fl">0.5</span>,<span class="fl">0.05</span>,</a>
<a class="sourceLine" id="cb41-2" data-line-number="2">           <span class="fl">0.15</span>,<span class="fl">0.65</span>,<span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb41-3" data-line-number="3">           <span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb41-4" data-line-number="4"><span class="kw">library</span>(diagram)</a>
<a class="sourceLine" id="cb41-5" data-line-number="5"><span class="kw">rownames</span>(P)=<span class="kw">c</span>(<span class="st">"L"</span>, <span class="st">"M"</span>, <span class="st">"U"</span>); <span class="kw">plotmat</span>(<span class="kw">t</span>(P), <span class="dt">lwd =</span> <span class="dv">1</span>, <span class="dt">box.lwd =</span> <span class="dv">2</span>, <span class="dt">cex.txt =</span> <span class="fl">0.8</span>, </a>
<a class="sourceLine" id="cb41-6" data-line-number="6">               <span class="dt">box.size =</span> <span class="fl">0.1</span>, <span class="dt">box.prop =</span> <span class="fl">0.4</span>, <span class="dt">relsize=</span><span class="fl">0.7</span>,</a>
<a class="sourceLine" id="cb41-7" data-line-number="7">               <span class="dt">main =</span> <span class="st">"Social mobility"</span>)</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The <strong>Chapman-Kolmogorov equation</strong> for each <strong>time-homogeneous Markov chain</strong> now is simplified as a matrix-matrix multiplication
<span class="math display" id="eq:dck-2">\[
\begin{align*}
\mathbf{P}^{k+t}&amp;=\mathbf{P}^{k}\mathbf{P}^{t} \tag{13.3}  \\
&amp;=\underset{k+t}{\underbrace{\mathbf{P}\cdots\mathbf{P}}} \tag{13.4} 
\end{align*}
\]</span>
where <span class="math inline">\(p^{t+k}_{ij}=\sum_{s=1}^{3}p^{k}_{is}p^{t}_{sj}\)</span> for states <span class="math inline">\(i, j\)</span> and the state <span class="math inline">\(s\)</span> stands for the intermediate state that can take any of the three possibilities. One can find that equation <a href="ch-UnMulti.html#eq:dck-1">(13.3)</a> of the discrete <strong>state space</strong> is analogous to the <strong>Chapman-Kolmogorov equation</strong> <a href="ch-UnMulti.html#eq:ck-1">(13.1)</a> of the continuous <strong>state space</strong>, and <a href="ch-UnMulti.html#eq:dck-2">(13.4)</a> corresponds to <a href="ch-UnMulti.html#eq:ck-2">(13.2)</a>. To derive the above result, let’s consider the meaning of <span class="math inline">\(\mathbf{P}^2\)</span>. Notice that the meaning of <span class="math inline">\(p_{is}p_{sj}\)</span> is <span class="math display">\[\begin{align*}
p_{is}p_{sj}&amp;=\mathbb{P}(X_{t+2}=j|X_{t+1}=s)\mathbb{P}(X_{t+1}=s|X_t=i)\\
&amp;=\mathbb{P}(X_{t+2}=j,X_{t+1}=s|X_t=i)
\end{align*}
\]</span>
where the second equality comes from <strong>Markov’s principle</strong> of joint probability. Then by calculating all the possible states of <span class="math inline">\(s\)</span>, we have <span class="math inline">\(\mathbb{P}(X_{t+2}=j|X_t=i)= \sum_{s=1}^{3} p_{is}p_{sj}\)</span>. Because
<span class="math display">\[\mathbf{P}^2 = \left[\sum_{s=1}^{3}p_{is}p_{sj}\right]_{1\leq i\,,\,j\leq3}\]</span> we know that <span class="math inline">\(\mathbf{P}^2\)</span> is a <strong>probability transition matrix</strong> of two-steps ahead, namely <span class="math inline">\(\mathbb{P}(X_{t+2}|X_t)\)</span>.
We can generalize the result that the <span class="math inline">\(k\)</span>-step <strong>probability transition matrix</strong>of this <strong>time-homogeneous Markov chain</strong> must be <span class="math inline">\(\mathbf{P}^k\)</span>.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1">P<span class="op">%*%</span>P </a></code></pre></div>
<pre><code>##        [,1]   [,2]   [,3]
## [1,] 0.2775 0.5750 0.1475
## [2,] 0.1650 0.5975 0.2375
## [3,] 0.0750 0.5750 0.3500</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="kw">rowSums</span>(P<span class="op">%*%</span>P)</a></code></pre></div>
<pre><code>## [1] 1 1 1</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw">library</span>(expm) <span class="co"># Matrix power </span></a>
<a class="sourceLine" id="cb46-2" data-line-number="2">P<span class="op">%^%</span><span class="dv">10</span> </a></code></pre></div>
<pre><code>##           [,1]      [,2]      [,3]
## [1,] 0.1606135 0.5882353 0.2511512
## [2,] 0.1604433 0.5882353 0.2513214
## [3,] 0.1602730 0.5882353 0.2514917</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="kw">rowSums</span>(P<span class="op">%^%</span><span class="dv">10</span>)</a></code></pre></div>
<pre><code>## [1] 1 1 1</code></pre>
<p>Because any <span class="math inline">\(k+t\)</span> power of the probability transition matrix <span class="math inline">\(\mathbf{P}\)</span> can be split as the sum of products of <span class="math inline">\(k\)</span>-step and <span class="math inline">\(t\)</span>-step transition probability matrices, we can split <span class="math inline">\(\mathbf{P}^{k+t}\)</span> as the products of <span class="math inline">\(k+t\)</span> identical matrices <span class="math inline">\(\mathbf{P}\)</span> that exactly coincides with the <strong>Chapman-Kolmogorov equation</strong> in <a href="ch-UnMulti.html#eq:ck-1">(13.1)</a> and <a href="ch-UnMulti.html#eq:ck-2">(13.2)</a>.</p>
<p>The idea of modeling dynamics by chains can be traced back to a metaphysical topic called the <em>great chain of being</em> where the chain was conceived as a static hierarchy, starting with God at the top and descending through angels, human beings, animals, etc. This progression of the life forms gave the basis for the idea of <em>evolution</em>: complex structures emerge from simpler forms through (natural) selection mechanisms.<label for="tufte-sn-265" class="margin-toggle sidenote-number">265</label><input type="checkbox" id="tufte-sn-265" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">265</span> In political and social science, creating secular governmental structures that vested power into various citizens’ classes was viewed as an (r)evolutionary movements in Hegel, Marx and Engels’ work. However, the theory of evolution plays several different roles over there, some toward increasing the order and complexity while some mean just the opposite.</span> Another feature of the chain is that although it was viewed as one continuous whole, it has the potential for the missing and overlapping links. Each link in the chain might be splitted further. Based on the dual nature of the chain - divided yet united, Carl Linnaeus, who is considered as one of the founders of ecology, formalized his modern system of naming organisms (taxonomy).</p>
</div>
<div id="sub:rw" class="section level2">
<h2>
<span class="header-section-number">13.3</span> Example: Forward and Backward Transitions and Random Walks</h2>
<p>In this section, we only consider <a href="ch-UnMulti.html#sub:Markov">time-homogeneous</a> Markov chain with <span class="math inline">\(n\)</span> number of states.</p>
<p><span class="newthought">Forward and backward Transitions </span></p>
<p>A vector <span class="math inline">\(\mathbf{u}\in\mathbb{R}^n\)</span> is called the <em>probability vector</em>, if all the entries <span class="math inline">\(u_i\)</span> of the <span class="math inline">\(n\)</span>-vector <span class="math inline">\(\mathbf{u}\)</span> are non-negative <span class="math inline">\(u_{i}\geq0\)</span>, and sum up to one, <span class="math inline">\(\sum_{i=1}^{n}u_{i}=1\)</span>. One special case is the singleton, i.e., <span class="math inline">\(u_i = 1\)</span> and <span class="math inline">\(u_j=0\)</span> for <span class="math inline">\(1\leq j\neq i\leq n\)</span>. Each row of the <a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a>, by definition, is a row <strong>probability vector</strong>. Consider the social mobility model in section <a href="ch-UnMulti.html#sub:Markov">13.2</a>, the vector <span class="math inline">\(\mathbb{P}(X_{t+10}|X_t=i)\)</span>, namely the <span class="math inline">\(i\)</span>-th row of <span class="math inline">\(\mathbf{P}^{10}\)</span>, gives the probability of the belonging class for the descendant in ten-generation. You may find that they are almost the same, roughly <span class="math inline">\([0.16, 0.59, 0.25]\)</span>, for <span class="math inline">\(i=1,2,3\)</span>. The result indicates that regardless of the initial state <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> of the family, the descendant in ten-generation will face almost the same transition probability. For example, given an initial (row) <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}^\top(0)=[1,0,0]\)</span>, namely the family belonging to the lower class at time <span class="math inline">\(t=0\)</span>, figure <a href="ch-UnMulti.html#fig:probVec">13.5</a> shows that the evolution of this time-homogeneous Markov chain follows <span class="math display">\[\begin{align*}
\mathbf{u}^{\top}(t) &amp;= \sum_{i=\mathcal{X}}\mathbb{P}(X_{t}|X_{t-1}=i)\mathbb{P}(X_{t-1}=i) \\
&amp;= \mathbf{u}^{\top}(t-1)\mathbf{P} = \cdots =\mathbf{u}^{\top}(0)\mathbf{P}^{t}
\end{align*}\]</span> from <span class="math inline">\(t=1\)</span> to <span class="math inline">\(t=15\)</span> where <span class="math inline">\(u_{i}(t)\)</span> in <span class="math inline">\(\mathbf{u}(t)\)</span> denotes the (unconditional) probability of being at the state <span class="math inline">\(i\)</span>, namely <span class="math inline">\(u_{i}(t)=\mathbb{P}(X_{t}=i)\)</span>.<label for="tufte-sn-266" class="margin-toggle sidenote-number">266</label><input type="checkbox" id="tufte-sn-266" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">266</span> The <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}^{\top}(0)=[1,0,0]\)</span> associates with the singleton <span class="math inline">\(X_0=\mbox{Low}\)</span>. This singleton simply says that the state <span class="math inline">\(i=\mbox{Low}\)</span> happens with probability one; namely, the state <span class="math inline">\(i\)</span> surely happens, and the probabilistic event degenerates into a deterministic one.</span> We can see that the <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}(t)\)</span> converges as <span class="math inline">\(t\)</span> grows.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:probVec"></span>
<img src="fig/Part3/probVec.gif" alt="Evolution of the probability vector " width="100%"><!--
<p class="caption marginnote">-->Figure 13.5: Evolution of the probability vector <!--</p>-->
<!--</div>--></span>
</p>
<div class="solution">
<p class="solution-begin">
Code <span id="sol-start-60" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-60', 'sol-start-60')"></span>
</p>
<div id="sol-body-60" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">P=<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="fl">0.45</span>,<span class="fl">0.5</span>,<span class="fl">0.05</span>,</a>
<a class="sourceLine" id="cb50-2" data-line-number="2">           <span class="fl">0.15</span>,<span class="fl">0.65</span>,<span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb50-3" data-line-number="3">           <span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>), <span class="dt">nrow=</span><span class="dv">3</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb50-4" data-line-number="4"></a>
<a class="sourceLine" id="cb50-5" data-line-number="5"><span class="kw">library</span>(expm) <span class="co"># Matrix power </span></a>
<a class="sourceLine" id="cb50-6" data-line-number="6">init.u =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb50-7" data-line-number="7">L =<span class="st"> </span><span class="kw">c</span>(); M =<span class="st"> </span><span class="kw">c</span>(); U =<span class="st"> </span><span class="kw">c</span>();</a>
<a class="sourceLine" id="cb50-8" data-line-number="8">L[<span class="dv">1</span>] =<span class="st"> </span><span class="dv">1</span>; M[<span class="dv">1</span>] =<span class="st"> </span><span class="dv">0</span>; U[<span class="dv">1</span>] =<span class="st"> </span><span class="dv">0</span>;</a>
<a class="sourceLine" id="cb50-9" data-line-number="9"><span class="cf">for</span>(t <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span><span class="dv">15</span>){</a>
<a class="sourceLine" id="cb50-10" data-line-number="10">     u.t =<span class="st"> </span>init.u<span class="op">*</span>P<span class="op">%^%</span>(t<span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb50-11" data-line-number="11">     L[t] =<span class="st"> </span>u.t[<span class="dv">1</span>,<span class="dv">1</span>]; M[t] =<span class="st"> </span>u.t[<span class="dv">1</span>,<span class="dv">2</span>]; U[t] =<span class="st"> </span>u.t[<span class="dv">1</span>,<span class="dv">3</span>]</a>
<a class="sourceLine" id="cb50-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb50-13" data-line-number="13">data =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">time=</span><span class="dv">1</span><span class="op">:</span><span class="dv">15</span>, L, M, U)</a>
<a class="sourceLine" id="cb50-14" data-line-number="14"><span class="co"># plot</span></a>
<a class="sourceLine" id="cb50-15" data-line-number="15"><span class="kw">library</span>(ggplot2); <span class="kw">library</span>(gganimate); <span class="kw">library</span>(reshape2)</a>
<a class="sourceLine" id="cb50-16" data-line-number="16">fig =<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">melt</span>(data, <span class="dt">id.vars=</span><span class="st">"time"</span>), <span class="kw">aes</span>(time, value, <span class="dt">colour=</span>variable, <span class="dt">group=</span>variable)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span><span class="st">"Probability"</span>)  </a>
<a class="sourceLine" id="cb50-17" data-line-number="17">fig <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">group =</span> <span class="kw">seq_along</span>(time))) <span class="op">+</span><span class="st"> </span><span class="kw">transition_reveal</span>(time) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>To understand the mechanism behind this convergence, we need to take a further look at the property of the <a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a> <span class="math inline">\(\mathbf{P}\)</span> of the chain. One important feature of <span class="math inline">\(\mathbf{P}\)</span> is that the fixed point of <span class="math inline">\(\mathbf{P}\)</span> always exists
<span class="math display">\[\mathbf{P}\mathbf{v}=\lambda \mathbf{v},\, \mbox{ with } \lambda=1\]</span>
and the eigenvector <span class="math inline">\(\mathbf{v}=[1,1,\dots,1]^{\top}\)</span> because each row of <span class="math inline">\(\mathbf{P}\)</span> sums up to one. The other feature is that the eigenvalue <span class="math inline">\(\lambda=1\)</span> turns out to be the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> of <span class="math inline">\(\mathbf{P}\)</span>. Quick verification of the previous statement is to assume an eigenvalue <span class="math inline">\(|\lambda|&gt;1\)</span> to exist so that <span class="math inline">\(\mathbf{P}^{k}\)</span> must be an expanding transformation. But the property of the <a href="ch-UnMulti.html#sub:Markov">Chapman-Kolmogorov equation</a> implies that any <span class="math inline">\(\mathbf{P}^{k}\)</span> must be a <a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a> whose row sums are one. Thus <span class="math inline">\(\mathbf{P}^{k}\)</span> should not induce an expanding transformation.<label for="tufte-sn-267" class="margin-toggle sidenote-number">267</label><input type="checkbox" id="tufte-sn-267" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">267</span> The formal version of these two features is given by the <em>Perron–Frobenius theorem</em>. The theorem asserts that any <strong>irreducible</strong> real square matrix with non-negative entries has a unique <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> and that the corresponding eigenvector has strictly positive components. We will discuss the <strong>irreducibility</strong> later.</span></p>
<div class="solution">
<p class="solution-begin">
Proof of the non-expanding feature <span id="sol-start-61" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-61', 'sol-start-61')"></span>
</p>
<div id="sol-body-61" class="solution-body" style="display: none;">
<p>We can examine the non-expanding feature of <span class="math inline">\(\mathbf{P}\)</span> by using the <a href="sub-continuity.html#sub:continuousFunc"><span class="math inline">\(\ell_{1}\)</span>-norm</a> of the vector. For any stochastic matrix <span class="math inline">\(\mathbf{P}\in\mathbb{R}^{n\times n}\)</span> and any vector <span class="math inline">\(\mathbf{v}\in\mathbb{R}^n\)</span>, we have<label for="tufte-sn-268" class="margin-toggle sidenote-number">268</label><input type="checkbox" id="tufte-sn-268" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">268</span> In particular, if <span class="math inline">\(\mathbf{v}\)</span> has all non-negative entries, then we can drop the absolute value signs, and the inequality becomes an equality.</span></p>
<p><span class="math display">\[\begin{align*}
\sum_{j=1}^{n}\left|\sum_{i=1}^{n}p_{ij}v_{j}\right|&amp; \leq\sum_{i=1}^{n}\sum_{j=1}^{n}p_{ij}|v_{j}| \leq\sum_{j=1}^{n}|v_{j}|\sum_{i=1}^{n}p_{ij}\\
&amp;   =\sum_{j=1}^{n}|v_{j}|\times1=\|\mathbf{v}\|_{1}.
\end{align*}\]</span>
where the first inequality comes from the fact that <span class="math inline">\(p_{ij}\geq0\)</span> for any <span class="math inline">\(i,j\)</span>, and the second inequality utilizes the fact <span class="math inline">\(\sum_{j=1}^{n}p_{ij}|v_{j}|\leq\sum_{j=1}^{n}(\max_{j}p_{ij})|v_{j}|\)</span> and <span class="math inline">\(\sum_{i=1}^{n}(\max_{j}p_{ij})=\sum_{i=1}^{n}p_{ij}=1\)</span>. So we have <span class="math inline">\(\|\mathbf{P}\mathbf{v}\|_{1}\leq\|\mathbf{v}\|_{1}\)</span>, the result follows.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The dynamical property of eigenvalues in chapter <a href="ch-eigen.html#sub:diag">12.2</a> tells us that the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> determines the linear dynamics generated by the matrix. So we expect that the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> of <span class="math inline">\(\mathbf{P}\)</span> should tell us something about the evolution of <span class="math inline">\(\mathbf{u}(\cdot)\)</span>.
Now, our task is to explain the dynamics (evolution) of <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}(\cdot)\)</span> by means of the eigenvalues and eigenvectors of <span class="math inline">\(\mathbf{P}\)</span>.</p>
<p>The convergence of <span class="math inline">\(\mathbf{u}^{\top}(t+1)=\mathbf{u}^{\top}(t)\mathbf{P}\)</span> means that the dynamical vector tends to be a <a href="ch-vecMat.html#sub:linearSys">stationary vector</a> or a fixed point. The <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}\)</span> is a fixed point (called <em>stationary probability</em>) if and only if <span class="math display">\[\mathbf{u}^{\top}=\mathbf{u}^{\top}\mathbf{P}.\]</span>
where <span class="math inline">\(\mathbf{u}^\top\)</span> is a <a href="ch-vecMat.html#sub:vec">row vector</a>. By taking the transpose operation of both sides of <span class="math inline">\(\mathbf{u}^{\top}=\mathbf{u}^{\top}\mathbf{P}\)</span>, we can see that the column <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}\)</span> is the <strong>eigenvector</strong> of <span class="math inline">\(\mathbf{P}^\top\)</span>:
<span class="math display">\[\mathbf{P}^\top \mathbf{u}= \mathbf{u}.\]</span> Such an eigenvector is called the <strong>left-hand eigenvector</strong>.<label for="tufte-sn-269" class="margin-toggle sidenote-number">269</label><input type="checkbox" id="tufte-sn-269" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">269</span> A <em>left-hand eigenvector</em> corresponding to an eigenvalue <span class="math inline">\(\lambda\)</span> of <span class="math inline">\(\mathbf{A}\in\mathbb{R}^{n\times n}\)</span> is a <a href="ch-vecMat.html#sub:vec">column vector</a> <span class="math inline">\(\mathbf{x}\in\mathbb{R}^n\)</span> such that <span class="math display">\[\mathbf{x}^{\top} \mathbf{A}= \lambda \mathbf{x}^{\top}.\]</span> It follows that <strong>left-hand eigenvectors</strong> of <span class="math inline">\(\mathbf{A}\)</span> are the (right-hand) eigenvectors of <span class="math inline">\(\mathbf{A}^\top\)</span> since <span class="math inline">\(\mathbf{x}^{\top} \mathbf{A}= \lambda \mathbf{x}^{\top}\)</span> implies that <span class="math inline">\(\mathbf{A}^\top \mathbf{x} = \lambda \mathbf{x}\)</span>.</span></p>
<p>When people mention an eigenvector without explicitly saying which one, usually they mean the (right-hand) eigenvector as it appears more often in the literature. That’s why our preceding discussions only centered on the (right-hand) eigenvectors. Especially, the (right-hand) and the <strong>left-hand eigenvectors</strong> share the same set of eigenvalues. Take the probability transition matrix <span class="math inline">\(\mathbf{P}\)</span> as an example. The <a href="ch-eigen.html#sub:det">property of determinant</a> tells that <span class="math inline">\(\mbox{det}(\mathbf{P})=\mbox{det}(\mathbf{P}^{\top})\)</span>. We have <span class="math display">\[\mbox{det}(\mathbf{P}-\lambda\mathbf{I})=\mbox{det}(\mathbf{P}^{\top}-\lambda\mathbf{I}^{\top})=\mbox{det}(\mathbf{P}^{\top}-\lambda\mathbf{I}).\]</span> Hence the eigenvalues of <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{P}^{\top}\)</span> are the same. However, this is not true for the eigenvectors.</p>
<p>Left-hand and right-hand eigenvectors corresponding to the same eigenvalue are generally different. An exception is when the matrix is symmetric. In the context of Markov’s models, these two types of eigenvectors deliver two opposite world images. For a Markov chain model, the <em>transposed probability transition matrix</em> <span class="math inline">\(\mathbf{P}^{\top}\)</span> is called the <em>time-reversal</em> of <span class="math inline">\(\mathbf{P}\)</span>. If <span class="math inline">\(\mathbf{P}=\mathbb{P}(X_{t+1}|X_t)\)</span> suggests looking at the <a href="ch-UnMulti.html#sub:Markov">time-homogeneous Markov chain</a> run forward in time, <span class="math inline">\(\mathbf{P}^{\top}=\mathbb{P}(X_{t}|X_{t+1})\)</span> suggests looking at the chain run backward in time.<label for="tufte-sn-270" class="margin-toggle sidenote-number">270</label><input type="checkbox" id="tufte-sn-270" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">270</span> Does the <strong>time-reversal</strong> violate our understanding of the real world, namely the world proceed with the <a href="sub-inferknow.html#sub:dyn">arrow of time</a>? Yes and no. If a very ordered (disordered) structure disintegrates (integrates) into disordered (ordered) elements, it is very easy for us to recognize the <a href="sub-inferknow.html#sub:dyn">time arrow</a>, and the reversal of such a process without outer forces or energies is simply impossible. But suppose that the elements will remain what they were forever, then the <a href="sub-inferknow.html#sub:dyn">arrow of time</a> loses its meaning: one cannot tell the direction of time for the timeless objects. In figure <a href="ch-UnMulti.html#fig:probVec">13.5</a>, the from <span class="math inline">\(t=0\)</span> to <span class="math inline">\(t=8\)</span>, one can see the singleton probability vector converges the <strong>stationary probability</strong>. But starting from <span class="math inline">\(t=9\)</span>, the <strong>stationary probability</strong> remains almost the same. It seems no difference by pointing those lines from <span class="math inline">\(t=9\)</span> to <span class="math inline">\(t=12\)</span> or from <span class="math inline">\(t=12\)</span> to <span class="math inline">\(t=9\)</span>.</span> That means if the chain reaches the <strong>stationary probability</strong>, it is quite likely that one cannot tell whether the chain runs forward and backward in time.<label for="tufte-sn-271" class="margin-toggle sidenote-number">271</label><input type="checkbox" id="tufte-sn-271" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">271</span> The <strong>stationary probability</strong>, as a “global” property of the Markov chains, cannot directly acquire the attribute about time-reversibility. For being time-reversible, a Markov chain needs some kind of “local” property saying that <span class="math inline">\(\mathbf{P}\)</span> and <span class="math inline">\(\mathbf{P}^{\top}\)</span> are <a href="ch-eigen.html#sub:diag">similar</a> under the <a href="ch-eigen.html#sub:diag">coordinates</a> given by the <strong>stationary probability</strong> <span class="math inline">\(\mathbf{u}\)</span> with strictly positive components. See the following discussion for details.</span></p>
<div class="solution">
<p class="solution-begin">
Discussion about time-reversal <span id="sol-start-62" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-62', 'sol-start-62')"></span>
</p>
<div id="sol-body-62" class="solution-body" style="display: none;">
<p>A deterministic process is <em>time-reversible</em> if the equation is invariant when the direction of the <a href="sub-inferknow.html#sub:dyn">arrow of time</a> reverses. Watching the deterministic process in reverse mode corresponds to showing a video backward, frame by frame. When time is turned backward, we can re-define the original process as “another” process called <em>reversed process</em>.</p>
<p>For stochastic processes, in most cases, the original process, namely the forward process, is not the same as the <strong>reversed process</strong>. <em>Reversibility</em> means that the forward process’s probability law is the same as the law for the reversed one.</p>
<p>Let’s consider the <strong>stationary probability</strong> of staying at state <span class="math inline">\(i\)</span>, <span class="math display">\[u_i = \sum_{j\in\mathcal{X}}p_{ij}u_j=p_{ii}u_i + \sum_{j\neq i}p_{ij}u_j.\]</span> The expression implies that
<span class="math display">\[u_i (1- p_{ii}) = \sum_{j\neq i}p_{ij}u_j, \,\,\mbox{or say } \,\, u_i \left(\sum_{j\neq i} p_{ij}\right) = \sum_{j\neq i}p_{ij}u_j, \]</span>
where the left-hand side represents the total probability flows out of state <span class="math inline">\(i\)</span> into states other than <span class="math inline">\(i\)</span>, while the right-hand side represents the total probability flows out of all states <span class="math inline">\(j\neq i\)</span> into state <span class="math inline">\(i\)</span>. This equation is called the <em>global balance equation</em>. It says that the ﬂow of probability is balanced globally: at each state, the amount of probability ﬂowing-in in one step equals the amount ﬂowing-out.</p>
<p>However, the global balance equation is not enough to reverse the chain completely; we also need to say the ﬂow of probability is balanced locally: at each transition, the amount of probability that ﬂows across in one direction in one step equals the amount that ﬂows in. This requires an additional equation, called the <strong>detailed balance equation</strong>.</p>
<p>First, let <span class="math inline">\(r_{ij}= \mathbb{P}(X_t=j | X_{t+1} =i)\)</span> denote the transition probability of the <strong>reversed process</strong>.
If the stationary probability has non-zero <span class="math inline">\(u_i&gt;0\)</span>, we have<label for="tufte-sn-272" class="margin-toggle sidenote-number">272</label><input type="checkbox" id="tufte-sn-272" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">272</span> The condition of <span class="math inline">\(u_i&gt;0\)</span> is called <em>positive recurrent</em> of state <span class="math inline">\(i\)</span>.</span>
<span class="math display">\[
\begin{align*}
r_{ij}= \mathbb{P}(X_t=j | X_{t+1} =i) &amp;= \frac{\mathbb{P}(X_t= j , X_{t+1}=i)}{\mathbb{P}(X_{t+1}=i)}, \\
&amp;= \frac{\mathbb{P}(X_{t+1}=i | X_t= j )\mathbb{P}(X_{t}=j)}{\mathbb{P}(X_{t+1}=i)}
\end{align*} 
\]</span>
Then when the chain reaches the stationary probability, namely <span class="math inline">\(\mathbb{P}(X_{t})=\mathbb{P}(X_{t+1})=\mathbf{u}\)</span>, the above expression becomes
<span class="math display">\[r_{ij} = \frac{p_{ji}u_j}{u_i}.\]</span>
Note that <span class="math inline">\(r_{ij}\)</span> induces a <strong>probability vector</strong> <span class="math display">\[\sum_j r_{ij}=\frac{1}{u_i}\sum_j p_{ji}u_j=\frac{u_i}{u_i}=1\]</span> where the second equality comes from <span class="math display">\[\sum_j \mathbb{P}(X_{t+1}=i|X_t= j )\mathbb{P}(X_{t}=j)=\mathbb{P}(X_{t+1}=i)=u_i.\]</span> Thus, the matrix <span class="math inline">\(\mathbf{R}=[r_{ij}]\)</span> is the <a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a> for the <strong>reversed process</strong>. In particular, the relation between <span class="math inline">\(\mathbf{R}\)</span> and <span class="math inline">\(\mathbf{P}\)</span> is <span class="math display">\[ \mathbf{R} = \mbox{diag}(\mathbf{u})\mathbf{P}^{\top}\mbox{diag}(\mathbf{u}),\]</span> namely, <span class="math inline">\(\mathbf{R}\)</span> is <a href="ch-eigen.html#sub:diag">similar</a> to <span class="math inline">\(\mathbf{P}^{\top}\)</span>.</p>
<p>Since the <strong>reversibility</strong> requires the <strong>forward process’s</strong> <a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a> to be the same as that of the <strong>reversed process</strong>, the <strong>reversibility</strong> for this Markov chain means <span class="math inline">\(\mathbf{P}=\mathbf{R}\)</span>, which is the <em>detailed balance equation</em>, namely, <span class="math display">\[r_{ij}=p_{ij} = \frac{p_{ji}u_j}{u_i},\]</span>
or say <span class="math inline">\(u_i p_{ij} = u_jp_{ji}\)</span>. One can see that the <strong>detailed balance</strong> implies the <strong>global balance</strong>: <span class="math inline">\(\sum_i u_i p_{ij} =\sum_i u_jp_{ji}=u_i \sum_ip_{ji}=u_i\)</span> whose matrix form gives the <strong>left-hand eigenvector</strong> <span class="math inline">\(\mathbf{u}= \mathbf{P}^{\top} \mathbf{u}\)</span>. In other words, the
<strong>global balance</strong> does not imply the <strong>detailed balance</strong>, because the <strong>detailed balance equation</strong> requires the additional condition that <span class="math inline">\(\mathbf{P}\)</span> needs to be <a href="ch-eigen.html#sub:diag">similar</a> to
<span class="math inline">\(\mathbf{P}^{\top}\)</span>, namely <span class="math inline">\(\mathbf{P} = \mbox{diag}(\mathbf{u})\mathbf{P}^{\top}\mbox{diag}(\mathbf{u})\)</span>.</p>
<p><strong>Detailed balance</strong> is a necessary and sufficient condition for the <strong>reversibility</strong> of a <a href="ch-UnMulti.html#sub:Markov">time-homogeneous</a> Markov chain.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>For <span class="math inline">\(n\)</span> number of states, because <span class="math inline">\(\mathbf{P}\in\mathbb{R}^{n\times n}\)</span> and <span class="math inline">\(\mathbf{P}^\top\in\mathbb{R}^{n\times n}\)</span> share the same set of eigenvalues, and because the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> of <span class="math inline">\(\mathbf{P}\)</span> (and <span class="math inline">\(\mathbf{P}^\top\)</span>) is one, we can infer that the evolution (or the dynamical system) <span class="math inline">\(\mathbf{u}^{\top}(t) \mathbf{P}\)</span> will <a href="ch-eigen.html#sub:diag">converge</a> to the <strong>left-hand eigenvector</strong> <span class="math inline">\(\mathbf{u}\)</span> if there is a unique <span class="math inline">\(\mathbf{u}\)</span> accompanying the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a>. When the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> is associated with more than one <strong>left-hand eigenvector</strong>, more than one <strong>left-hand eigenvector</strong> will be eligible for leading the dynamics. In this case, the convergence may not exist. We will use <strong>random walk</strong> examples to illustrate this issue, and the background of the issue is given below.</p>
<div class="solution">
<p class="solution-begin">
Convergence and the principal eigenvalues <span id="sol-start-63" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-63', 'sol-start-63')"></span>
</p>
<div id="sol-body-63" class="solution-body" style="display: none;">
<p>Let <span class="math inline">\(\mathbf{u}^\top_1\mathbf{P}=\mathbf{u}^\top_{1}\lambda_{1}\)</span>, <span class="math inline">\(\dots, \mathbf{u}^\top_{n}\mathbf{P}=\mathbf{u}^\top_{n}\lambda_{n}\)</span>. When there is a unique eigenvector associating with the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a>, we can rank the eigenvalues of <span class="math inline">\(\mathbf{P}\in\mathbb{R}^{n\times n}\)</span> by their absolute values. Then we have eigenvalue-eigenvector pairs <span class="math inline">\((\lambda_1, \mathbf{u}_1)\)</span>, <span class="math inline">\((\lambda_2, \mathbf{u}_2)\)</span>, and so on, where <span class="math inline">\(|\lambda_1|=1&gt;|\lambda_2|\geq\dots\geq|\lambda_n|\)</span>. The <strong>left-hand eigenvectors</strong> <span class="math inline">\(\{\mathbf{u}^\top_1,\dots,\mathbf{u}^\top_n\}\)</span> also form a <a href="ch-eigen.html#sub:diag">basis</a> in <span class="math inline">\(\mathbb{R}^n\)</span>.<label for="tufte-sn-273" class="margin-toggle sidenote-number">273</label><input type="checkbox" id="tufte-sn-273" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">273</span> 
Generally speaking, the set of <strong>left-hand eigenvectors</strong> and (right-hand) eigenvectors together form a pair of bases called the dual basis. We will discuss it in ch[?]. In a nutshell, the duality means that the left-hand eigenvector matrix is orthogonal to the (right-hand) eigenvector matrix. Since the (right-hand) eigenvectors form a basis (see section <a href="ch-eigen.html#sub:diag">12.2</a>), by the orthogonality, we can expect that the <strong>left-hand eigenvectors</strong> also form a basis. See figure <a href="ch-UnMulti.html#fig:Orthogonal">13.6</a>.</span> So any <span class="math inline">\(\mathbf{u}^\top(t)\)</span> can be represented by a <a href="ch-vecMat.html#sub:vec">linear combination</a> of <span class="math inline">\(\{\mathbf{u}^\top_1,\dots,\mathbf{u}^\top_n\}\)</span>:
<span class="math display">\[\begin{align*}
\mathbf{u}^\top(t)&amp;=\mathbf{u}^\top(0)\mathbf{P}^{t}=(c_{1}\mathbf{u}^\top_{1}+\cdots+c_{n}\mathbf{u}^\top_{n})\mathbf{P}^{t}\\
&amp;=c_{1}\mathbf{u}^\top_{1}+c_{2}(\lambda_{2})^{t}\mathbf{u}^\top_{2}+\cdots+c_{n}(\lambda_{n})^{t}\mathbf{u}^\top_{n}.
\end{align*}\]</span>
As <span class="math inline">\(|\lambda_{i}|&lt;1\)</span> for <span class="math inline">\(i=2,\dots n\)</span>, when <span class="math inline">\(t\)</span> increases, all the terms except the leading one will drop out
<span class="math display">\[
\lim_{t\rightarrow \infty}\mathbf{u}^\top(t)=\lim_{t\rightarrow \infty}\mathbf{u}^\top(0)\mathbf{P}^{t} =c_{1}\mathbf{u}^\top_{1}.
\]</span>
So the <strong>left-hand eigenvector</strong> <span class="math inline">\(\mathbf{u}_{1}\)</span> induces the <strong>stationary probability</strong> <span class="math inline">\(\mathbf{u}\)</span> by <span class="math inline">\(\mathbf{u}=c_1\mathbf{u}_1\)</span> where <span class="math inline">\(c_1=1/(\mathbf{u}_{1}^\top\mathbf{1})\)</span> normalizes <span class="math inline">\(\mathbf{u}_{1}\)</span> as a <strong>probability vector</strong> with <span class="math inline">\(\mathbf{1}=[1,\dots,1]^\top\)</span>.<label for="tufte-sn-274" class="margin-toggle sidenote-number">274</label><input type="checkbox" id="tufte-sn-274" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">274</span> As <span class="math inline">\(\mathbf{u}^{\top} \mathbf{P} = \mathbf{u}^\top\)</span> gives rise to the system of equations <span class="math inline">\(\mathbf{u}^{\top} (\mathbf{P} -\mathbf{I})= 0\)</span>, which must have a <a href="ch-MatComp.html#sub:matInv">singular matrix</a> <span class="math inline">\(\mathbf{P} -\mathbf{I}\)</span> for non-zero <span class="math inline">\(\mathbf{u}^\top\)</span> (see statement 1 and 4 in chapter <a href="ch-MatComp.html#sub:matInv">11.2</a>). This <a href="ch-MatComp.html#sub:matInv">singular matrix</a> <span class="math inline">\(\mathbf{P} -\mathbf{I}\)</span> gives rise to only <span class="math inline">\((n-1)\)</span> (not <span class="math inline">\(n\)</span>) <a href="ch-MatComp.html#sub:vecSpaces">linearly independent</a> equations of the system <span class="math inline">\(\mathbf{u}^{\top} (\mathbf{P} -\mathbf{I})= 0\)</span>. Normalizing the solution gives the unique result of the system as the procedure implicitly utilizes an additional equation <span class="math inline">\(\mathbf{u}^\top\mathbf{1}=1\)</span>. (Or you can think that one of the equations in the system <span class="math inline">\(\mathbf{u}^{\top} (\mathbf{P} -\mathbf{I})= 0\)</span> is replaced by the normalizing equation, so the resulting system has a nonsingular matrix, which means that it has a unique solution.)</span></p>
<p>On the other hand, if two <strong>left-hand eigenvectors</strong> are associated with the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> such that
<span class="math inline">\(1=|\lambda_1|=|\lambda_2|&gt;|\lambda_3|\)</span>, then the previous representation of <span class="math inline">\(\mathbf{u}^\top(t)\)</span> becomes
<span class="math display">\[
\mathbf{u}^\top(t)=\mathbf{u}^\top(0)\mathbf{P}^{t} =c_{1}\mathbf{u}^\top_{1}+c_{2}\mathbf{u}^\top_{2} + o(t)
\]</span> where <span class="math inline">\(o(t)\)</span> is a negligible term when <span class="math inline">\(t\rightarrow\infty\)</span>. The expression <span class="math inline">\(c_{1}\mathbf{u}^\top_{1}+c_{2}\mathbf{u}^\top_{2}\)</span> is a mixture of <span class="math inline">\(\mathbf{u}^\top_{1}\)</span> and <span class="math inline">\(\mathbf{u}^\top_{2}\)</span>. By tuning the coefficients <span class="math inline">\(c_{1}\)</span> and <span class="math inline">\(c_{2}\)</span>, there are infinite ways to represent <span class="math inline">\(\mathbf{u}^\top(t)\)</span>. The limit of <span class="math inline">\(\mathbf{u}^\top(0)\mathbf{P}^{t}\)</span> will not converge to a unique result. A similar argument holds for the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> accompanying more than two <strong>left-hand eigenvectors</strong>.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The convergence of <span class="math inline">\(\mathbf{u}^{\top}(t) \mathbf{P}\)</span> or <span class="math inline">\(\mathbf{u}^\top(0)\mathbf{P}^t\)</span> implies that the <strong>stationary probability</strong> is independent of the initial <span class="math inline">\(\mathbf{u}^\top(0)\)</span> because <span class="math inline">\(\mathbf{u}=\lim_{t\rightarrow \infty}\mathbf{u}^\top(0)\mathbf{P}^t\)</span> holds for any <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}^\top(0)\)</span>.<label for="tufte-sn-275" class="margin-toggle sidenote-number">275</label><input type="checkbox" id="tufte-sn-275" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">275</span> It worths to stress that the existence of <span class="math inline">\(\mathbf{u}^\top=\lim_{t\rightarrow\infty}\mathbf{u}^\top(t)\mathbf{P}\)</span> implies that both the vector <span class="math inline">\(\mathbf{u}(t)\)</span> and the matrix <span class="math inline">\(\mathbf{P}^t\)</span> converge independently of the initial <span class="math inline">\(\mathbf{u}(0)\)</span>. The limit <span class="math inline">\(\lim_{t\rightarrow\infty}\mathbf{u}^\top(t)\mathbf{P}\)</span> is also called the <em>equilibrium probability</em> or <em>steady-state probability</em>, to highlight the sense that the effect of the initial state has disappeared.</span></p>
<p>For the social mobility model in section <a href="ch-UnMulti.html#sub:Markov">13.2</a>, it is easy to see that the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a> accompanies with only one <strong>left-hand eigenvector</strong>. Thus, we can study the equilibrium behavior of its Markov chain by the eigenvectors as the initial state does not matter in this model.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1">v.eigen =<span class="st"> </span><span class="kw">eigen</span>(P, <span class="dt">symmetric=</span><span class="ot">FALSE</span>); v.eigen</a></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1] 1.00 0.45 0.15
## 
## $vectors
##           [,1]        [,2]       [,3]
## [1,] 0.5773503 -0.76665188  0.6337243
## [2,] 0.5773503 -0.06388766 -0.4436070
## [3,] 0.5773503  0.63887656  0.6337243</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1">v.eigen<span class="op">$</span>vectors[,<span class="dv">1</span>] <span class="co"># eigenvector with identical entries</span></a></code></pre></div>
<pre><code>## [1] 0.5773503 0.5773503 0.5773503</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1">u.eigen =<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">t</span>(P), <span class="dt">symmetric=</span><span class="ot">FALSE</span>); u.eigen</a></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1] 1.00 0.45 0.15
## 
## $vectors
##           [,1]          [,2]       [,3]
## [1,] 0.2432601  7.071068e-01  0.4082483
## [2,] 0.8919538 -6.077150e-16 -0.8164966
## [3,] 0.3811075 -7.071068e-01  0.4082483</code></pre>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1">u =<span class="st"> </span>u.eigen<span class="op">$</span>vectors[,<span class="dv">1</span>]; </a>
<a class="sourceLine" id="cb57-2" data-line-number="2">u.normalized =<span class="st"> </span>u<span class="op">/</span><span class="kw">sum</span>(u); u.normalized <span class="co"># see "Convergence and the principal eigenvalues" for the reason of normalization.</span></a></code></pre></div>
<pre><code>## [1] 0.1604278 0.5882353 0.2513369</code></pre>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:Orthogonal"></span>
<img src="fig/Part3/orthogonal.png" alt="The product of the right-hand and left-hand eigenvector matrices shows non-zero diagonals (the orthogonality of these two matrices) " width="100%"><!--
<p class="caption marginnote">-->Figure 13.6: The product of the right-hand and left-hand eigenvector matrices shows non-zero diagonals (the orthogonality of these two matrices) <!--</p>-->
<!--</div>--></span>
</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1"><span class="co"># About the basis (see "Convergence and the principal eigenvalues") </span></a>
<a class="sourceLine" id="cb59-2" data-line-number="2">V=v.eigen<span class="op">$</span>vectors; <span class="co">#right-hand eigenvector matrix</span></a>
<a class="sourceLine" id="cb59-3" data-line-number="3">U=u.eigen<span class="op">$</span>vectors  <span class="co">#left-hand eigenvector matrix</span></a>
<a class="sourceLine" id="cb59-4" data-line-number="4"><span class="kw">library</span>(Matrix); VU=<span class="kw">Matrix</span>(<span class="kw">t</span>(U)<span class="op">%*%</span>V, <span class="dt">sparse=</span><span class="ot">TRUE</span>); <span class="kw">image</span>(VU) <span class="co"># plot the diagonal matrix</span></a></code></pre></div>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1"><span class="co"># The limit of P^t</span></a>
<a class="sourceLine" id="cb60-2" data-line-number="2">P<span class="op">%^%</span><span class="dv">1000</span></a></code></pre></div>
<pre><code>##           [,1]      [,2]      [,3]
## [1,] 0.1604278 0.5882353 0.2513369
## [2,] 0.1604278 0.5882353 0.2513369
## [3,] 0.1604278 0.5882353 0.2513369</code></pre>
<p>The limit of <span class="math inline">\(\mathbf{P}^{t}\)</span> is a matrix of three identical rows coinciding with the <strong>stationary probability</strong> <span class="math inline">\(\mathbf{u}\)</span>. Any <strong>probability vector</strong> <span class="math inline">\(\mathbf{u}(0)\)</span> multiplying with this matrix will return the same result as <span class="math display">\[
\begin{align*}
\lim_{t\rightarrow \infty}\mathbf{u}^\top(0)\mathbf{P}^t &amp;= [u_{1}(0),u_{2}(0),u_{3}(0)]\left[\begin{array}{ccc}
u_{1} &amp; u_{2} &amp; u_{3}\\
u_{1} &amp; u_{2} &amp; u_{3}\\
u_{1} &amp; u_{2} &amp; u_{3}
\end{array}\right] \\ &amp;=\left(\sum_{i=1}^3 u_{i}(0)\right)\times \mathbf{u}=\mathbf{u}.\end{align*}\]</span>
We can see that the limit of <span class="math inline">\(\mathbf{u}^\top(0)\mathbf{P}^{t}\)</span> or <span class="math inline">\(\mathbf{u}^\top(t)\mathbf{P}\)</span> exists and equals to the <strong>stationary probability</strong> <span class="math inline">\(\mathbf{u}\)</span>. This limit is independent of the initial <span class="math inline">\(\mathbf{u}^\top(0)\)</span>.</p>
<p><span class="newthought">Random walks </span></p>
<p>To have the <strong>Markov chain</strong> converge to the <strong>stationary probability</strong>, we want only one <strong>left-hand</strong> eigenvector that can possess the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a>. This goal can be decomposed into two missions. One mission is to ensure that only one <strong>left-hand eigenvector</strong> can associate with the eigenvalue one (<strong>irreducibility</strong>). The other mission is to ensure that no <strong>left-hand eigenvector</strong> can associate with the eigenvalues that could create periodic cycles (<strong>aperiodicity</strong>), such as <span class="math inline">\(-1\)</span>, <span class="math inline">\(\mbox{i}\)</span>, <span class="math inline">\(-\mbox{i}\)</span>, or any complex number has the absolute value as one.<label for="tufte-sn-276" class="margin-toggle sidenote-number">276</label><input type="checkbox" id="tufte-sn-276" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">276</span> We can express such a complex number in the <a href="sub-inferknow.html#sub:histgeo">polar form</a> <span class="math inline">\(e^{\theta \mbox{i}}\)</span> such that <span class="math inline">\(\{\theta : |e^{\theta \mbox{i}}|=1\}\)</span>.</span></p>
<p>The <em>irreducibility</em> means that every state <span class="math inline">\(i\)</span> is reachable from every other state <span class="math inline">\(j\)</span> in certain moves. That is, there exists some integers <span class="math inline">\(k\)</span> such that <span class="math inline">\(\mathbb{P}(X_{t+k}=j|X_t=i)&gt;0\)</span> for <span class="math inline">\(1\leq i,j\leq n\)</span>. The <em>aperiodicity</em> means that every state <span class="math inline">\(i\)</span> cannot be visited in a cyclic manner.<label for="tufte-sn-277" class="margin-toggle sidenote-number">277</label><input type="checkbox" id="tufte-sn-277" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">277</span> Put these two conditions in terms of the probability transition matrix <span class="math inline">\(\mathbf{P}\)</span>. The <strong>irreducibility</strong> means the matrix <span class="math inline">\(\mathbf{P}\)</span> is not <a href="ch-eigen.html#sub:diag">similar</a> to a block upper triangular matrix via a permutation, i.e., there is no <a href="ch-MatComp.html#sub:matInv">permutation elementary matrix</a> <span class="math inline">\(\mathbf{E}\)</span>
such that the matrix <span class="math inline">\(\mathbf{E}^{-1}\mathbf{P}\mathbf{E}\)</span> becomes a block upper triangular matrix <span class="math display">\[\mathbf{E}^{-1}\mathbf{P}\mathbf{E}\neq\left[\begin{array}{cc}
\mathbf{B} &amp; \mathbf{C}\\
\mathbf{0} &amp; \mathbf{D}
\end{array}\right].\]</span>
The <strong>aperiodicity</strong> means there doesn’t exist a period <span class="math inline">\(k\)</span> such that <span class="math inline">\(\mathbf{P}^{k+t} =\mathbf{P}^{t}\)</span>.</span></p>
<p>We study these two conditions through a one-dimensional <strong>random walk</strong> models.</p>
<p>A <em>random walk</em> is a stochastic process <span class="math inline">\(X_{t}\)</span>
<span class="math display">\[X_{t}=\varepsilon_{1}+\cdots+\varepsilon_{t},\,\mbox{ with }\varepsilon_{i}=\begin{cases}
1, &amp; \mbox{ with probability }q\\
-1, &amp; \mbox{ with probability }1-q.
\end{cases}\]</span>
Suppose <span class="math inline">\(X_{0}\)</span> is known, the sequence <span class="math inline">\(X_{1},X_{2},\dots\)</span> is a discrete-time stochastic process whose <a href="ch-UnMulti.html#sub:Markov">state space</a> is the set of all integers.<label for="tufte-sn-278" class="margin-toggle sidenote-number">278</label><input type="checkbox" id="tufte-sn-278" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">278</span> One can depict such an image from the model: a walker walks randomly on the integer line of states <span class="math inline">\(0\)</span>, <span class="math inline">\(\pm 1\)</span>, <span class="math inline">\(\pm 2,\dots\)</span>, and so on; at each discrete unit of time, the walker moves one unit either up or down, with probability <span class="math inline">\(q\)</span> and <span class="math inline">\(1 − q\)</span> respectively.</span> The model satisfies the <a href="ch-UnMulti.html#sub:Markov">Markov’s principle</a>, as all the transitions follow a <a href="ch-UnMulti.html#sub:Markov">time-homogeneous</a> <a href="ch-UnMulti.html#sub:Markov">transition probability</a> <span class="math display">\[\mathbb{P}(X_{t+1}|X_t=i) = \begin{cases} i+1, &amp; \mbox{ with probability }q\\
i-1, &amp; \mbox{ with probability }1-q.
\end{cases}\]</span> Thus, we can study <strong>random walks</strong> by Markov chains.<label for="tufte-sn-279" class="margin-toggle sidenote-number">279</label><input type="checkbox" id="tufte-sn-279" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">279</span> For example, the processes in figures <a href="ch-UnMulti.html#fig:rw">13.3</a> are actually simulated by the same random walk model with the states in <span class="math inline">\(\mathcal{X}=\{1,2,\dots,100\}\)</span>.</span></p>
<div class="solution">
<p class="solution-begin">
Simulate the random walks <span id="sol-start-64" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-64', 'sol-start-64')"></span>
</p>
<div id="sol-body-64" class="solution-body" style="display: none;">
<p>The simulation in figure <a href="ch-UnMulti.html#fig:rw">13.3</a> is based on the following codes.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="kw">library</span>(markovchain)</a>
<a class="sourceLine" id="cb62-2" data-line-number="2"></a>
<a class="sourceLine" id="cb62-3" data-line-number="3">N=<span class="dv">100</span>;  P=<span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>N,<span class="dt">ncol=</span>N);</a>
<a class="sourceLine" id="cb62-4" data-line-number="4">p=<span class="fl">0.5</span>; q=<span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb62-5" data-line-number="5"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>(N<span class="dv">-1</span>)){</a>
<a class="sourceLine" id="cb62-6" data-line-number="6">    P[i<span class="op">+</span><span class="dv">1</span>,i]=q;</a>
<a class="sourceLine" id="cb62-7" data-line-number="7">    P[i<span class="dv">-1</span>,i]=q</a>
<a class="sourceLine" id="cb62-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb62-9" data-line-number="9"><span class="co"># Boundary conditions</span></a>
<a class="sourceLine" id="cb62-10" data-line-number="10">P[<span class="dv">1</span>,<span class="dv">1</span>]=<span class="dv">1</span>; P[<span class="dv">2</span>,<span class="dv">1</span>]=<span class="fl">0.5</span>;P[<span class="dv">1</span>,<span class="dv">2</span>]=<span class="dv">0</span>;</a>
<a class="sourceLine" id="cb62-11" data-line-number="11">P[N,N]=<span class="dv">1</span>;P[N<span class="dv">-1</span>,N]=<span class="fl">0.5</span>; P[N,N<span class="dv">-1</span>]=<span class="dv">0</span></a>
<a class="sourceLine" id="cb62-12" data-line-number="12"><span class="co"># P[1,1]=0.5; P[1,2]=0.5; P[N,N-1]=0.5; P[N,N]=0.5</span></a>
<a class="sourceLine" id="cb62-13" data-line-number="13">P[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>] </a>
<a class="sourceLine" id="cb62-14" data-line-number="14">P[(N<span class="dv">-5</span>)<span class="op">:</span>N,(N<span class="dv">-5</span>)<span class="op">:</span>N]</a>
<a class="sourceLine" id="cb62-15" data-line-number="15"></a>
<a class="sourceLine" id="cb62-16" data-line-number="16"><span class="kw">set.seed</span>(<span class="dv">2020</span>)</a>
<a class="sourceLine" id="cb62-17" data-line-number="17">MC=<span class="st"> </span><span class="kw">new</span>(<span class="st">"markovchain"</span>, <span class="dt">transitionMatrix=</span>P)</a>
<a class="sourceLine" id="cb62-18" data-line-number="18"><span class="kw">is.irreducible</span>(MC) </a>
<a class="sourceLine" id="cb62-19" data-line-number="19"><span class="kw">absorbingStates</span>(MC)</a>
<a class="sourceLine" id="cb62-20" data-line-number="20">X.omega1=<span class="kw">markovchainSequence</span>(<span class="dt">n=</span><span class="dv">500</span>, <span class="dt">markovchain=</span>MC, <span class="dt">t0=</span><span class="dv">30</span>, <span class="dt">include.t0 =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb62-21" data-line-number="21">X.omega2=<span class="kw">markovchainSequence</span>(<span class="dt">n=</span><span class="dv">500</span>, <span class="dt">markovchain=</span>MC, <span class="dt">t0=</span><span class="dv">30</span>, <span class="dt">include.t0 =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb62-22" data-line-number="22">X.omega3=<span class="kw">markovchainSequence</span>(<span class="dt">n=</span><span class="dv">500</span>, <span class="dt">markovchain=</span>MC, <span class="dt">t0=</span><span class="dv">30</span>, <span class="dt">include.t0 =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb62-23" data-line-number="23">time=<span class="dv">1</span><span class="op">:</span><span class="dv">501</span>;</a>
<a class="sourceLine" id="cb62-24" data-line-number="24">d=<span class="kw">data.frame</span>(time,X.omega1,X.omega2,X.omega3)</a></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1"><span class="co"># Plot</span></a>
<a class="sourceLine" id="cb63-2" data-line-number="2"><span class="kw">library</span>(ggplot2); <span class="kw">library</span>(reshape2); <span class="kw">library</span>(gganimate)</a>
<a class="sourceLine" id="cb63-3" data-line-number="3">fig=<span class="kw">ggplot</span>( <span class="kw">melt</span>(d, <span class="dt">id.vars=</span><span class="st">"time"</span>), <span class="kw">aes</span>(time, value, <span class="dt">colour=</span>variable, <span class="dt">group=</span>variable)) <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">y =</span><span class="st">"state"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</a>
<a class="sourceLine" id="cb63-4" data-line-number="4">fig <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st">  </span><span class="kw">transition_time</span>(<span class="dt">time=</span>time) <span class="op">+</span><span class="st"> </span><span class="kw">shadow_mark</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>One famous random walk model with a finite number of states is the <em>gambler’s ruin problem</em> (first discussed by Pascal and Fermat). A gambler starts with a certain amount of money, say <span class="math inline">\(i\)</span> (state <span class="math inline">\(i\)</span>), and on each play, the gambler can either win a unit with probability <span class="math inline">\(q\)</span> or lose a unit with probability <span class="math inline">\(1-q\)</span>. The interest is in determining whether the gambler is ruined, i.e., loses all the money (the Markov chain moves to state zero) or wins a fortune <span class="math inline">\(N\)</span> (the Markov chain moves into the state <span class="math inline">\(N&gt;i\)</span>). The probability transition matrix is<label for="tufte-sn-280" class="margin-toggle sidenote-number">280</label><input type="checkbox" id="tufte-sn-280" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">280</span> The first and the last row correspond to the termination of the game, either ruining or winning. They give a kind of boundaries to the gambler/random walker, so they are known as a <em>boundary condition</em> of this probability transition matrix.</span> <span class="math display">\[\mathbf{P}=\left[\begin{array}{ccccccc}
1 &amp; 0 &amp; 0 &amp; \cdots\\
1-q &amp; 0 &amp; q &amp; 0 &amp; \cdots\\
0 &amp; 1-q &amp; 0 &amp; q &amp; 0 &amp; \cdots\\
\vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots\\
0 &amp; \cdots &amp;  &amp; 1-q &amp; 0 &amp; q &amp; 0\\
0 &amp; \cdots &amp;  &amp; 0 &amp; 1-q &amp; 0 &amp; q\\
0 &amp; \cdots &amp;  &amp; 0 &amp; 0 &amp; 0 &amp; 1
\end{array}\right].\]</span>
We can see that the chain cannot reach the other states once it visits either the state <span class="math inline">\(0\)</span> or <span class="math inline">\(N\)</span>. That means the chain is not <strong>irreducible</strong>. The chain will eventually be absorbed by either state <span class="math inline">\(0\)</span> or <span class="math inline">\(N\)</span>. So we would expect that the chain has at least two <strong>stationary probabilities</strong>, one telling the evolution towards winning and the other towards losing. Since there are two stationary probabilities, there will be two <strong>left-hand eigenvectors</strong> associating with the unit eigenvalue. Moreover, the existence of such two <strong>left-hand eigenvectors</strong> indicates that the chain cannot make <span class="math inline">\(\mathbf{u}^\top(0)\mathbf{P}^{t}\)</span> converge independent of the initial <span class="math inline">\(\mathbf{u}(0)\)</span>.<label for="tufte-sn-281" class="margin-toggle sidenote-number">281</label><input type="checkbox" id="tufte-sn-281" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">281</span> If the initial is the absorbing state, either <span class="math inline">\(0\)</span> or <span class="math inline">\(N\)</span>, the chain will converge.</span> The following numerical result and figure <a href="ch-UnMulti.html#fig:rw1">13.7</a> verifies the above statement (two <strong>stationary probabilities</strong> and <span class="math inline">\(\mathbf{P}^{t}\)</span> does not converge).</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:rw1"></span>
<img src="fig/Part3/rw1.gif" alt="Evolution of the probability transition matrix for the Gambler's ruining problem " width="100%"><!--
<p class="caption marginnote">-->Figure 13.7: Evolution of the probability transition matrix for the Gambler’s ruining problem <!--</p>-->
<!--</div>--></span>
</p>
<div class="solution">
<p class="solution-begin">
Gambler’s ruining problem <span id="sol-start-65" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-65', 'sol-start-65')"></span>
</p>
<div id="sol-body-65" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1"><span class="co"># two unit eigenvalues</span></a>
<a class="sourceLine" id="cb64-2" data-line-number="2">N=<span class="dv">10</span>;  P=<span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>N,<span class="dt">ncol=</span>N);</a>
<a class="sourceLine" id="cb64-3" data-line-number="3">q=<span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb64-4" data-line-number="4"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>(N<span class="dv">-1</span>)){</a>
<a class="sourceLine" id="cb64-5" data-line-number="5">    P[i<span class="op">+</span><span class="dv">1</span>,i]=q;</a>
<a class="sourceLine" id="cb64-6" data-line-number="6">    P[i<span class="dv">-1</span>,i]=<span class="dv">1</span><span class="op">-</span>q</a>
<a class="sourceLine" id="cb64-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb64-8" data-line-number="8"><span class="co"># Boundary conditions</span></a>
<a class="sourceLine" id="cb64-9" data-line-number="9">P[<span class="dv">1</span>,<span class="dv">1</span>]=<span class="dv">1</span>; P[<span class="dv">2</span>,<span class="dv">1</span>]=<span class="fl">0.5</span>;P[<span class="dv">1</span>,<span class="dv">2</span>]=<span class="dv">0</span>;</a>
<a class="sourceLine" id="cb64-10" data-line-number="10">P[N,N]=<span class="dv">1</span>;P[N<span class="dv">-1</span>,N]=<span class="fl">0.5</span>; P[N,N<span class="dv">-1</span>]=<span class="dv">0</span></a>
<a class="sourceLine" id="cb64-11" data-line-number="11"></a>
<a class="sourceLine" id="cb64-12" data-line-number="12"><span class="co"># Eigenvalues and left-hand eigenvectors</span></a>
<a class="sourceLine" id="cb64-13" data-line-number="13"><span class="kw">eigen</span>(<span class="kw">t</span>(P))</a></code></pre></div>
<pre><code>## eigen() decomposition
## $values
##  [1]  1.0000000  1.0000000 -0.9396926  0.9396926  0.7660444 -0.7660444
##  [7] -0.5000000  0.5000000 -0.1736482  0.1736482
## 
## $vectors
##       [,1] [,2]        [,3]       [,4]       [,5]        [,6]
##  [1,]    1    0  0.04148907 -0.6250437 -0.4775711 -0.08516412
##  [2,]    0    0 -0.16095207  0.0753895  0.2234608  0.30080723
##  [3,]    0    0  0.30249095  0.1416859  0.3423619 -0.46086341
##  [4,]    0    0 -0.40754495  0.1908929  0.3010680  0.40527648
##  [5,]    0    0  0.46344302  0.2170754  0.1189010 -0.16005618
##  [6,]    0    0 -0.46344302  0.2170754 -0.1189010 -0.16005618
##  [7,]    0    0  0.40754495  0.1908929 -0.3010680  0.40527648
##  [8,]    0    0 -0.30249095  0.1416859 -0.3423619 -0.46086341
##  [9,]    0    0  0.16095207  0.0753895 -0.2234608  0.30080723
## [10,]    0    1 -0.04148907 -0.6250437  0.4775711 -0.08516412
##                [,7]          [,8]       [,9]      [,10]
##  [1,]  1.336306e-01  3.535534e-01  0.1904676 -0.2610549
##  [2,] -4.008919e-01 -3.535534e-01 -0.4470840  0.4314464
##  [3,]  4.008919e-01 -3.535534e-01  0.1552706  0.1498398
##  [4,]  5.597455e-16 -4.645746e-17  0.3931590 -0.3794076
##  [5,] -4.008919e-01  3.535534e-01 -0.2918133 -0.2816066
##  [6,]  4.008919e-01  3.535534e-01 -0.2918133  0.2816066
##  [7,]  5.070096e-16  2.748659e-16  0.3931590  0.3794076
##  [8,] -4.008919e-01 -3.535534e-01  0.1552706 -0.1498398
##  [9,]  4.008919e-01 -3.535534e-01 -0.4470840 -0.4314464
## [10,] -1.336306e-01  3.535534e-01  0.1904676  0.2610549</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1">Pplot=<span class="kw">Matrix</span>(P, <span class="dt">sparse=</span><span class="ot">TRUE</span>); <span class="kw">image</span>(Pplot, <span class="dt">main=</span><span class="st">"t=1"</span>)</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The <strong>gambler’s ruin problem</strong> shows when a Markov chain is not <strong>irreducible</strong>, there will exist more than one <strong>stationary probability</strong>. However, even if the chain is <strong>irreducible</strong>, namely the unit eigenvalue only associates with one <strong>left-hand eigenvector</strong> (the stationary probability), the chain’s convergence may fail due to the periodic effect created by other eigenvectors associating with the <a href="ch-eigen.html#sub:diag">principal eigenvalue</a>.</p>
<p>In chapter <a href="ch-eigen.html#sub:diag">12.2</a>, we have seen that the negative and imaginary eigenvalues generate the fluctuations or oscillations in the dynamical systems. When these negative and imaginary eigenvalues have their absolute values as one, the fluctuating or oscillating movements will turn into cycles.</p>
<p>We can modify the previous <strong>gambler’s ruin problem</strong> into a cyclic <strong>random walk</strong> model. Note that the boundary values of the <a href="ch-UnMulti.html#sub:Markov">probability transition matrix</a> make the chain absorb at states <span class="math inline">\(0\)</span> and <span class="math inline">\(N\)</span>, and invalidates the <strong>irreducibility</strong>.</p>
<p>Let’s consider the following probability transition matrix
<span class="math display">\[
\mathbf{P}=\left[\begin{array}{ccccccc}
0 &amp; 1 &amp; 0 &amp; \cdots\\
1-q &amp; 0 &amp; q &amp; 0 &amp; \cdots\\
0 &amp; 1-q &amp; 0 &amp; q &amp; 0 &amp; \cdots\\
\vdots &amp;  &amp; \ddots &amp; \ddots &amp; \ddots\\
0 &amp; \cdots &amp;  &amp; 0 &amp; 1-q &amp; 0 &amp; q\\
1 &amp; \cdots &amp;  &amp; 0 &amp; 0 &amp; 0 &amp; 0
\end{array}\right]
\]</span>
where the first row says that the walker can always recover from the bankruptcy (from state <span class="math inline">\(0\)</span> to state <span class="math inline">\(1\)</span>), and the last row says that the walker will become bankrupt at the peak fortune <span class="math inline">\(N\)</span> (from state <span class="math inline">\(N\)</span> to state <span class="math inline">\(0\)</span>), a perpetually destroying and regenerating walker. The modification of the boundary values makes the chain <strong>irreducible</strong>. However, the transition from <span class="math inline">\(N\)</span> to <span class="math inline">\(0\)</span> creates a cyclic effect: the end leads to the beginning (<em>hen to pan</em>).</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:rwnet"></span>
<img src="fig/Part3/rwnet.png" alt="Network representation of two random walk models   " width="100%"><!--
<p class="caption marginnote">-->Figure 13.8: Network representation of two random walk models <!--</p>-->
<!--</div>--></span>
</p>
<p>Currently, the <a href="ch-eigen.html#sub:diag">principal eigenvalues</a> have two components, <span class="math inline">\(1\)</span> and <span class="math inline">\(-1\)</span>. The <strong>left-hand eigenvector</strong> introduced by <span class="math inline">\(-1\)</span> contains negative entries, and it cannot be a <strong>probability vector</strong>. So there is only one <strong>stationary probability</strong> in this Markov chain. Although the <strong>stationary probability</strong> is unique, the eigenvalue <span class="math inline">\(-1\)</span> disturbs the convergence by bringing in a two-period cycle to the chain.<label for="tufte-sn-282" class="margin-toggle sidenote-number">282</label><input type="checkbox" id="tufte-sn-282" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">282</span> For the left-hand eigenvector <span class="math inline">\(\mathbf{u}\)</span> from <span class="math inline">\(\mathbf{u}^\top \mathbf{P}= - \mathbf{u}^\top\)</span>, the two-period cycle comes from the fact that <span class="math inline">\(\mathbf{u}^\top \mathbf{P}^{2k}= (-)^{2k} \mathbf{u}^\top=\mathbf{u}^\top\)</span> for any integer <span class="math inline">\(k\)</span>.</span></p>
<p>The two-period cycle implies that this <strong>irreducible</strong> Markov chain is not <strong>aperiodic</strong>. Therefore, the convergence of <span class="math inline">\(\mathbf{P}^{t}\)</span> does not hold, see figure <a href="ch-UnMulti.html#fig:rw2">13.9</a>. In other words, we shouldn’t expect any <span class="math inline">\(\mathbf{u}(0)\)</span> will converge to the same <span class="math inline">\(\mathbf{u}(t)\)</span> for this chain, as the limit
<span class="math display">\[\lim_{t\rightarrow\infty}\mathbf{u}^{\top}(0)\mathbf{P}^{t}=\lim_{t\rightarrow\infty}\mathbf{u}^{\top}(0)\mathbf{P}^{t+2}\neq\lim_{t\rightarrow\infty}\mathbf{u}^{\top}(0)\mathbf{P}^{t+1}=\lim_{t\rightarrow\infty}\mathbf{u}^{\top}(0)\mathbf{P}^{t+3}\]</span>
cannot be unique.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:rw2"></span>
<img src="fig/Part3/rw2.gif" alt="Evolution of the probability transition matrix for the Ouroboros " width="100%"><!--
<p class="caption marginnote">-->Figure 13.9: Evolution of the probability transition matrix for the Ouroboros <!--</p>-->
<!--</div>--></span>
</p>
<div class="solution">
<p class="solution-begin">
Ouroboros <span id="sol-start-66" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-66', 'sol-start-66')"></span>
</p>
<div id="sol-body-66" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="co"># eigenvalues: 1 and -1; period 2</span></a>
<a class="sourceLine" id="cb67-2" data-line-number="2">P =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb67-3" data-line-number="3">             <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb67-4" data-line-number="4">             <span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="fl">0.5</span>,</a>
<a class="sourceLine" id="cb67-5" data-line-number="5">             <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">nrow=</span><span class="dv">4</span>, <span class="dt">byrow=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb67-6" data-line-number="6"><span class="kw">eigen</span>(<span class="kw">t</span>(P))</a></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1] -1+0.0i  1+0.0i  0+0.5i  0-0.5i
## 
## $vectors
##               [,1]         [,2]      [,3]      [,4]
## [1,]  0.5477226+0i 0.5477226+0i  0.0-0.5i  0.0+0.5i
## [2,] -0.7302967+0i 0.7302967+0i -0.5-0.0i -0.5+0.0i
## [3,]  0.3651484+0i 0.3651484+0i  0.0+0.5i  0.0-0.5i
## [4,] -0.1825742+0i 0.1825742+0i  0.5+0.0i  0.5+0.0i</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1">P<span class="op">%^%</span><span class="dv">25</span></a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]  0.0  0.8  0.0  0.2
## [2,]  0.6  0.0  0.4  0.0
## [3,]  0.0  0.8  0.0  0.2
## [4,]  0.6  0.0  0.4  0.0</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1">P<span class="op">%^%</span><span class="dv">26</span></a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]  0.6  0.0  0.4  0.0
## [2,]  0.0  0.8  0.0  0.2
## [3,]  0.6  0.0  0.4  0.0
## [4,]  0.0  0.8  0.0  0.2</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1">P<span class="op">%^%</span><span class="dv">27</span></a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]  0.0  0.8  0.0  0.2
## [2,]  0.6  0.0  0.4  0.0
## [3,]  0.0  0.8  0.0  0.2
## [4,]  0.6  0.0  0.4  0.0</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" data-line-number="1">u2.eigen=<span class="kw">eigen</span>(<span class="kw">t</span>(P))<span class="op">$</span>vectors[,<span class="dv">2</span>]</a>
<a class="sourceLine" id="cb75-2" data-line-number="2">u2=u2.eigen<span class="op">/</span>(<span class="kw">sum</span>(u2.eigen))</a>
<a class="sourceLine" id="cb75-3" data-line-number="3"></a>
<a class="sourceLine" id="cb75-4" data-line-number="4"><span class="kw">c</span>(<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>)<span class="op">%*%</span>(P<span class="op">%^%</span><span class="dv">1000</span>)</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,]  0.3  0.4  0.2  0.1</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" data-line-number="1"><span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.6</span>)<span class="op">%*%</span>(P<span class="op">%^%</span><span class="dv">1000</span>)</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,] 0.18 0.56 0.12 0.14</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" data-line-number="1"><span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.6</span>)<span class="op">%*%</span>(P<span class="op">%^%</span><span class="dv">1001</span>)</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,] 0.42 0.24 0.28 0.06</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" data-line-number="1"><span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>,<span class="fl">0.6</span>)<span class="op">%*%</span>(P<span class="op">%^%</span><span class="dv">1002</span>)</a></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4]
## [1,] 0.18 0.56 0.12 0.14</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1"><span class="co"># Network Plot</span></a>
<a class="sourceLine" id="cb83-2" data-line-number="2">N=<span class="dv">10</span>;  P=<span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>N,<span class="dt">ncol=</span>N);</a>
<a class="sourceLine" id="cb83-3" data-line-number="3">q=<span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb83-4" data-line-number="4"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>(N<span class="dv">-1</span>)){</a>
<a class="sourceLine" id="cb83-5" data-line-number="5">    P[i<span class="op">+</span><span class="dv">1</span>,i]=q;</a>
<a class="sourceLine" id="cb83-6" data-line-number="6">    P[i<span class="dv">-1</span>,i]=<span class="dv">1</span><span class="op">-</span>q</a>
<a class="sourceLine" id="cb83-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb83-8" data-line-number="8"><span class="co"># Boundary conditions</span></a>
<a class="sourceLine" id="cb83-9" data-line-number="9">P[<span class="dv">1</span>,<span class="dv">1</span>]=<span class="dv">1</span>; P[<span class="dv">2</span>,<span class="dv">1</span>]=<span class="fl">0.5</span>;P[<span class="dv">1</span>,<span class="dv">2</span>]=<span class="dv">0</span>;</a>
<a class="sourceLine" id="cb83-10" data-line-number="10">P[N,N]=<span class="dv">1</span>;P[N<span class="dv">-1</span>,N]=<span class="fl">0.5</span>; P[N,N<span class="dv">-1</span>]=<span class="dv">0</span></a>
<a class="sourceLine" id="cb83-11" data-line-number="11"></a>
<a class="sourceLine" id="cb83-12" data-line-number="12">N=<span class="dv">10</span>;  Q=<span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>N,<span class="dt">ncol=</span>N);</a>
<a class="sourceLine" id="cb83-13" data-line-number="13">q=<span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb83-14" data-line-number="14"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>(N<span class="dv">-1</span>)){</a>
<a class="sourceLine" id="cb83-15" data-line-number="15">    Q[i<span class="op">+</span><span class="dv">1</span>,i]=q;</a>
<a class="sourceLine" id="cb83-16" data-line-number="16">    Q[i<span class="dv">-1</span>,i]=<span class="dv">1</span><span class="op">-</span>q</a>
<a class="sourceLine" id="cb83-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb83-18" data-line-number="18"><span class="co"># Boundary conditions</span></a>
<a class="sourceLine" id="cb83-19" data-line-number="19">Q[<span class="dv">1</span>,<span class="dv">1</span>]=<span class="dv">0</span>; Q[<span class="dv">2</span>,<span class="dv">1</span>]=<span class="fl">0.5</span>;Q[<span class="dv">1</span>,<span class="dv">2</span>]=<span class="dv">1</span>;</a>
<a class="sourceLine" id="cb83-20" data-line-number="20">Q[N,N]=<span class="dv">0</span>;Q[N<span class="dv">-1</span>,N]=<span class="fl">0.5</span>; Q[N,N<span class="dv">-1</span>]=<span class="dv">0</span>; Q[N,<span class="dv">1</span>]=<span class="dv">1</span></a>
<a class="sourceLine" id="cb83-21" data-line-number="21"></a>
<a class="sourceLine" id="cb83-22" data-line-number="22"><span class="kw">library</span>(igraph)</a>
<a class="sourceLine" id="cb83-23" data-line-number="23">p1=<span class="kw">graph.adjacency</span>(P, <span class="st">"directed"</span>, <span class="dt">weighted =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb83-24" data-line-number="24">p2=<span class="kw">graph.adjacency</span>(Q, <span class="st">"directed"</span>, <span class="dt">weighted =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb83-25" data-line-number="25"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</a>
<a class="sourceLine" id="cb83-26" data-line-number="26"><span class="kw">plot</span>(p1, <span class="dt">layout=</span><span class="kw">layout_in_circle</span>(p1), <span class="dt">main=</span><span class="st">"Gambler's ruin"</span>, <span class="dt">vertex.color =</span> <span class="st">"gray90"</span>, <span class="dt">edge.arrow.size=</span><span class="fl">0.2</span>)</a>
<a class="sourceLine" id="cb83-27" data-line-number="27"><span class="kw">plot</span>(p2, <span class="dt">layout=</span><span class="kw">layout_in_circle</span>(p2), <span class="dt">main=</span><span class="st">"Ouroboros"</span>, <span class="dt">vertex.color =</span> <span class="st">"gray90"</span>, <span class="dt">edge.arrow.size=</span><span class="fl">0.2</span>)</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>To sum up, if we want to design a convergent finite-states Markov chain in which the limit of <span class="math inline">\(\mathbf{u}^\top(0)\mathbf{P}^t\)</span> will equal to the unique <strong>stationary probability</strong> and will be independent of the initial <span class="math inline">\(\mathbf{u}^\top(0)\)</span>, then we need to ensure that only one <strong>left-hand eigenvector</strong> associates with the <a href="ch-UnMulti.html#sub:Markov">principal eigenvalue</a> of this chain which means the chain is <strong>irreducible</strong> and <strong>aperiodic</strong>.</p>
<div class="solution">
<p class="solution-begin">
An irreducible and aperiodic random walk <span id="sol-start-67" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-67', 'sol-start-67')"></span>
</p>
<div id="sol-body-67" class="solution-body" style="display: none;">
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1">N=<span class="dv">10</span>;  P=<span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dt">nrow=</span>N,<span class="dt">ncol=</span>N);</a>
<a class="sourceLine" id="cb84-2" data-line-number="2">q=<span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb84-3" data-line-number="3"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>(N<span class="dv">-1</span>)){</a>
<a class="sourceLine" id="cb84-4" data-line-number="4">    P[i<span class="op">+</span><span class="dv">1</span>,i]=q;</a>
<a class="sourceLine" id="cb84-5" data-line-number="5">    P[i<span class="dv">-1</span>,i]=<span class="dv">1</span><span class="op">-</span>q</a>
<a class="sourceLine" id="cb84-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb84-7" data-line-number="7"><span class="co"># Boundary conditions for an irreducible and aperiodic Markov chain</span></a>
<a class="sourceLine" id="cb84-8" data-line-number="8">P[<span class="dv">1</span>,<span class="dv">1</span>]=<span class="fl">0.5</span>; P[<span class="dv">2</span>,<span class="dv">1</span>]=<span class="fl">0.5</span>;P[<span class="dv">1</span>,<span class="dv">2</span>]=<span class="fl">0.5</span>;</a>
<a class="sourceLine" id="cb84-9" data-line-number="9">P[N,N]=<span class="fl">0.5</span>;P[N<span class="dv">-1</span>,N]=<span class="fl">0.5</span>; P[N,N<span class="dv">-1</span>]=<span class="fl">0.5</span> </a>
<a class="sourceLine" id="cb84-10" data-line-number="10"><span class="kw">eigen</span>(<span class="kw">t</span>(P))<span class="op">$</span>values</a></code></pre></div>
<pre><code>##  [1]  1.000000e+00  9.510565e-01  8.090170e-01  5.877853e-01  3.090170e-01
##  [6] -4.440892e-16 -3.090170e-01 -5.877853e-01 -8.090170e-01 -9.510565e-01</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1">u.eigen =<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">t</span>(P))<span class="op">$</span>vector[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb86-2" data-line-number="2">u =<span class="st"> </span>u.eigen<span class="op">/</span><span class="kw">sum</span>(u.eigen); u</a></code></pre></div>
<pre><code>##  [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1">P<span class="op">%^%</span><span class="dv">1000</span></a></code></pre></div>
<pre><code>##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
##  [1,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [2,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [3,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [4,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [5,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [6,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [7,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [8,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
##  [9,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1
## [10,]  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1   0.1</code></pre>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
</div>
<div id="sub:WLLN" class="section level2">
<h2>
<span class="header-section-number">13.4</span> Miscellaneous: Statistical Inductive Inference, Law of Large Numbers, Bayes’ Law, and Falsifiability</h2>
<p>The uncertainty of a <a href="ch-CalUn.html#sub:rv">random variable</a> <span class="math inline">\(X(\omega)\)</span> stems from the unobservable state <span class="math inline">\(\omega\)</span>. A natural question is if one can identify the invisible state <span class="math inline">\(\omega\)</span> or at least if one can extract some ideas about this state by observing <span class="math inline">\(X(\omega)\)</span>. Our previous attempt was to model a probability law <span class="math inline">\(\mathbb{P}\)</span> that is able to generate interesting <span class="math inline">\(X(\omega)\)</span> or <span class="math inline">\(X_t(\omega)\)</span>. Hence, our primary interest is about <span class="math inline">\(\mathbb{P}(X(\omega))\)</span>. In this section, let’s suppose that a contrary situation where we have little idea about the underlying law <span class="math inline">\(\mathbb{P}\)</span>, and our hope is to infer some structure of <span class="math inline">\(\mathbb{P}\)</span> from the observations of <span class="math inline">\(X(\omega)\)</span>. In other words, given a data vector <span class="math inline">\(\mathbf{x}\)</span> as the observations of <span class="math inline">\(X(\omega)\)</span>, now we (temporarily) switch our attention to the following <a href="ch-CalUn.html#sub:conProb">joint probability</a> <span class="math display">\[\Pr(\mathbf{x},\omega)\]</span> where <span class="math inline">\(\omega\in\Omega\)</span> is from the underlying <a href="sub-incomplete.html#sub:beyond2">probability space</a> <span class="math inline">\((\Omega,\sigma(\Omega),\mathbb{P})\)</span> of which we have no idea but in which we are interested.<label for="tufte-sn-283" class="margin-toggle sidenote-number">283</label><input type="checkbox" id="tufte-sn-283" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">283</span> The notation <span class="math inline">\(\Pr(\mathbf{x},\omega)\)</span> stands for the joint probability
<span class="math display">\[\Pr(X(\omega)=x_{1},\dots,X(\omega)=x_{n},\omega).\]</span>
Notice that the notation <span class="math inline">\(\Pr(\cdot,\omega)\)</span> distinguishes itself from the underlying probability law <span class="math inline">\(\mathbb{P}\)</span> because <span class="math inline">\(\Pr(X(\omega),\omega)\)</span> may not coincide with <span class="math inline">\(\mathbb{P}(X(\omega))\)</span>. This notation is inspired by the contents in Part II <span class="citation">Keynes (<a href="bibliography.html#ref-Keynes1921">1921</a>)</span> and Chapter 8 <span class="citation">Popper (<a href="bibliography.html#ref-Popper1959">1959</a>)</span>. <span class="citation">Keynes (<a href="bibliography.html#ref-Keynes1921">1921</a>)</span> and <span class="citation">Popper (<a href="bibliography.html#ref-Popper1959">1959</a>)</span> both consider unconditional probability as a probability conditional on some logical truth. In terms of Keynes’ and Poppe’s symbol, the joint probability relates to <span class="math inline">\(\Pr(\mathbf{x}/\omega)\)</span> and <span class="math inline">\(_{\omega}\Pr(\mathbf{x})\)</span>, respectively.</span> This kind of problem is known as <em>statistical inference</em>.</p>
<p>The theory of statistics can be seen in two parts, descriptive and inductive.<label for="tufte-sn-284" class="margin-toggle sidenote-number">284</label><input type="checkbox" id="tufte-sn-284" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">284</span> The emergence of statistics related to the needs of a systematic study of quantitative facts about the state (the country) in the early 19th century. In the first half of the 20th century, the development of statistical methodology was pushed forward by the rise of British empiricism. Unlike probability, statistics adopt a substantive empirical undertaking.</span> The former describes certain principal features of large groups of phenomena and provides measurements and summaries of various characters and events of interests. The latter uses different kinds of inferences leading from a set of empirical statements of <a href="sub-logic.html#sub:logic">premises</a> to some general statements of <a href="sub-logic.html#sub:logic">conclusion</a>. The empirical statement refers to the values of the observable data, namely <span class="math inline">\(\mathbf{x}\)</span> (in statistics, it is called a <em>sample</em>), and the general conclusion refers to all possible values generated by <span class="math inline">\(\omega\)</span>, namely <span class="math inline">\(X(\omega)\)</span> (in statistics, it is called a <em>population</em>). In other words, the <strong>statistical inference</strong> seeks to extend its descriptive power to a realm that is beyond observing the <strong>sample</strong>. Large parts of data analysis are inferential in the <strong>sample-to-population</strong> sense.</p>
<p>However, the <em>problem of induction</em> may arise when an inference tends to generalize an empirical finding to a universal law. For example, extending the scope of a statistical relation, i.e., a correlation or a regression, of two objects, to the one of an existential <a href="sub-inferknow.html#determinism">causality</a> may cause the <strong>problem of induction</strong>. To go deeper for this discussion, let’s consider two standard statistical inferential paradigms.</p>
<p>We will start with the joint probability <span class="math inline">\(\Pr(\mathbf{x},\omega)\)</span>, an unconditional probability. For an unconditional probability, there is always one <a href="ch-CalUn.html#sub:conProb">conditional probability</a> lurking in the background. For <span class="math inline">\(\Pr(\mathbf{x},\omega)\)</span>, the conditional probability of interest is <span class="math inline">\(\Pr(\mathbf{x}|\omega)\)</span> called the <strong>likelihood</strong> in statistics. The <em>likelihood</em> is a probability of the sample conditioning on some specification of the underlying probability space. The two statistical inferential paradigms are about making inference of <span class="math inline">\(\omega\)</span> by two different ways of utilizing the <strong>likelihoods</strong>.</p>
<p><span class="newthought">Hypothesis testing </span></p>
<p>The first paradigm is known as <em>hypothesis testing</em>, with its emphasis on justifying some hypothetical claims. One claims a hypothesis or a theory and then tests it by data. The paradigm relies on two conflicting hypothetical claims regarding <span class="math inline">\(\omega\)</span>. One is called the <em>null hypothesis</em> <span class="math inline">\(H_{0}\)</span>, on which the primary interest of the test lies, and the other is called the <em>alternative hypothesis</em> <span class="math inline">\(H_{1}\)</span>. If <span class="math inline">\(\omega \in H_{0}\)</span>, then <span class="math inline">\(\omega \notin H_{1}\)</span>, and vice versa.<label for="tufte-sn-285" class="margin-toggle sidenote-number">285</label><input type="checkbox" id="tufte-sn-285" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">285</span> The motivation of designing such a binary structure relates to the <em>Kolmogorov’s zero–one law</em>. The law says that for an infinite sequence of <a href="ch-CalUn.html#sub:divRV">independent identical random variables</a>, an event as a convergent value of the sequence (called a tail event) must occur with probability <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>, and there is no intermediate value.</span></p>
<p>By conditioning on these hypotheses, the joint probability becomes <span class="math display">\[\Pr(\mathbf{x},\omega)=\Pr(\mathbf{x}|\omega\in H_{0})\Pr(\omega\in H_{0})+\Pr(\mathbf{x}|\omega\in H_{1})\Pr(\omega\in H_{1}).\]</span> As the hypotheses are conflicting, we have either <span class="math inline">\(\Pr(\omega\in H_{0})=1\)</span> or <span class="math inline">\(\Pr(\omega\in H_{1})=1\)</span>. Thus, the above expression can be rewritten as:
<span class="math display">\[
\Pr(\mathbf{x},\omega)=\begin{cases}
\Pr(\mathbf{x}|\omega\in H_{0}) &amp; \mbox{ for }\omega\in H_{0},\\
\Pr(\mathbf{x}|\omega\in H_{1}) &amp; \mbox{ for }\omega\in H_{1}.
\end{cases}\]</span>
The joint probability <span class="math inline">\(\Pr(\mathbf{x},\omega)\)</span> is now decomposed into two categories of <strong>likelihoods</strong> <span class="math inline">\(\Pr(\mathbf{x}|\omega)\)</span>. In section <a href="ch-UnMulti.html#sub:Markov">13.2</a>, we have seen that any <a href="ch-CalUn.html#sub:conProb">conditional probability</a> of finite states can be expressed in a matrix form. One can design the following <span class="math inline">\(2\times 2\)</span> <a href="ch-UnMulti.html#sub:Markov">stochastic matrix</a> for <span class="math inline">\(\Pr(\mathbf{x}|\omega)\)</span> with two binary states:
<span class="math display" id="eq:hypo-1">\[\begin{align*}
&amp;\left[\begin{array}{cc}
\Pr(\mathbf{x}\in\mathcal{H}_{0}|\omega\in H_{0}) &amp; \Pr(\mathbf{x}\notin\mathcal{H}_{0}|\omega\in H_{0})\\
\Pr(\mathbf{x}\in\mathcal{H}_{0}|\omega\in H_{1}) &amp; \Pr(\mathbf{x}\notin\mathcal{H}_{0}|\omega\in H_{1})
\end{array}\right] \Rightarrow\\
&amp; \left[\begin{array}{cc}
\Pr(\theta(\mathbf{x})\in\Theta_{0}|\theta(\omega)\in H_{0}) &amp; \;\Pr(\theta(\mathbf{x})\notin\Theta_{0}|\theta(\omega)\in H_{0})\\
\Pr(\theta(\mathbf{x})\in\Theta_{0}|\theta(\omega)\in H_{1}) &amp; \;\Pr(\theta(\mathbf{x})\notin\Theta_{0}|\theta(\omega)\in H_{1})
\end{array}\right] \tag{13.5} \\
 &amp; = \left[\begin{array}{cc}
\mbox{p-value} &amp; \mbox{type I-error}\\
\mbox{type II-error} &amp; \mbox{power}
\end{array}\right].\\
\end{align*}
\]</span>
The implication sign “<span class="math inline">\(\Rightarrow\)</span>” in <a href="ch-UnMulti.html#eq:hypo-1">(13.5)</a> is about parameterization, which we will discuss later, and the second equality gives the usual terminology of the corresponding entries. The set <span class="math inline">\(\mathcal{H}_{0}\)</span> and <span class="math inline">\(\Theta_0\)</span> are defined as a set of the desired level of the probability within which the hypothetical <span class="math inline">\(\omega\)</span> lies. Such a desired level is called the <em>confidence level</em> under the <strong>null hypothesis</strong>.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:confidenceLevel"></span>
<img src="fig/Part3/ConfidenceLevel.gif" alt="Confidence level of" width="100%"><!--
<p class="caption marginnote">-->Figure 13.10: Confidence level of<!--</p>-->
<!--</div>--></span>
</p>
<p>For example, for one realization <span class="math inline">\(x\)</span>, if the <strong>null hypothesis</strong> <span class="math inline">\(H_{0}\)</span> is <span class="math inline">\(X(\omega)\sim\mathcal{N}(0,1)\)</span>, then at the <span class="math inline">\(95\%\)</span>-<strong>confidence level</strong>, we set <span class="math inline">\(\mathcal{H}_{0}=[-1.96,1.96]\)</span> as the interval for testing whether <span class="math inline">\(x \in \mathcal{H}_{0}\)</span>. If <span class="math inline">\(x\)</span> is realized from a <a href="ch-CalUn.html#sub:divRV">standard normal random variable</a>, there is a <span class="math inline">\(95\%\)</span>-<strong>likelihood</strong> that <span class="math inline">\(x \in \mathcal{H}_{0}\)</span>, see figure <a href="ch-UnMulti.html#fig:confidenceLevel">13.10</a>.</p>
<p>But for <span class="math inline">\(n\)</span>-independent identical trials, the <strong>likelihood</strong> <span class="math inline">\(\Pr(\mathbf{x}|\omega)\)</span> actually is a product <span class="math inline">\(\prod_{i=1}^{n}\Pr(x_{i}|\omega)\)</span>, which may be difficult for specifying the hypotheses.<label for="tufte-sn-286" class="margin-toggle sidenote-number">286</label><input type="checkbox" id="tufte-sn-286" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">286</span> For <span class="math inline">\(n=100\)</span>, even if <span class="math inline">\(\Pr(x_{i}\in\mathcal{H}_{0}|\omega\in H_{0})=0.95\)</span>, the product <span class="math inline">\((0.95)^{100}\approx0.06\)</span> is rather small. So at <span class="math inline">\(95\%\)</span>-<strong>confidence level</strong>, <span class="math inline">\(\mathcal{H}_0\)</span> must be too large to make <span class="math inline">\(\Pr(x_{i}\in\mathcal{H}_{0}|\omega\in H_{0})\)</span> closely to one. For such a large set <span class="math inline">\(\mathcal{H}_0\)</span>, say the whole real line <span class="math inline">\(\mathbb{R}\)</span>, the conflicting <strong>alternative hypothesis</strong> may not exist. That is, if the <strong>null hypothesis</strong> is <span class="math inline">\(X(\omega)\in \mathbb{R}\)</span>, the <strong>alternative hypothesis</strong> <span class="math inline">\(X(\omega)\notin \mathbb{R}\)</span> becomes a contradictory statement for a <a href="ch-CalUn.html#sub:rv">random variable</a> <span class="math inline">\(X(\omega):\Omega \rightarrow \mathbb{R}\)</span>.</span> In this case, one can switch to test a parameterized statistical estimator <span class="math inline">\(\theta(\mathbf{x})\)</span> (the same as previous notation <span class="math inline">\(\hat{\theta}\)</span>) that can deliver the information contained the <strong>population</strong> parameter <span class="math inline">\(\theta(\omega)\)</span>. For example, if the <strong>null hypothesis</strong> <span class="math inline">\(H_{0}\)</span> is <span class="math inline">\(X(\omega)\sim\mathcal{N}(\mu,\sigma^2)\)</span>, in an approximating sense, one can test the parameter <span class="math inline">\(\theta(\omega)=[\mu,\sigma^2]\)</span> with the statistical estimator <span class="math inline">\(\theta(\mathbf{x})\)</span>.<label for="tufte-sn-287" class="margin-toggle sidenote-number">287</label><input type="checkbox" id="tufte-sn-287" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">287</span> In fact, to verify a normal distribution, one needs infinitely many paramters. Apart from the first and the second <a href="ch-CalUn.html#sub:ex">moments</a>, (in principle) one also needs to verify that the higher <a href="ch-CalUn.html#sub:ex">moments</a> are all negligible. But the practical testing procedure simply looks for the first two. That’s why the parameterization of a test is treated as an implication step in <a href="ch-UnMulti.html#eq:hypo-1">(13.5)</a>.</span></p>
<p>The relations between <span class="math inline">\(\theta(\mathbf{x})\)</span> and <span class="math inline">\(\theta(\omega)\)</span> are established through some convergent arguments (along with the <strong>zero-one law</strong>). To catch a glimpse of the idea, we will illustrate the reasoning procedure through the (weak) <strong>law of large numbers</strong>. Let’s assume that the <strong>null hypothesis</strong> is <span class="math inline">\(H_{0}=\{\omega:\:\mathbb{E}[X(\omega)]=\mu\}\)</span> for some real number <span class="math inline">\(\mu\)</span>. In other words, the <strong>null hypothesis</strong> is to test the <a href="ch-CalUn.html#sub:ex">mean</a> parameter: <span class="math inline">\(\theta(\omega)=\mathbb{E}[X(\omega)]=\mu\)</span>. The statistical estimator of the <a href="ch-CalUn.html#sub:ex">mean</a> parameter is <span class="math inline">\(\theta(\mathbf{x})=\sum_{i=1}^{n}x_{i}/n\)</span>. The (weak) <em>law of large numbers</em> says that if the samples <span class="math inline">\(\{ x_1,\dots,x_n\}\)</span> are the <a href="ch-CalUn.html#sub:divRV">independent</a> realizations of a random variable <span class="math inline">\(X(\omega)\)</span>, then<label for="tufte-sn-288" class="margin-toggle sidenote-number">288</label><input type="checkbox" id="tufte-sn-288" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">288</span> It says that the event of <span class="math inline">\(\sum_{i=1}^{n}x_{i}/n \neq \mathbb{E}[X(\omega)]\)</span> has zero probability of happening when <span class="math inline">\(n\)</span> goes to infinite. One can consider such an event as the tail event in the <strong>Kolmogorov’s zero–one law</strong>.</span>
<span class="math display">\[\lim_{n\rightarrow\infty}\Pr\left\{ \left|\sum_{i=1}^{n}\frac{x_{i}}{n}-\mathbb{E}[X(\omega)]\right|\geq\epsilon\right\}=0.\]</span></p>
<p>In particular, when <span class="math inline">\(\theta(\cdot)\)</span> stands for the parameterization function of the mean parameter, the (weak) <strong>law of large numbers</strong> becomes<label for="tufte-sn-289" class="margin-toggle sidenote-number">289</label><input type="checkbox" id="tufte-sn-289" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">289</span> For a general estimator <span class="math inline">\(\theta(\mathbf{x})\)</span>, if <span class="math inline">\(\lim_{n\rightarrow\infty}\Pr\left\{ \left|\theta(\mathbf{x})-\theta(\omega)\right|\geq\epsilon\right\}\)</span> , then <span class="math inline">\(\theta(\mathbf{x})\)</span> is called the <em>consistent estimator</em> of <span class="math inline">\(\theta(\omega)\)</span>.</span>
<span class="math display">\[\lim_{n\rightarrow\infty}\Pr\left\{ \left|\theta(\mathbf{x})-\theta(\omega)\right|\geq\epsilon\right\} =0,\]</span> which says the mean estimator is <strong>consistent</strong> with the <strong>population</strong> mean.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:WLLN"></span>
<img src="fig/Part3/WLLN.gif" alt="20 simulations for the estimators of the mean parameter 0.5" width="100%"><!--
<p class="caption marginnote">-->Figure 13.11: 20 simulations for the estimators of the mean parameter 0.5<!--</p>-->
<!--</div>--></span>
</p>
<p>Figure <a href="ch-UnMulti.html#fig:WLLN">13.11</a> shows the paths of <span class="math inline">\(20\)</span> simulators. Each path stands for a single simulator that estimates the mean under the different sizes of samples. We can see that those paths tend to converge to <span class="math inline">\(\theta(\omega)=0.5\)</span>.<label for="tufte-sn-290" class="margin-toggle sidenote-number">290</label><input type="checkbox" id="tufte-sn-290" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">290</span> Figure <a href="ch-UnMulti.html#fig:WLLN">13.11</a> also shows that when the sample size is not so large, the difference <span class="math inline">\(\theta(\mathbf{x})\)</span> and <span class="math inline">\(\theta(\omega)\)</span> could be significantly different from zero. That is why we still need a set, say <span class="math inline">\([-1.96+\mu,\:1.96+\mu]\)</span>, to incorporate the qualified <span class="math inline">\(\theta(\mathbf{x})\)</span>. In fact, slower the convergence of the estimator by a factor <span class="math inline">\(\sqrt{n}\)</span>, the statistics <span class="math inline">\(\sum_{i=1}^{n}x_{i}/\sqrt{n}-\mu\)</span> will converge to <span class="math inline">\(\mathcal{N}(0,1)\)</span> by the <strong>central limit theorem</strong> in CH[?]. That means <span class="math inline">\(95%\)</span> of <span class="math inline">\(\theta(\mathbf{x})-\mu\)</span> under the <strong>null hypothesis</strong> <span class="math inline">\(H_{0}=\{\omega:\:\mathbb{E}[X(\omega)]=\mu\}\)</span> will locate on the interval <span class="math inline">\([-1.96,\:1.96]\)</span>.</span></p>
<div class="solution">
<p class="solution-begin">
Proof of weak law of large numbers <span id="sol-start-68" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-68', 'sol-start-68')"></span>
</p>
<div id="sol-body-68" class="solution-body" style="display: none;">
<p>Suppose <span class="math inline">\(X\)</span> is a random variable with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, and suppose that <span class="math inline">\(h(\cdot)\)</span> is a non-decreasing non-negative function, and that the expectation <span class="math inline">\(\mathbb{E}[h(X)]=\int_{-\infty}^{\infty}h(x)f(x)\mbox{d}x\)</span> exists with the <a href="ch-CalUn.html#sub:rv">probability density function</a> <span class="math inline">\(f(x)\)</span>.</p>
<p>By the non-decreasing non-negative property of <span class="math inline">\(h(\cdot)\)</span>, we have <span class="math display">\[\begin{align*}
\int_{-\infty}^{\infty}h(x)f(x)\mbox{d}x\geq\int_{a}^{\infty}h(x)f(x)\mbox{d}x\geq \\ h(a)\int_{a}^{\infty}f(x)\mbox{d}x=h(a)\Pr\{X\geq a\}.
\end{align*}\]</span>
This leads directly to the following inequality called <em>Markov inequality</em>:<label for="tufte-sn-291" class="margin-toggle sidenote-number">291</label><input type="checkbox" id="tufte-sn-291" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">291</span> If we set <span class="math inline">\(h(x)=|x|\)</span>, we will have the standard <strong>Markov inequality</strong>: <span class="math display">\[\Pr(|X(\omega)|\geq a)\leq\frac{\mathbb{E}[|X|]}{a}.\]</span></span>
<span class="math display">\[\Pr\{X\geq a\}\leq\frac{\mathbb{E}[h(X)]}{h(a)}, \, \mbox{ for }a&gt;0.\]</span></p>
<p>Now, let <span class="math inline">\(Y=(X-\mathbb{E}[X])^{2}\)</span> so that <span class="math inline">\(Y\)</span> is non-negative, and let <span class="math inline">\(h(Y)=Y\)</span>.
<strong>Markov inequality</strong> gives
<span class="math display">\[\Pr\{Y\geq a^2\}\leq\frac{\mathbb{E}[Y]}{a^2}.\]</span>
Notice that <span class="math inline">\(\mathbb{E}[Y]=\sigma^2\)</span> and
<span class="math display">\[\Pr\{Y\geq a^2\} =\Pr\{(X-\mathbb{E}[X])^2\geq a^2\}=\Pr\{|X-\mathbb{E}[X]|\geq a\}.\]</span>
So we have
<span class="math display">\[\Pr\{|X-\mathbb{E}[X]| \geq a\}\leq\frac{\sigma^2}{a^2}.\]</span>
As <span class="math inline">\(a\)</span> is an arbitrary non-negative number, so we can set <span class="math inline">\(a= \epsilon\)</span>, and the Markov inequality becomes
<span class="math display">\[\Pr\{|X-\mathbb{E}[X]|\geq \epsilon \}\leq\frac{\sigma^2}{\epsilon^2}.\]</span>
Now instead of using one <span class="math inline">\(X\)</span>, we use the average of <span class="math inline">\(n\)</span>-independent identical <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\sum_i X_i /n\)</span>. The mean of <span class="math inline">\(\sum_i X_i /n\)</span> is still <span class="math inline">\(\mu\)</span>, but the variance of <span class="math inline">\(\sum_i X_i /n\)</span> becomes <span class="math inline">\(\sigma^2/n\)</span>. So the above inequality becomes <span class="math display">\[\Pr\left\{\left|\sum_{i=1}^{n}\frac{X_i}{n}-\mathbb{E}[X]\right|\geq \epsilon \right\}\leq\frac{\sigma^2}{n\epsilon^2}.\]</span> In the experiment, <span class="math inline">\(\sum_i X_i /n\)</span> is realized by <span class="math inline">\(\sum_i x_i /n\)</span>. And for any <span class="math inline">\(\epsilon\)</span>, there is <span class="math inline">\(\lim_{n\rightarrow \infty}\sigma^2/n\epsilon^2=0\)</span>. The result follows.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The paradigm of <strong>hypothesis testing</strong> plays a crucial role in understanding the frequency interpretation of probability. The testing statistics <span class="math inline">\(\theta(\mathbf{x})\)</span> actually depends on the <strong>frequency</strong> of counting the events. The frequency is an objective property that could be empirically measured and sampled. Thus, the empirical motivated <strong>hypothesis testing</strong> is considered to follow the objective <strong>frequentism</strong> spirit. A short discussion about this connection is given below.</p>
<div class="solution">
<p class="solution-begin">
Frequentism and empiricism in terms of estimators <span id="sol-start-69" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-69', 'sol-start-69')"></span>
</p>
<div id="sol-body-69" class="solution-body" style="display: none;">
<p>Traditionally, the estimator <span class="math inline">\(\theta(\mathbf{x})\)</span> was written as <span class="math inline">\(\theta(\hat{F})\)</span>, where <span class="math inline">\(\hat{F}\)</span> is about the frequency of probability events.</p>
<p>Suppose that we run a long sequence of <span class="math inline">\(n\)</span> trials, on each of which <span class="math inline">\(\mathcal{A}\)</span> might occur or not. It is natural to identify the probability of <span class="math inline">\(\mathcal{A}\)</span> with the <em>relative frequency</em> of trials on which the event occurs:
<span class="math display">\[\Pr(\mathcal{A})=\frac{\mbox{number of }\mathcal{A}}{n}.\]</span></p>
<p>For a random variable <span class="math inline">\(X(\omega)\)</span>, notice that the probability law induces the distribution function <span class="math inline">\(\mathbb{P}(X(\omega)\leq a)=\int_{-\infty}^{a}f(x)dx=F(a)\)</span>
where <span class="math inline">\(f(\cdot)\)</span> is the <a href="ch-CalUn.html#sub:rv">probability density function</a> <span class="math inline">\(\mathbb{P}(x&lt;X(\omega)&lt;x+dx)=f(x)dx\)</span>.</p>
<p>For an <a href="sub-set-theory.html#sub:func">indicator function</a>, one can derive the following expression
<span class="math display">\[\mathbb{E}[\mathbf{1}_{\{X(\omega)\leq a\}}]=\int[\mathbf{1}_{\{x\leq a\}}]f(x)dx=\int_{-\infty}^{a}f(x)dx=\mathbb{P}(X(\omega)\leq a).\]</span>
Because <span class="math inline">\(F(\cdot)\)</span> is a continuous function, and it is an integral, we can approximate <span class="math inline">\(F(\cdot)\)</span> using the same logic as we did for defining the <a href="sub-calculus.html#sub:diffInt">Riemann integration</a> by bins: approximating the integral by the averages.</p>
<p>Consider the following sum of indicator functions <span class="math display">\[\hat{F}(x)=\frac{\sum_{i=1}^{n}\mathbf{1}_{\{x_{i}\leq x\}}}{n}.\]</span>
The function is called the <em>empirical distribution function</em>.<label for="tufte-sn-292" class="margin-toggle sidenote-number">292</label><input type="checkbox" id="tufte-sn-292" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">292</span> Because <span class="math inline">\(\hat{F}\)</span> is from a discrete function, the probability derived from this discrete distribution is a <a href="ch-CalUn.html#sub:rv">probability mass function</a> <span class="math inline">\(f\)</span>:
<span class="math display">\[\hat{f}(a)=\frac{\sum_{i=1}^{n}\mathbf{1}_{\{X_{i}=a\}}}{n}.\]</span></span></p>
<p>The function <span class="math inline">\(\hat{F}(x)\)</span> (and <span class="math inline">\(\hat{f}(x)\)</span>) is just the observed frequencies of the events <span class="math inline">\(\{X\leq x\}\)</span> (and <span class="math inline">\(\{X=x\}\)</span>). Any parameter <span class="math inline">\(\theta\)</span> comes with the probability function. For example, if <span class="math inline">\(X(\omega) \sim \mathcal{N}(\theta, 1)\)</span>. It is known that <span class="math inline">\(\mathbb{E}[X(\omega)]=\int x \mbox{d}F(dx)=\theta\)</span>. Thus, the statistical estimator becomes
<span class="math display">\[\theta(\hat{F})=\int x \mbox{d}\hat{F}(dx)=\frac{\sum_{i=1}^{n}x \mathbf{1}_{\{x_{i}= x\}}}{n}= \frac{\sum_{i=1}^{n}x_i}{n}  =\theta(\mathbf{x}).\]</span> Thus, we can see that the estimator <span class="math inline">\(\theta(\mathbf{x})\)</span> depends on the <strong>relative frequency</strong> of the <span class="math inline">\(n\)</span>-trials.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p><span class="newthought">Bayesian inference </span></p>
<p>The Bayesian inference takes its name from the fact that the inference makes central use of the <strong>Bayes’ law</strong>, a probabilistic calculus rule about inverting the arguments of a conditional probability (<strong>likelihood</strong>). Let’s return to the joint probability <span class="math inline">\(\Pr(\mathbf{x},\omega)\)</span>. This time, instead of conditioning <span class="math inline">\(\omega\)</span> on two binary states, we consider <span class="math inline">\(\omega\)</span> as a random variable.<label for="tufte-sn-293" class="margin-toggle sidenote-number">293</label><input type="checkbox" id="tufte-sn-293" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">293</span> The randomness comes from conditioning <span class="math inline">\(\omega\)</span> on some <span class="math inline">\(\sigma\)</span>-algebra.</span> The inference of <span class="math inline">\(\omega\)</span> will be conducted by the conditional probability <span class="math inline">\(\Pr(\omega|\mathbf{x})\)</span> called <strong>posterior</strong>. The <em>posterior</em> comes from
<span class="math display">\[
\begin{align*}\Pr(\omega|\mathbf{x})=\frac{\Pr(\mathbf{x},\omega)}{\Pr(\mathbf{x})}&amp;=\frac{\Pr(\mathbf{x}|\omega)\Pr(\omega)}{\Pr(\mathbf{x})}\\
&amp;=\frac{\Pr(\mathbf{x}|\omega)\Pr(\omega)}{\int_{\omega\in\Omega}\Pr(\mathbf{x}|\omega)\Pr(\omega)\mbox{d}\omega}\end{align*}\]</span>
where the second equality is known as the <em>Bayes’ law</em>, in memory of a Presbyterian minister Thomas Bayes.<label for="tufte-sn-294" class="margin-toggle sidenote-number">294</label><input type="checkbox" id="tufte-sn-294" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">294</span> In most statistical situations, the unconditional probability <span class="math inline">\(\Pr(\mathbf{x})\)</span> is unavailable, so in the third equality, <span class="math inline">\(\Pr(\mathbf{x})\)</span> is expressed as an integral of the <strong>likelihood</strong> and the <strong>prior</strong>.</span> The term <span class="math inline">\(\Pr(\omega)\)</span> called the <em>prior</em> represents some amount of epistemic knowledge of <span class="math inline">\(\omega\)</span>. The knowledge contained in <strong>the prior</strong> <span class="math inline">\(\Pr(\omega)\)</span> is neither from the sample nor from the underlying probability <span class="math inline">\(\mathbb{P}(\cdot)\)</span>. So one can also consider the <strong>prior</strong> as a “hypothesis”, a hypothetical probability law towards the underlying probability.<label for="tufte-sn-295" class="margin-toggle sidenote-number">295</label><input type="checkbox" id="tufte-sn-295" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">295</span> However, a deterministic “prior”, such as the <strong>hypothesis</strong> in the <strong>frequentist’s testing</strong>, the <strong>Bayes’ law</strong> cannot update the <strong>posterior</strong> <span class="math inline">\(\frac{\Pr(\mathbf{x}|\omega)\Pr(\omega)}{\Pr(\mathbf{x})}\)</span>, because if <span class="math inline">\(\omega\in H_{i}\)</span>, <span class="math display">\[\frac{\Pr(\mathbf{x}|\omega)\Pr(\omega\in H_{i})}{\Pr(\mathbf{x}|\omega)\Pr(\omega\in H_{i})+0}=1\]</span> for <span class="math inline">\(i=0,1\)</span>.</span> The <strong>Bayes’ law</strong> instructs how one could rationally update one’s <strong>prior</strong> knowledge in the light of empirical evidence <span class="math inline">\(\mathbf{x}\)</span> (in the <strong>likelihood</strong>) so that one’s <strong>posterior</strong> knowledge contains the information from both the experience and the primitive intuition. One can iteratively update the knowledge under the <strong>Bayes’ law</strong>: After assigning a posterior given the a priori hypothesis, one can then go on and use that posterior as the new prior in a further inference and so on.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:bayes"></span>
<img src="fig/Part3/bayes.gif" alt="Bayesian inference with Poisson likelihood and the underlying parameter at three" width="100%"><!--
<p class="caption marginnote">-->Figure 13.12: Bayesian inference with Poisson likelihood and the underlying parameter at three<!--</p>-->
<!--</div>--></span>
</p>
<p>One of the problems of invoking <strong>prior</strong> probabilities, as we can see, is the <em>problem of subjectivity</em>. The <strong>priors</strong> are subjective because people have different opinions or epistemic knowledge on what the prior probabilities should be. One might assume <span class="math inline">\(\omega\)</span> from a <a href="ch-CalUn.html#sub:divRV">normal family</a>, while the other might assume it from a <a href="ch-CalUn.html#sub:divRV">Poisson family</a> (i.e., see figure <a href="ch-CalUn.html#fig:NormalvsPoi">9.8</a>). For different families of priors, the posteriors could behave rather different;y in a finite number of observations.<label for="tufte-sn-296" class="margin-toggle sidenote-number">296</label><input type="checkbox" id="tufte-sn-296" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">296</span> However, for a large number of observations, the <strong>likelihood</strong> term dominates the <strong>prior</strong> during the updating. That is, the value of the product <span class="math display">\[\Pr(\mathbf{x}|\omega)\Pr(\omega)=\prod_{j=1}^{n}\Pr(x_{i}|\omega)\Pr(\omega)\]</span> is led by the values of the likelihood for a large <span class="math inline">\(n\)</span>. In this case, the <strong>posterior</strong> is influenced more by the <strong>likelihood</strong> than the <strong>prior</strong>. See figure <a href="ch-UnMulti.html#fig:bayes">13.12</a>.</span> Thus, the subjectivity does affect the Bayesian inference in a finite sample. But in fact, what makes things worse (in a logical exploration) is that Bayes’ law inevitably explains the new coming evidence on the basis of the old subjective prior.<label for="tufte-sn-297" class="margin-toggle sidenote-number">297</label><input type="checkbox" id="tufte-sn-297" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">297</span> For example, the prior belief can be reinforced by various sources of information, and a “prophet” may become confident that certain propositions are “objectively” true. However, there is no straightforward way of explaining these extreme degrees of belief, unless they are verifiable under some transcendental forces.</span></p>
<p>The <strong>a priori-a posteriori</strong> relation can also be found in the philosophical literature. In particular, <span class="citation">Kant (<a href="bibliography.html#ref-Kant2008">2008</a>)</span> uses this form in his <em>transcendental deduction</em>. The deduction says that the perception of <a href="sub-inferknow.html#sub:histgeo">temporal and spatial</a> orders is determined by experiencing the world conditional on some pure form that is “transcending the limits of experience.” This pure form, which Kant calls <strong>a priori</strong>, is without any empirical content. Kant’s deduction has made a successful attempt to construct a possible logic of the <strong>a priori</strong> by blending the subjectivity with rationalism and empiricism. However, Bayesian inference does not fully share the <strong>transcendental deduction</strong> logic. The purpose of this statistical inference is intended to recover the transcendental state of the prior, a metaphysical concept at which Kant’s deduction does not target.</p>
<div class="solution">
<p class="solution-begin">
An example of Bayesian inference <span id="sol-start-70" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-70', 'sol-start-70')"></span>
</p>
<div id="sol-body-70" class="solution-body" style="display: none;">
<p>One can parametrize <span class="math inline">\(\omega\)</span> as <span class="math inline">\(\theta(\omega)\)</span> so that the <strong>Bayes’ law</strong> becomes <span class="math display">\[\Pr(\theta(\omega)|\mathbf{x})=\frac{\Pr(\mathbf{x}|\theta)\Pr(\theta)}{\int_{\theta\in\Theta}\Pr(\mathbf{x}|\theta)\Pr(\theta)\mbox{d}\theta}\propto\Pr(\mathbf{x}|\theta)\Pr(\theta)\]</span>
where <span class="math inline">\(\Theta\)</span> is the set of all possible parameters.</p>
<p>Assume that the data <span class="math inline">\(\mathbf{x}\)</span> is a realization from a <a href="ch-CalUn.html#sub:divRV">Poisson distribution</a> <span class="math inline">\(\mbox{Poi}(\theta)\)</span>. The <strong>likelihood</strong> is <span class="math display">\[\Pr(\mathbf{x}|\theta)=\prod_{i=1}^{n}\frac{\theta^{x_{i}}e^{-\theta}}{x_{i}!}=\frac{\theta^{\sum_{i=1}^{n}x_{i}}e^{-n\theta}}{\prod_{i=1}^{n}x_{i}!}\]</span>
If we consider the prior <span class="math inline">\(\theta(\omega)\)</span> to follow the <a href="ch-CalUn.html#sub:divRV">Gamma distribution</a> <span class="math inline">\(\mbox{Gamma}(\alpha,\beta)\)</span>, namely <span class="math inline">\(\theta(\omega)=\theta(\alpha,\beta)\sim\mbox{Gamma}(\alpha,\beta)\)</span>, then we have
<span class="math display">\[\Pr(\theta(\omega))=\Pr(\theta(\alpha,\beta))=\frac{\beta^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha-1}e^{-\beta\theta}\]</span>
The <strong>posterior</strong> follows
<span class="math display">\[\begin{align*}
\Pr(\theta(\alpha,\beta)|\mathbf{x})&amp;\propto\Pr(\mathbf{x}|\theta(\alpha,\beta))\Pr(\theta(\alpha,\beta))\\
&amp;=  \frac{\beta^{\alpha}}{\prod_{i=1}^{n}x_{i}!\Gamma(\alpha)}\left(\theta^{\sum_{i=1}^{n}x_{i}}e^{-n\theta}\theta^{\alpha-1}e^{-\beta\theta}\right)\\&amp;\propto\theta^{\sum_{i=1}^{n}x_{i}+\alpha-1}e^{-(\beta+n)\theta}\end{align*}\]</span>
which says that the <strong>posterior</strong> is proportional to another <a href="ch-CalUn.html#sub:divRV">Gamma distribution</a>, <span class="math inline">\(\mbox{Gamma}(\sum_{i=1}^{n}x_{i}+\alpha,\beta+n)\)</span>. Note that the posterior of <span class="math inline">\(\theta\)</span> updates the prior <span class="math inline">\(\mbox{Gamma}(\alpha,\beta)\)</span> by the information from the sample, namely <span class="math inline">\(\sum_{i}x_{i}\)</span> and <span class="math inline">\(n\)</span>.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1">n=<span class="dv">15</span>; <span class="co"># Number of observations</span></a>
<a class="sourceLine" id="cb90-2" data-line-number="2">theta.under =<span class="st"> </span><span class="dv">3</span>  <span class="co"># Underlying parameter theta</span></a>
<a class="sourceLine" id="cb90-3" data-line-number="3">theta.d =<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">7</span>, <span class="fl">0.01</span>) <span class="co"># domain of theta</span></a>
<a class="sourceLine" id="cb90-4" data-line-number="4">prior =<span class="st"> </span><span class="kw">dgamma</span>(theta.d, <span class="dt">shape=</span><span class="dv">1</span>, <span class="dt">rate=</span><span class="dv">1</span>) <span class="co"># prior density over the domain</span></a>
<a class="sourceLine" id="cb90-5" data-line-number="5">x =<span class="st"> </span><span class="kw">rpois</span>(n, theta.under) <span class="co"># empirical evidence</span></a>
<a class="sourceLine" id="cb90-6" data-line-number="6">posterior =<span class="st"> </span><span class="kw">dgamma</span>(theta.d, <span class="dt">shape=</span><span class="dv">1</span><span class="op">+</span><span class="kw">sum</span>(x), <span class="dt">rate=</span><span class="dv">1</span><span class="op">+</span>n) <span class="co"># posterior </span></a>
<a class="sourceLine" id="cb90-7" data-line-number="7">data =<span class="st"> </span><span class="kw">data.frame</span>(theta.d, prior, posterior)</a>
<a class="sourceLine" id="cb90-8" data-line-number="8"></a>
<a class="sourceLine" id="cb90-9" data-line-number="9"><span class="kw">library</span>(ggplot2);  <span class="kw">library</span>(reshape2)</a>
<a class="sourceLine" id="cb90-10" data-line-number="10">fig =<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">melt</span>(data, <span class="dt">id.vars=</span><span class="st">"theta.d"</span>), <span class="kw">aes</span>(theta.d, value, <span class="dt">colour=</span>variable, <span class="dt">group=</span>variable)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span><span class="st">"Probability"</span>, <span class="dt">x=</span><span class="st">"x"</span>) <span class="op">+</span><span class="st">  </span><span class="kw">annotate</span>(<span class="dt">geom=</span><span class="st">"text"</span>, <span class="dt">x=</span><span class="dv">5</span>, <span class="dt">y=</span><span class="fl">0.8</span>, <span class="dt">label=</span><span class="st">"n=15"</span>, <span class="dt">color=</span><span class="st">"red"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</a></code></pre></div>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p><span class="newthought">Falsifiability </span></p>
<p>The use of subjective and objective probabilities has evoked a great number of debates amongst different statistical schools. <strong>Frequentism</strong> prefers to put the subjectivity in a hypothesis and a tendency of acquiring similar large samples so that the objective frequency can decide whether the hypothesis is (statistically) acceptable. <strong>Bayesianism</strong> prefers to orderly revise the subjective opinion on the basis of objective information so that <strong>a priori</strong> hypothetical believer can learn from experience.</p>
<p>From a philosophical point of view, this difference is really due to something more fundamental: the lack of an adequate conceptual bridge between the underlying probability law <span class="math inline">\(\mathbb{P}(X(\omega))\)</span> and the observable statistics <span class="math inline">\(\Pr(\mathbf{x}|\omega)\)</span>.</p>
<p>As the discussion in chapter <a href="sub-inferknow.html#sub:inferknow">4</a>, the inferences are traditionally divided into deductive and inductive. In <strong>deductive inferences</strong>, the information conveyed by the <a href="sub-logic.html#sub:logic">conclusion</a> is already included in the <a href="sub-logic.html#sub:logic">premises</a>, such as <a href="sub-inferknow.html#sub:inferknow">recursion</a>. While in <strong>inductive inferences</strong>, the <a href="sub-logic.html#sub:logic">conclusion</a> says something extra with respect to the <a href="sub-logic.html#sub:logic">premises</a>. This means that the <a href="sub-logic.html#sub:logic">conclusion</a> of <strong>inductive inference</strong> is inevitably uncertain. All statistical inferences are in the subject of <strong>inductive inferences</strong>.<label for="tufte-sn-298" class="margin-toggle sidenote-number">298</label><input type="checkbox" id="tufte-sn-298" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">298</span> For example, any conclusion regarding <span class="math inline">\(\omega\)</span> is beyond the statistical information delivered by <span class="math inline">\(\mathbf{x}\)</span> because in principle the information of <span class="math inline">\(\omega\)</span> is stored in the population probability <span class="math inline">\(\mathbb{P}(X(\omega))\)</span>, while finite observations <span class="math inline">\(\mathbf{x}\)</span> cannot contain the full information about <span class="math inline">\(\omega\)</span>. The joint probability <span class="math inline">\(\Pr(\mathbf{x},\omega)\)</span> requires additional information about <span class="math inline">\(\omega\)</span>, so it comes from either our <strong>hypothesis</strong> with a convergent tendency or our <strong>prior</strong> about what random family <span class="math inline">\(\omega\)</span> could belong to.</span> Hence, even though the truth of the <a href="sub-logic.html#sub:logic">premises</a> is taken as guaranteed, we cannot avoid the risk that the extra information conveyed by the <a href="sub-logic.html#sub:logic">conclusion</a> of statistical inference may be false.</p>
<p>According to <span class="citation">Popper (<a href="bibliography.html#ref-Popper1959">1959</a>)</span>, the growth of knowledge has its root in <em>falsifiability</em>, a capacity to identify and correct the false hypotheses from the <strong>deductive inferences</strong>. Among the falsificationists and anti-inductivists, many share Popper’s view that <strong>deductive inference</strong> is the only legitimate form of the inferences in science. Given that statistical inductive inference may suffer the incompatibility with its logical ground, one may want to consider the empirical evidence from another perspective.</p>
<p>How about combining Popper’s and Kant’s arguments? If we can define a transcendental source (in Kant’s sense) for the <strong>prior</strong>, then we could turn the <strong>a priori-a posteriori</strong> inference into a <strong>transcendental deduction</strong>. By considering the underlying information as a transcendental source, empirical evidence may reinforce some of our tendency to specify the source but has no vital right to <strong>falsify</strong> the source. The transcendental source is only <strong>falsifiable</strong> by the transcendental means. When a prior is developed from such a transcendental source, the whole reasoning process of deriving the posterior is closer to <strong>transcendental deduction</strong> than the statistical inductive inference. In other words, if some transcendental source can explain the extra <a href="sub-logic.html#sub:logic">conclusion</a> occurring in the <strong>inductive inference</strong>, then the gap vanishes between the <strong>inductive</strong> and <strong>deductive inference</strong>. However, in this case, the transcendental source stays beyond the statistical realm, making the inference no longer a statistical inference.</p>

</div>
</div></body></html>

<p style="text-align: center;">
<a href="ch-eigen.html"><button class="btn btn-default">Previous</button></a>
<a href="part-iv-three-masons-to-illuminate-the-dual-world.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-10-04
</p>
</div>
</div>



</body>
</html>
