<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7 Calculus | Project XXII" />
<meta property="og:type" content="book" />





<meta name="author" content="Zhengyuan Gao" />

<meta name="date" content="2020-08-30" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="7 Calculus | Project XXII">

<title>7 Calculus | Project XXII</title>

<link href="libs/tufte-css/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding/datatables.js"></script>
<link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>



</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Project XXII<p><p class="author">Zhengyuan Gao</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BA; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Preface</a>
<a href="part-i-inference-based-upon-logic-and-logical-computation.html">PART I: Inference Based upon Logic and Logical Computation</a>
<a href="sub-logic.html"><span class="toc-section-number">1</span> Logic</a>
<a href="sub-set-theory.html"><span class="toc-section-number">2</span> Set Theory</a>
<a href="sub-axioms.html"><span class="toc-section-number">3</span> Axioms</a>
<a href="sub-inferknow.html"><span class="toc-section-number">4</span> Inference and Knowledge</a>
<a href="sub-incomplete.html"><span class="toc-section-number">5</span> Incompleteness</a>
<a href="part-ii-infinitesimal-changes-and-their-consequences.html">PART II: Infinitesimal Changes and their Consequences</a>
<a href="sub-continuity.html"><span class="toc-section-number">6</span> Continuity</a>
<a id="active-page" href="sub-calculus.html"><span class="toc-section-number">7</span> Calculus</a><ul class="toc-sections">
<li class="toc"><a href="#sub:diffInt"> Differentiation and Integration</a></li>
<li class="toc"><a href="#sub:noDiff"> Counterexamples: Continuous and Nowhere Differentiable Function, Integration with Infinite Discontinuities</a></li>
<li class="toc"><a href="#sub:opt"> Optimality</a></li>
<li class="toc"><a href="#sub:Taylor"> Examples: Power Series and Taylor Series</a></li>
</ul>
<a href="ch-DE.html"><span class="toc-section-number">8</span> Differential Equations</a>
<a href="ch-CalUn.html"><span class="toc-section-number">9</span> Calculus under Uncertainty</a>
<a href="part-iii-emergence-of-abstract-interactions.html">PART III: Emergence of Abstract Interactions</a>
<a href="ch-vecMat.html"><span class="toc-section-number">10</span> Vector and Matrix</a>
<a href="ch-MatComp.html"><span class="toc-section-number">11</span> Matrix Computation</a>
<a href="ch-eigen.html"><span class="toc-section-number">12</span> Eigenvalues and Eigenvectors</a>
<a href="ch-UnMulti.html"><span class="toc-section-number">13</span> Uncertainty in Multiple Dimensions</a>
<a href="part-iv-three-masons-to-illuminate-the-dual-world.html">PART IV: Three Masons to Illuminate the Dual World</a>
<a href="bibliography.html">Bibliography</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="sub:calculus" class="section level1">
<h1>
<span class="header-section-number">7</span> Calculus</h1>
<p>According to Aristotle’s metaphysics, “forms,” like Plato’s “ideas,” are continuous, and they become gradually more knowable. That is, after the change, the thing in question has more “form” than before, namely one idea following from another in our minds. The notion of <strong>calculus</strong> has been such a “form” that expands our understanding of <a href="sub-continuity.html#sub:rational">infinitesimal change</a>. When changes occur in continuous “form,” they obtain both local and global properties. Infinitesimal changes happen locally in lines, curves, space, time, and lives through presumably continuous matters and forms. Common sense would have suggested to us that there has been none. Still, continuous observation indicates that, on the global level, where the infinitesimals accumulate to a sensible magnitude, there has. This reciprocal relationship of infinitesimal changes is studied as operations of <strong>differentiation</strong> and <strong>integration</strong> in the framework of <a href="sub-calculus.html#sub:calculus">calculus</a>, a system of rules and algorithms for computation.</p>
<p>Historically, the emergence of the idea about infinitesimal changes was against those conservative opinions of holding elementary properties invariant. In the early 17th century Europe, infinitesimal was a subject of political and religious controversies, for which clerics in Rome even issued a ban.<label for="tufte-sn-86" class="margin-toggle sidenote-number">86</label><input type="checkbox" id="tufte-sn-86" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">86</span> Perhaps the most famous scathing attack on the infinitesimal was given by Geroge Berkeley, a Bishop of Cloyne. He said, “what are these same evanescent Increments? They are neither finite Quantities nor Quantities infinitely small, nor yet nothing. May we not call them the Ghosts of departed Quantities?” </span> Despite resistance, Newton demonstrated that infinitesimal is the basic language to derive his <strong>logic of nature</strong>. Calculus began with the study of the infinitesimal changes. The changes firstly referred to changes in direction or position, now the changes could be the diffusion of knowledge or epidemic, the fluctuation of price or social stability, etc.</p>
<p>Newton and Leibniz independently invented and developed calculus in the late 17th century. Newton showed that a small set of his equations - laws of motion and gravity- could explain the mysterious patterns in the solar system, a system of the universe. These equations demonstrated the power of reason and ushered in the Enlightenment. Nowadays, cause and effect in the natural world are viewed as “forms” in calculus, with one truth following from another by <a href="sub-logic.html#sub:PeanoInd">deduction logic</a>. Calculus, as a logical engine, allows us to deduce the law of nature and to investigate changes in other concepts beyond the physical world.</p>
<div id="sub:diffInt" class="section level2">
<h2>
<span class="header-section-number">7.1</span> Differentiation and Integration</h2>
<p><span class="newthought">Differentiation </span></p>
<p>Let’s take a loose patchwork of ideas about motion and curves and turned it into a calculus. Consider a curve described by the function <span class="math inline">\(f(x)\)</span> for <span class="math inline">\(x\in[a,b]\)</span>. A small change in the <a href="sub-set-theory.html#sub:func">input</a>, <span class="math inline">\(\Delta x\)</span>, product a small change in the <a href="sub-set-theory.html#sub:func">output</a>, <span class="math inline">\(\Delta y=f(x+\Delta x)-f(x)\)</span>. As you can see, <span class="math inline">\(\Delta x\)</span> is the previous <a href="sub-continuity.html#sub:rational">infinitesimal</a> <span class="math inline">\(\epsilon\)</span> of the concern. Because the small change of <span class="math inline">\(y\)</span> is also an infinitesimal, we use the notation <span class="math inline">\(\Delta x\)</span> and <span class="math inline">\(\Delta y\)</span> to represent <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(f(x+\epsilon)-f(x)\)</span>. When <span class="math inline">\(y=f(x)\)</span> is a <a href="sub-continuity.html#sub:continuousFunc">continuous</a> function of <span class="math inline">\(x\)</span>, the curve has no gaps or jumps in it. To measure precisely the changes, one needs to measure the change of the curve by a <em>rate of change</em> <span class="math inline">\(\Delta y/\Delta x\)</span>.<label for="tufte-sn-87" class="margin-toggle sidenote-number">87</label><input type="checkbox" id="tufte-sn-87" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">87</span> In analogous to the <a href="sub-logic.html#sub:1order">first-order logic</a>, the infinitesimal quantity <span class="math inline">\(\frac{f(x+\epsilon)-f(x)}{\epsilon}\)</span> is a first-order property for the function.</span></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:derivative"></span>
<img src="fig/Part2/diff.gif" alt="Derivative" width="100%"><!--
<p class="caption marginnote">-->Figure 7.1: Derivative<!--</p>-->
<!--</div>--></span>
</p>
<p>Calculus needs a definition for the <a href="sub-incomplete.html#sub:infinity">limit</a> of <span class="math inline">\(\Delta y/\Delta x\)</span>. Given a curve determined by correlated variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, the limit of the ratio <span class="math inline">\(\Delta y/\Delta x\)</span> is written as <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span>, where the infinitesimal differences, or <em>differentials</em> <span class="math inline">\(\mbox{d}x\)</span> and <span class="math inline">\(\mbox{d}y\)</span>, are essentially the limits of <span class="math inline">\(\Delta x\)</span> and <span class="math inline">\(\Delta y\)</span>. The limit, <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span> or <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span> is called the <em>derivative</em>. Asking for a <strong>derivative</strong> is more than asking for <a href="sub-continuity.html#sub:continuousFunc">continuity</a>. The reason is fundamental, <span class="math display">\[\begin{align*} \mbox{Continuous}:   \; &amp;\lim_{\Delta x\rightarrow0} \Delta y=\lim_{\Delta x\rightarrow0}\left(f(x+\Delta x)-f(x)\right)=0, \\
\mbox{Derivative}:  \; &amp; \lim_{\Delta x\rightarrow0}\frac{\Delta y}{\Delta x}=\lim_{\Delta x\rightarrow0}\frac{f(x+\Delta x)-f(x)}{\Delta x}=\frac{\mbox{d}f(x)}{\mbox{d}x}.\end{align*}\]</span> The requirement of <a href="sub-continuity.html#sub:continuousFunc">continuity</a> asks that <span class="math inline">\(\Delta y\)</span> goes to zero when <span class="math inline">\(\Delta x\)</span> goes to zero.<label for="tufte-sn-88" class="margin-toggle sidenote-number">88</label><input type="checkbox" id="tufte-sn-88" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">88</span> One can present this requirement by the definition of continuity: <span class="math inline">\(\Delta y\)</span> is the <a href="sub-continuity.html#sub:continuousFunc"><span class="math inline">\(\epsilon\)</span>-neighborhood</a> of <span class="math inline">\(f(x)\)</span>, namely <span class="math inline">\(\mathcal{B}_{\epsilon}(f(x))\)</span>. For continuity, the <span class="math inline">\(\epsilon\)</span>-neighborhood must contain the image <span class="math inline">\(f(\Delta x)\)</span> of <span class="math inline">\(\Delta x\)</span>. When <span class="math inline">\(\Delta x\rightarrow0\)</span>, the continuity implies that <span class="math inline">\(\Delta y\rightarrow0\)</span>.</span> But for <strong>derivative</strong>, the requirement is that <span class="math inline">\(\Delta y\rightarrow0\)</span> “as fast as” <span class="math inline">\(\Delta x\rightarrow0\)</span>, so that a limit exists.</p>
<p>If <span class="math inline">\(\Delta y\)</span> goes faster than <span class="math inline">\(\Delta x\)</span> to zero, then <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span> is always zero. On the other hand, if <span class="math inline">\(\Delta y\)</span> goes slower, then <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span> becomes an undefined <span class="math inline">\(\mbox{d}y/0\)</span>. This indefiniteness is what Berkeley objected to. Berkeley question simply asked: Is <span class="math inline">\(\mbox{d}x\)</span> zero or not? If it is, then <span class="math inline">\(\mbox{d}y/0\)</span> is not allowed because you can’t divide something by zero. But if <span class="math inline">\(\mbox{d}x\)</span> is not zero, then some kind of error must be made in passing from <span class="math inline">\(\Delta y/\Delta x\)</span> to <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span>. To clarify Berkeley’s confusion, let’s consider a curve <span class="math inline">\(y=f(x)=x(1-x^{2})\)</span> for <span class="math inline">\(x\in[0,1]\)</span>. When we increase <span class="math inline">\(x\)</span> to <span class="math inline">\(x+\Delta x\)</span>, <span class="math inline">\(\Delta y\)</span> becomes
<span class="math display">\[\begin{align*}
 &amp; (x+\Delta x)\left(1-(x+\Delta x)^{2}\right)-(x-x^{3})    \\
=&amp;x+\Delta x-\left(x^{3}+3x^{2}\Delta x+3x(\Delta x)^{2}+(\Delta x)^{3}\right)-x+x^{3}\\
=&amp;\Delta x-3x^{2}\Delta x-3x(\Delta x)^{2}-(\Delta x)^{3}.\end{align*}\]</span>
Then dividing <span class="math inline">\(\Delta y\)</span> by <span class="math inline">\(\Delta x\)</span>, we have
<span class="math display">\[\frac{\Delta x-3x^{2}\Delta x-3x(\Delta x)^{2}-(\Delta x)^{3}}{\Delta x}=1-3x^{2}-3x(\Delta x)-(\Delta x)^{2}.\]</span>
Now taking the limit of <span class="math inline">\(\Delta x\)</span> gives us <span class="math inline">\(1-3x^{2}\)</span>, which is the answer of <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span>. As you can see, what Berkeley missed is that the <strong>derivative</strong> contains two <a href="sub-incomplete.html#sub:infinity">limits</a>: <span class="math inline">\(\Delta x\rightarrow0\)</span> and <span class="math inline">\(\Delta y/\Delta x\rightarrow\mbox{d}y/\mbox{d}x\)</span> rather than just one <span class="math inline">\(\Delta x\rightarrow0\)</span>. We need to ensure that the limit of <span class="math inline">\(\Delta y/\Delta x\)</span> exists. That is, <span class="math inline">\(\Delta y\)</span> goes to zero “as fast as” <span class="math inline">\(\Delta x\)</span> does.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:tangent"></span>
<img src="fig/Part2/tangent.gif" alt="Tangent lines" width="100%"><!--
<p class="caption marginnote">-->Figure 7.2: Tangent lines<!--</p>-->
<!--</div>--></span>
</p>
<p>For a curve <span class="math inline">\(y=f(x)\)</span>, <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span> or <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span> represents the <em>slope</em> of the curve. This suggests, except the linear case where the slope is a constant, the slopes vary as the variable <span class="math inline">\(x\)</span> changes; and we can regard the slope as a function of <span class="math inline">\(x\)</span>, just like <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x=1-3x^{2}\)</span> in above example. <strong>Rates of change</strong> can no longer be mere numbers, but functions. When we emphasize the <strong>slope</strong> at the corresponding point <span class="math inline">\(x_{0}\)</span>, we use the notation <span class="math inline">\(\left.\frac{df(x)}{dx}\right|_{x=x_{0}}\)</span>. When the derivative <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span> exists on a set <span class="math inline">\(\mathcal{X}\)</span>, we say <span class="math inline">\(f\)</span> is <em>differentiable</em> on <span class="math inline">\(\mathcal{X}\)</span>. When <span class="math inline">\(f\)</span> is <strong>differentiable</strong> at <span class="math inline">\(x_{0}\)</span>, we define the <em>tangent line</em> to <span class="math inline">\(f\)</span> at <span class="math inline">\(x_{0}\)</span> to be the linear function <span class="math inline">\(f(x_{0})+\left.\frac{df(x)}{dx}\right|_{x=x_{0}}(x-x_{0})\)</span>. When <span class="math inline">\(f\)</span> is <strong>differentiable</strong> at <span class="math inline">\(x_{0}\)</span>, the <strong>tangent line</strong> passes through the point <span class="math inline">\((x_{0},f(x_{0}))\)</span> with slope <span class="math inline">\(\left.\frac{df(x)}{dx}\right|_{x=x_{0}}\)</span>.<label for="tufte-sn-89" class="margin-toggle sidenote-number">89</label><input type="checkbox" id="tufte-sn-89" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">89</span> The tangent line is the best linear approximation to <span class="math inline">\(f(x)\)</span> for <span class="math inline">\(x\)</span> very close to <span class="math inline">\(x_{0}\)</span>. Figure <a href="sub-calculus.html#fig:tangent">7.2</a> shows the linear approximation of <span class="math inline">\(x\sin(1/x)\)</span> at <span class="math inline">\(x_0=0\)</span>.</span></p>
<p>The <em>differentiation rules</em> and useful derivatives are summarized as follows.</p>
<ul>
<li><p><em>Sums and constant factors</em> : Let <span class="math inline">\(f(x)=a u(x)+b v(x)\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are constants. <span class="math display">\[\frac{\mbox{d}f(x)}{\mbox{d}x}=a\frac{\mbox{d}u(x)}{\mbox{d}x}+b\frac{\mbox{d}v(x)}{\mbox{d}x}.\]</span></p></li>
<li><p><em>Products (and power)</em> : Let <span class="math inline">\(f(x)=u(x)\cdot v(x)\)</span>.<label for="tufte-sn-90" class="margin-toggle sidenote-number">90</label><input type="checkbox" id="tufte-sn-90" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">90</span> For example, if <span class="math inline">\(y=x^{2}=x\times x\)</span>, then <span class="math inline">\(\mbox{d}y/\mbox{d}x=2x\)</span>. By induction, if <span class="math inline">\(y=x^{n}\)</span> for any positive integer <span class="math inline">\(n\)</span>, <span class="math display">\[\frac{\mbox{d}y}{\mbox{d}x}=n x^{n-1}.\]</span> This is also known as the <strong>power rule</strong>.</span> <span class="math display">\[\frac{\mbox{d}f(x)}{\mbox{d}x}=u(x)\frac{\mbox{d}v(x)}{\mbox{d}x}+v(x)\frac{\mbox{d}u(x)}{\mbox{d}x}.\]</span></p></li>
<li><p><em>Quotients</em> : Let <span class="math inline">\(f(x)=u(x)/v(x)\)</span>.<label for="tufte-sn-91" class="margin-toggle sidenote-number">91</label><input type="checkbox" id="tufte-sn-91" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">91</span> For example, if <span class="math inline">\(y=x^{-n}=1/x^{n}\)</span>, then <span class="math display">\[\frac{\mbox{d}y}{\mbox{d}x}=\frac{-nx^{n-1}}{x^{2n}}=-n x^{-n-1}.\]</span></span> <span class="math display">\[\frac{\mbox{d}f(x)}{\mbox{d}x}=\left(v(x)\frac{\mbox{d}u(x)}{\mbox{d}x}-u(x)\frac{\mbox{d}v(x)}{\mbox{d}x}\right)/v^{2}(x).\]</span></p></li>
<li><p><em>Inverse functions</em> : Let <span class="math inline">\(y=f(x)\)</span> and <span class="math inline">\(x=f^{-1}(y)\)</span>.<label for="tufte-sn-92" class="margin-toggle sidenote-number">92</label><input type="checkbox" id="tufte-sn-92" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">92</span> For example, <span class="math inline">\(y=x^{1/2}\)</span> is the inverse function of <span class="math inline">\(x=y^{2}\)</span>. <span class="math display">\[\frac{\mbox{d}y}{\mbox{d}x}=\frac{1}{\mbox{d}x/\mbox{d}y}=\frac{1}{2y}=\frac{x^{-1/2}}{2}.\]</span></span> <span class="math display">\[\frac{\mbox{d}y}{\mbox{d}x}=1/\left(\frac{\mbox{d}x}{\mbox{d}y}\right)\,\, \mbox{ for } \frac{\mbox{d}x}{\mbox{d}y}\neq0.\]</span></p></li>
<li><p><em>Exponential and logarithm functions</em> :<span class="math display">\[\frac{\mbox{d}\mbox{e}^x}{\mbox{d}x}= \mbox{e}^{x}, \mbox{ and } \frac{\mbox{d}\ln x}{\mbox{d}x}=\frac{1}{x}.\]</span></p></li>
<li><p><em>Trigonometric function</em> : <span class="math display">\[\frac{\mbox{d}}{\mbox{d}x}\sin x=\cos x, \,\,\mbox{ and }\, \frac{\mbox{d}}{\mbox{d}x}\cos x=-\sin x.\]</span></p></li>
<li><p><em>Composite function (chain rule)</em> : Let <span class="math inline">\(y=h(x)=f\circ g(x)\)</span> and let <span class="math inline">\(z=g(x)\)</span> <span class="math display">\[\frac{\mbox{d}h(x)}{\mbox{d}x}=\frac{\mbox{d}f(z)}{\mbox{d}z}\frac{\mbox{d}z}{\mbox{d}x}.\]</span></p></li>
</ul>
<div class="solution">
<p class="solution-begin">
Proof of the differentiation rules <span id="sol-start-12" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-12', 'sol-start-12')"></span>
</p>
<div id="sol-body-12" class="solution-body" style="display: none;">
<p><span class="newthought">Proof of sums and constant factors </span></p>
<p>Note that <span class="math inline">\(y+\Delta y=f(x+\Delta x)\)</span>, <span class="math inline">\(u+\Delta u=u(x+\Delta x)\)</span>, <span class="math inline">\(v+\Delta v=v(x+\Delta x)\)</span>, so we have <span class="math inline">\(\Delta y=a\Delta u+b\Delta v\)</span>. Dividing the expression of <span class="math inline">\(\Delta y\)</span> by <span class="math inline">\(\Delta x\)</span> and taking limit <span class="math inline">\(\Delta x\rightarrow0\)</span>, we have
<span class="math display">\[\begin{align*} \frac{\mbox{d}f(x)}{\mbox{d}x} &amp;=\lim_{\Delta x\rightarrow0}\frac{\Delta y}{\Delta x}=\lim_{\Delta x\rightarrow0}\frac{a\Delta u+b\Delta v}{\Delta x}\\
&amp;=a\lim_{\Delta x\rightarrow0}\frac{\Delta u}{\Delta x}+b\lim_{\Delta x\rightarrow0}\frac{\Delta v}{\Delta x}=a\frac{\mbox{d}u(x)}{\mbox{d}x}+b\frac{\mbox{d}v(x)}{\mbox{d}x}.
\end{align*}\]</span></p>
<p><span class="newthought">Proof of products </span></p>
<p>Consider <span class="math display">\[\begin{align*} y+\Delta y &amp;=u(x+\Delta x)\cdot v(x+\Delta x) \\
&amp;=(u+\Delta u)\cdot(v+\Delta v)=uv+u\Delta v+v\Delta u+\Delta u\Delta v. \end{align*}\]</span>
Subtracting <span class="math inline">\(y=uv\)</span> from both sides gives us <span class="math inline">\(\Delta y=u\Delta v+v\Delta u+\Delta u\Delta v\)</span>. The term <span class="math inline">\(\Delta u\Delta v\)</span> goes to zero faster than <span class="math inline">\(v\Delta u\)</span> and <span class="math inline">\(u\Delta v\)</span>. Thus <span class="math display">\[\begin{align*} \frac{\mbox{d}f(x)}{\mbox{d}x} &amp;=\lim_{\Delta x\rightarrow0}\frac{\Delta y}{\Delta x}=\lim_{\Delta x\rightarrow0}\frac{u\Delta v+v\Delta u+\Delta u\Delta v}{\Delta x}\\
    &amp;=u\lim_{\Delta x\rightarrow0}\frac{\Delta v}{\Delta x}+v\lim_{\Delta x\rightarrow0}\frac{\Delta u}{\Delta x}+\lim_{\Delta x\rightarrow0}\frac{\Delta u\Delta v}{\Delta x}=u(x)\frac{\mbox{d}v(x)}{\mbox{d}x}+v(x)\frac{\mbox{d}u(x)}{\mbox{d}x}.\end{align*}\]</span></p>
<p><span class="newthought">Proof of quotients </span></p>
<p>Note that <span class="math inline">\(y+\Delta y=\frac{u+\Delta u}{v+\Delta v}\)</span>. Subtracting <span class="math inline">\(y=u/v\)</span> and using the <a href="sub-incomplete.html#sub:fdim">geometric series</a> for <span class="math inline">\((1+\Delta v/v)^{-1}\)</span> yields <span class="math display">\[\begin{align*} \Delta y &amp;=\frac{u+\Delta u}{v+\Delta v}-\frac{u}{v}=\frac{v\Delta u-u\Delta v}{v^{2}+v\Delta v}\\
&amp;=\frac{v\Delta u-u\Delta v}{v^{2}}\left(1-\frac{\Delta v}{v}+\frac{(\Delta v)^{2}}{v^{2}}+\cdots\right) \end{align*}\]</span>
for <span class="math inline">\(v(x)\neq0\)</span>. Then dividing <span class="math inline">\(\Delta y\)</span> by <span class="math inline">\(\Delta x\)</span> and taking the limit gives <span class="math display">\[\begin{align*} \frac{\mbox{d}f(x)}{\mbox{d}x} &amp;=\lim_{\Delta x\rightarrow0}\frac{v\frac{\Delta u}{\Delta x}-u\frac{\Delta v}{\Delta x}}{v^{2}}\left(1-\frac{\Delta v}{v}+\frac{(\Delta v)^{2}}{v^{2}}+\cdots\right)\\
&amp;=u\lim_{\Delta x\rightarrow0}\frac{\Delta v}{\Delta x}+v\lim_{\Delta x\rightarrow0}\frac{\Delta u}{\Delta x}+\lim_{\Delta x\rightarrow0}\frac{\Delta u\Delta v}{\Delta x}=u(x)\frac{\mbox{d}v(x)}{\mbox{d}x}+v(x)\frac{\mbox{d}u(x)}{\mbox{d}x}.\end{align*}\]</span></p>
<p><span class="newthought">Proof of inverse function </span></p>
<p>Note that <span class="math inline">\(\frac{\Delta y}{\Delta x}=1/\left(\frac{\Delta x}{\Delta y}\right)\)</span>. Taking the limit gives the result.</p>
<p><span class="newthought">Proof of exponential function </span>
Note that <span class="math inline">\(y+\Delta y=\mbox{e}^{x+\Delta x}=\mbox{e}^{x}\mbox{e}^{\Delta x}\)</span> and <span class="math inline">\(\Delta y=\mbox{e}^{x}(\mbox{e}^{\Delta x}-1)\)</span>. Using the definition of exponential <span class="math inline">\(\mbox{e}^{\Delta x}=1+\Delta x+(\Delta x)^{2}/2!+\cdots\)</span>. We have <span class="math display">\[\begin{align*} \frac{\mbox{d}f(x)}{\mbox{d}x}   &amp;=\lim_{\Delta x\rightarrow0}\frac{\mbox{e}^{x}(\mbox{e}^{\Delta x}-1)}{\Delta x}=\lim_{\Delta x\rightarrow0}\mbox{e}^{x}\frac{\Delta x+(\Delta x)^{2}/2!+\cdots}{\Delta x}\\
    &amp;=\lim_{\Delta x\rightarrow0}\mbox{e}^{x}\left(1+(\Delta x)/2!+\cdots\right)=\mbox{e}^{x}.
\end{align*}\]</span></p>
<p><span class="newthought">Proof of logarithm function </span></p>
<p>The logarithm function is the inverse function of <span class="math inline">\(x=\mbox{e}^{y}\)</span>. <span class="math display">\[\frac{\mbox{d}y}{\mbox{d}x}=1/\left( \frac{\mbox{d}x}{\mbox{d}y}\right)=1/\mbox{e}^{y}=1/x.\]</span></p>
<p><span class="newthought">Proof of trigonometric functions </span></p>
<p>Consider <span class="math inline">\(y=\sin x\)</span>. Figure <a href="sub-calculus.html#fig:sincos">7.3</a> gives the graphical proof.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:sincos"></span>
<img src="fig/Part2/sin.gif" alt="Proof of the derivative of the sine function" width="100%"><!--
<p class="caption marginnote">-->Figure 7.3: Proof of the derivative of the sine function<!--</p>-->
<!--</div>--></span>
</p>
<p><span class="newthought">Proof of composite function (chain rule) </span></p>
<p>Consider <span class="math inline">\(z+\Delta z=g(x+\Delta x)\)</span> and <span class="math inline">\(y+\Delta y=h(x+\Delta x)=f(z+\Delta z)\)</span>. Then the result comes from the identity <span class="math display">\[\frac{\Delta y}{\Delta x}=\frac{\Delta y}{\Delta z}\cdot\frac{\Delta z}{\Delta x}.\]</span></p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>Differentiation characterizes many “first-order” properties in various disciplines. For example, <em>marginality</em> in economics that interprets the infinitesimal discrepancy in the value of goods and services, basically means taking a <strong>derivative</strong>. Let <span class="math inline">\(y=f(x)\)</span> be the cost of production with <span class="math inline">\(x\)</span> units input. Then <span class="math inline">\(\Delta y/\Delta x\)</span> is the average cost per extra unit. When <span class="math inline">\(\Delta x\rightarrow0\)</span>, the cost becomes the <em>marginal cost</em> that is <span class="math inline">\(\mbox{d}y/\mbox{d}x\)</span>. The terminology <em>elasticity</em> in economics is “marginal” divided by “average”. Let <span class="math inline">\(y\)</span> denote the demand and <span class="math inline">\(x\)</span> denote the price. The <strong>elasticity</strong> of the demand function <span class="math inline">\(y=f(x)\)</span> is<span class="math display">\[\lim_{\Delta x\rightarrow0}\frac{\Delta y/y}{\Delta x/x}=\frac{\mbox{d}y/\mbox{d}x}{y/x},\]</span>
which also represents the relative change in <span class="math inline">\(y\)</span> divided by the relative change in <span class="math inline">\(x\)</span>.</p>
<p><span class="newthought">Integration </span></p>
<p>The inverse operation of <strong>differentiation</strong> is called <strong>integration</strong>. Differentiation is all about finding the steepness of a curve. Undoing differentiation is a way of finding the area. An integral is defined as a limit related to the “area” covered by the function. In other words, integration is a problem of adding up infinitely many areas, each of which is <a href="sub-incomplete.html#sub:infinity">infinitesimally</a> small.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:RInt"></span>
<img src="fig/Part2/Integral.gif" alt="Integral" width="100%"><!--
<p class="caption marginnote">-->Figure 7.4: Integral<!--</p>-->
<!--</div>--></span>
</p>
<p>For a given function <span class="math inline">\(y=f(x)\)</span>, we want to compute the area between the <span class="math inline">\(x\)</span>-axis and the curve. Let us denote the area between the curve <span class="math inline">\(f(x)\)</span> as <span class="math inline">\(z=F(x)\)</span>. For an interval <span class="math inline">\([a,b]\)</span>, the area between the curve <span class="math inline">\(f(x)\)</span> and the interval <span class="math inline">\([a,b]\)</span> is <span class="math inline">\(F(b)-F(a)\)</span>. Consider that the segment <span class="math inline">\((x,f(x))\)</span> in figure <a href="sub-calculus.html#fig:RInt">7.4</a> moves towards the right. Consequently, if <span class="math inline">\(x\)</span> increases by <span class="math inline">\(\Delta x\)</span>, the area increases by <span class="math inline">\(\Delta z=F(x+\Delta x)-F(x)\)</span> (the light blue area between the curve and <span class="math inline">\(x\)</span>-axis), which is approximately <span class="math inline">\(f(x)\Delta x\)</span> (the area of the red rectangle). In the limit <span class="math inline">\(\Delta x\rightarrow \mbox{d}x\)</span> and <span class="math inline">\(\Delta z \rightarrow \mbox{d}z\)</span>, we have <span class="math inline">\(\mbox{d}z=f(x)\mbox{d}x\)</span> or say <span class="math inline">\(\mbox{d}z/\mbox{d}x=f(x)\)</span>. It means that the function <span class="math inline">\(f(x)\)</span> is the derivative of <span class="math inline">\(F(x)\)</span>, namely <span class="math display">\[\frac{\mbox{d}z}{\mbox{d}x}=\frac{\mbox{d}F(x)}{\mbox{d}x}=f(x).\]</span>
The <em>integral</em> is the inverse operation of the differentiation <span class="math display">\[\int_{a}^{b}f(x)\mbox{d}x=F(b)-F(a).\]</span>
The total blue area in figure <a href="sub-calculus.html#fig:RInt">7.4</a> comes from the <strong>integration</strong> (denoted by <span class="math inline">\(\int\)</span>) of <span class="math inline">\(f(x)\)</span> over the interval <span class="math inline">\([a,b]\)</span>.</p>
<p>Let’s construct the integration from scratch. Starting with the function <span class="math inline">\(f\)</span> on <span class="math inline">\([a,b]\)</span>, we partition <span class="math inline">\([a,b]\)</span> into small subintervals. On each subinterval <span class="math inline">\([x_{k-1},x_{k}]\)</span>, we pick some point <span class="math inline">\(c_{k}\in[x_{k-1},x_{k}]\)</span> and use the <span class="math inline">\(f(c_{k})\)</span> as an approximation for <span class="math inline">\(f\)</span> on <span class="math inline">\([x_{k-1},x_{k}]\)</span>. Thus the total area of all small rectangles is given by the so-called <em>Riemann sum</em> <span class="math display">\[z_{n}=f(c_{1})\Delta x_{1}+f(c_{2})\Delta x_{2}+\cdots+f(c_{n})\Delta x_{n}\]</span>
where <span class="math inline">\(z_{n}-z_{n-1}=f(c_{n})\Delta x_{n}\)</span>. The accuracy of the <strong>Riemann sum approximation</strong> improves as the rectangles get thinner. When we take the limit <span class="math inline">\(\Delta x_{i}\rightarrow0\)</span> for all <span class="math inline">\(i\)</span>, the width of the subintervals of the partitions tends to zero; if the limit exists, we have <span class="math display">\[\lim_{n\rightarrow\infty}\underset{n-\mbox{partition}}{\underbrace{\left(f(c_{1})\Delta x_{1}+\cdots+f(c_{n})\Delta x_{n}\right)}} = \int_{a}^{b}f(x)\mbox{d}x.\]</span> This limit is called the <em>Riemann integral</em>. Thus the <strong>derivative</strong> is the inverse operation of the <strong>integral</strong>, much as the difference is the inverse operation to addition.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:RiemannInt"></span>
<img src="fig/Part2/RSum.gif" alt="Riemann sum" width="100%"><!--
<p class="caption marginnote">-->Figure 7.5: Riemann sum<!--</p>-->
<!--</div>--></span>
</p>
<p>As you can see, the quality of the <strong>Riemann sum approximation</strong> is directly related to whether <span class="math inline">\(f(c_{k})\)</span> well approximates <span class="math inline">\(f(x)\)</span> as <span class="math inline">\(x\)</span> ranges over the subintervals. Intuitively, it helps to visualize a particular <strong>upper sum</strong> as an overestimate for the value of the integral and a <strong>lower sum</strong> as an underestimate. As the partitions get more refined, the <strong>upper sums</strong> get potentially smaller while the <strong>lower sums</strong> get potentially larger. A function is integrable if the upper and lower sums “meet” at some common value in the middle. For a “reasonable” function, these upper and lower estimates will converge to a common value as the partition is made finer and finer; in this case, we say the <strong>Riemann integral</strong> exists.</p>
<div class="solution">
<p class="solution-begin">
Existence of Riemann sum <span id="sol-start-13" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-13', 'sol-start-13')"></span>
</p>
<div id="sol-body-13" class="solution-body" style="display: none;">
<p>The <strong>Riemann sum approximation</strong> exists if both the <a href="sub-continuity.html#sub:completeness">lower bounds</a> and <a href="sub-continuity.html#sub:completeness">upper bounds</a> of <span class="math inline">\(f(x)\)</span> in those subintervals converge to the same value. Consider a <em>partition</em> <span class="math inline">\(\mathcal{P}=\{x_{0},x_{1},\dots,x_{n}\}\)</span> where <span class="math display">\[a=x_{0}&lt;x_{1}&lt;\cdots&lt;x_{n}=b.\]</span>
For each subinterval <span class="math inline">\([x_{k-1},x_{k}]\in\mathcal{P}\)</span>, let <span class="math inline">\(m_{k}=\inf\{f(x):\, x\in[x_{k-1},x_{k}]\}\)</span> and <span class="math inline">\(M_{k}=\sup\{f(x):\, x\in[x_{k-1},x_{k}]\}\)</span>. The areas of these upper and lower approximations are called <em>upper and lower sums</em> of the partition. The <strong>lower sum</strong> of <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(\mathcal{P}\)</span> is given by <span class="math display">\[L(f,\mathcal{P})=\sum_{k=1}^{n}m_{k}(x_{k}-x_{k-1}).\]</span>
Similarly, the <strong>upper sum</strong> of <span class="math inline">\(f\)</span> with respect to <span class="math inline">\(\mathcal{P}\)</span> is <span class="math display">\[U(f,\mathcal{P})=\sum_{k=1}^{n}M_{k}(x_{k}-x_{k-1}).\]</span>
For a Riemann integrable function, it basically requires those <span class="math inline">\((f(c_{k}))_{k=1}^{n}\)</span> are bounded by <span class="math inline">\(m_{k}\)</span> and <span class="math inline">\(M_{k}\)</span> such that <span class="math inline">\(m_{k}\leq f(c_{k})\leq M_{k}\)</span> on all subintervals. When the number of <strong>partitions</strong> grows to infinity, <span class="math inline">\(n\rightarrow\infty\)</span>, as long as <span class="math inline">\(L(f,\mathcal{P})=U(f,\mathcal{P})\)</span>, we know <span class="math inline">\(f(c_{k})=M_{k}=m_{k}\)</span> well approximates <span class="math inline">\(f(x)\)</span>.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>A statement about the inverse relationship between differentiation and integration is given by the <strong>fundamental theorem of calculus</strong>.<label for="tufte-sn-93" class="margin-toggle sidenote-number">93</label><input type="checkbox" id="tufte-sn-93" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">93</span> The word “fundamental” emphasizes that this is the central result connecting differential and integral calculus.</span></p>
<ul>
<li>
<em>Fundamental theorem of calculus</em> : Let <span class="math inline">\(f\)</span> be <strong>integrable</strong> on <span class="math inline">\([a,b]\)</span>.</li>
</ul>
<ol style="list-style-type: decimal">
<li>Define <span class="math inline">\(F(x)=\int_{a}^{x}f(t)\mbox{d}t\)</span> for <span class="math inline">\(a\leq x\leq b\)</span>; and <span class="math inline">\(F\)</span> is <a href="sub-continuity.html#sub:continuousFunc">continuous</a>. If <span class="math inline">\(f\)</span> is continuous at <span class="math inline">\(x_{0}\)</span>, <span class="math inline">\(F\)</span> is differentiable at <span class="math inline">\(x_{0}\)</span> and <span class="math display">\[\left.\frac{\mbox{d}F(x)}{\mbox{d}x}\right|_{x=x_{0}}=f(x_{0}).\]</span>
</li>
<li>On the other hand, if there is a continuous function <span class="math inline">\(F\)</span> on <span class="math inline">\([a,b]\)</span> that is <strong>differentiable</strong> on <span class="math inline">\((a,b)\)</span> such that <span class="math display">\[\frac{\mbox{d}F(x)}{\mbox{d}x}=f(x), \, \mbox{ then }  \int_{a}^{b}f(x)\mbox{d}x=F(b)-F(a).\]</span>
</li>
</ol>
<p>Because integrations are the inverse operations of differentiations, the rules of integrations can be derived from the differentiation rules.<label for="tufte-sn-94" class="margin-toggle sidenote-number">94</label><input type="checkbox" id="tufte-sn-94" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">94</span> Here are some useful integral results:
<span class="math display">\[\begin{align*}\int x^{n}\mbox{d}x &amp;=\frac{x^{n+1}}{n+1}+C, \\ \int\frac{1}{x}\mbox{d}x &amp;=\ln x+C, \\ 
\int \mbox{e}^{x}\mbox{d}x &amp;=\mbox{e}^{x}+C, \\ \int\cos x\,\mbox{d}x &amp;= \sin x+C, \\
\int\sin x \mbox{d}x &amp;=-\cos x+C.
\end{align*}\]</span> </span> We will mention other specific rules once we need them. At the moment, we only need to pay attention to one more thing: The integral of <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span> is <span class="math inline">\(f(x)+C\)</span> where <span class="math inline">\(C\)</span> is some constant that needs to be determined by some initial condition. To see this, suppose we know the value of <span class="math inline">\(f(a)\)</span>, then <span class="math display">\[\int_{a}^{x}\frac{\mbox{d}f(t)}{\mbox{d}t}\mbox{d}t=f(x)-f(a)=f(x)+C\]</span>
where <span class="math inline">\(C=-f(a)\)</span>.</p>
</div>
<div id="sub:noDiff" class="section level2">
<h2>
<span class="header-section-number">7.2</span> Counterexamples: Continuous and Nowhere Differentiable Function, Integration with Infinite Discontinuities</h2>
<p><span class="newthought">Nowhere differentiable function </span></p>
<p>The relationship between <a href="sub-continuity.html#sub:continuousFunc">continuity</a> and <a href="sub-calculus.html#sub:diffInt">differentiability</a> leads to fruitful results but also reveals several pathological counterexamples. We’ve seen that continuity is a requirement in differentiability. The absolute value function <span class="math inline">\(g(x)=|x|\)</span> for <span class="math inline">\(x\in[-1,1]\)</span> demonstrates that the converse of this statement is not true. For <span class="math inline">\(x\in[-1,0)\)</span>, the <a href="sub-calculus.html#sub:diffInt">derivative</a> of <span class="math inline">\(g\)</span> is <span class="math inline">\(-1\)</span>, and for <span class="math inline">\(x\in(0,1]\)</span>, the <a href="sub-calculus.html#sub:diffInt">derivative</a> is <span class="math inline">\(1\)</span>. The derivative is not well-defined at zero for the absolute value function. However, <span class="math inline">\(|x|\)</span> is continuous at zero because there is no gap in the graph. A function can be continuous but <strong>not differentiable</strong> at some point. For this type of function, we can study its differentiation, excluding the non-differentiable points.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:nowhere"></span>
<img src="fig/Part2/nowhere.gif" alt="Continuous but nowhere differentiable function" width="100%"><!--
<p class="caption marginnote">-->Figure 7.6: Continuous but nowhere differentiable function<!--</p>-->
<!--</div>--></span>
</p>
<p>The simple <strong>non-differentiable</strong> point of the absolute value function can be extended to infinite positions. This extension can lead to a function being continuous on the whole real line but not being differentiable at every point. Figure <a href="sub-calculus.html#fig:nowhere">7.6</a> gives a <a href="sub-incomplete.html#sub:fdim">fractal</a> constructed by the continuous function <span class="math inline">\(g(x)=|x|\)</span>.<label for="tufte-sn-95" class="margin-toggle sidenote-number">95</label><input type="checkbox" id="tufte-sn-95" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">95</span> Let’s copy <span class="math inline">\(g(x)=|x|\)</span> to the whole <span class="math inline">\(\mathbb{R}\)</span> (extend <span class="math inline">\(g(x)=|x|\)</span> as a <strong>periodic</strong> function on <span class="math inline">\(\mathbb{R}\)</span>). Then, we define a sequence of functions <span class="math inline">\(g_{i}(x)=(0.75)^{i}g(4^{i}x)\)</span>. In each <a href="sub-continuity.html#sub:Cauchy">iteration</a> <span class="math inline">\(i\)</span>, we take this extended function, choose the input position four times the previous position, and scale the magnitude by a factor <span class="math inline">\(0.75\)</span>. Then this iteration will generate a fractal feature. Now we define a function <span class="math inline">\(f\)</span> as the sum of all these <a href="sub-inferknow.html#sub:dyn">self-similar</a> functions such that <span class="math inline">\(f_{n}(x)=\sum_{i=0}^{n}g_{i}(x)\)</span>.</span> The figure shows that zigzags happen almost everywhere on the real line. These zigzags make the function <strong>nowhere differentiable</strong> but preserve the <a href="sub-continuity.html#sub:continuousFunc">continuity</a>. The same type of zigzags can be found in the financial charts, such as stock market prices, foreign exchange rates, etc. The standard differentiation is not suitable for modeling those zigzagging phenomena. In chapter [?], a new perspective will be introduced to model the non-differentiable phenomena.</p>
<p><span class="newthought">Lebesgue integral </span></p>
<p><a href="sub-calculus.html#sub:diffInt">Integration</a>, in general, is harder than <a href="sub-calculus.html#sub:diffInt">differentiation</a>. Between local and global problems, global problems are more laborious. Integration is a global operation. However, in terms of condition, the requirement of integration does not strictly ask for continuity so it seems less restrictive.</p>
<p>Consider the <a href="sub-set-theory.html#sub:func">indicator function</a> <span class="math inline">\(f(x)=\mathbf{1}_{1}(x)\)</span> such that <span class="math inline">\(f(x)=1\)</span> when <span class="math inline">\(x=1\)</span>, otherwise <span class="math inline">\(f(x)=0\)</span>. This function is not continuous at <span class="math inline">\(1\)</span>. But for the integration, we can directly find out that the result <span class="math inline">\(x=1\)</span>, a singleton, will contribute <span class="math inline">\(0\)</span> area in our calculation. This example shows that a <a href="sub-continuity.html#sub:completeness">bounded</a> function with a single discontinuity is <a href="sub-calculus.html#sub:diffInt">integrable</a>. In fact, As long as the function only misbehaves at the discontinuities, and the discontinuous points can be isolated from the integrable domain, then the function will be <a href="sub-calculus.html#sub:diffInt">integrable</a>.</p>
<p>But things are more complicated when we turn to the Dirichlet’s function (see figure <a href="sub-continuity.html#fig:DiriFunc">6.2</a>). For a bounded and closed interval, say <span class="math inline">\([0,1]\)</span>, we almost can guess that the area of “this integral” would be zero. Nevertheless, when we construct an arbitrary <a href="sub-calculus.html#sub:diffInt">partition</a> on <span class="math inline">\([0,1]\)</span>, any subinterval of this partition will have one as the <a href="sub-continuity.html#sub:completeness">upper bound</a> for <a href="sub-continuity.html#sub:rational">rationals</a> and zero as the <a href="sub-continuity.html#sub:completeness">lower bound</a> for <a href="sub-continuity.html#sub:rational">irrationals</a>. These bounds never change no matter how small the subinterval is. Therefore, Dirichlet’s function is not integrable just in the <a href="sub-calculus.html#sub:diffInt">Riemann’s sense</a>. Riemann integral fails for those functions with an infinite number of discontinuities. In the Riemann’s sense, <a href="sub-continuity.html#sub:continuousFunc">continuous functions</a> are <a href="sub-calculus.html#sub:diffInt">integrable</a>, functions with only a finite number of discontinuities are also integrable but functions with infinite discontinuities are not.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:LebIn"></span>
<img src="fig/Part2/LebIn.gif" alt="Riemann integral and Lebesgue integral" width="100%"><!--
<p class="caption marginnote">-->Figure 7.7: Riemann integral and Lebesgue integral<!--</p>-->
<!--</div>--></span>
</p>
<p>However, the figure <a href="sub-continuity.html#fig:DiriFunc">6.2</a> of Dirichlet’s function tells that the function must be integrable on <span class="math inline">\([0,1]\)</span> in some sense. In fact, just like a singleton contributes zero volume to the total area, an infinite number of discontinuous points may also make zero contribution to the total area as long as the set of the discontinuous points has “zero length.” The notion of zero length or zero <a href="sub-incomplete.html#sub:beyond2">measure</a> was mentioned in the discussion of the Cantor set (chapter <a href="sub-incomplete.html#sub:beyond2">5.3</a>). For Dirichlet’s function <span class="math inline">\(f\)</span>, the <a href="#sub:rationals">rational numbers</a> on <span class="math inline">\([0,1]\)</span> have zero length (<a href="sub-incomplete.html#sub:diagonal">countable</a>), and the <a href="#sub:rationals">irrational numbers</a> on <span class="math inline">\([0,1]\)</span> have <span class="math inline">\(1\)</span> length as they almost cover the whole interval (<a href="sub-incomplete.html#sub:diagonal">uncountable</a>). We can define a new integral for this function: <span class="math display">\[\begin{align*} \int_{0}^{1}f(x)\mbox{d}x &amp;= 1\times\left[\mbox{length of set where }f=1\right] \\
&amp;+ 0\times\left[\mbox{length of set where }f=0\right]=1\times0+0\times1=0.
\end{align*}\]</span>
It means that we can extend the integrability to a set of infinite discontinuities if and only if this set has zero length (zero measure). This extended integral is called the <em>Lebesgue’s integral</em>.</p>
<p>In order to eliminate the effect of “zero length” set, we construct the <strong>Lebesgue’s integration</strong> with respect to the <a href="sub-set-theory.html#sub:func">image</a> of the function rather than the <a href="sub-set-theory.html#sub:func">domain</a>. In figure <a href="sub-calculus.html#fig:LebIn">7.7</a>, we compare these two different senses of integrations. In the case of the <a href="sub-calculus.html#sub:diffInt">Riemann integral</a> (left), the <a href="sub-set-theory.html#sub:func">domain</a> is subdivided first; then, each subdivision constructs a rectangle to approximate the corresponding area covered by the function. In the case of the <strong>Lebesgue’s integral</strong> (right), the <a href="sub-set-theory.html#sub:func">image</a> of the function is subdivided first, then the corresponding division of the domain is found. The <strong>Lebesgue’s integral</strong> is available for more general functions than the Riemann ones.</p>
</div>
<div id="sub:opt" class="section level2">
<h2>
<span class="header-section-number">7.3</span> Optimality</h2>
<p>One prominent application of differential calculus is <em>optimization</em>: the process of finding the function’s <a href="sub-continuity.html#sub:completeness">maximal</a> and <a href="sub-continuity.html#sub:completeness">minimal</a> values. First, notice that on a closed and bounded interval, the continuous function always has its maximum and minimum (<a href="sub-continuity.html#sub:continuousFunc">extreme value property</a>). Second, we can use the <a href="sub-calculus.html#sub:diffInt">derivative</a> to testify the (local) monotonicity of the function. The derivative is the slope of the tangent to the curve <span class="math inline">\(y=f(x)\)</span>. If <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x&gt;0\)</span> for <span class="math inline">\(x\in(a,b)\)</span>, the function looks increasing on that interval; if <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x&lt;0\)</span> for <span class="math inline">\(x\in(a,b)\)</span>, the function seems to decrease. Third, we can testify the (local) <strong>optimality</strong> by monotonicity. If a function is monotonic increasing on <span class="math inline">\((a,c)\)</span> but becomes monotonic decreasing on <span class="math inline">\((c,b)\)</span>, we may guess that <span class="math inline">\(c\)</span> is a (local) <a href="sub-continuity.html#sub:completeness">maximum</a> point for the function. Finally, because <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x&gt;0\)</span> on <span class="math inline">\((a,c)\)</span> and <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x&lt;0\)</span> on <span class="math inline">\((c,b)\)</span>, by <a href="sub-continuity.html#sub:continuousFunc">intermediate value property</a>, we should have <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x=0\)</span> at <span class="math inline">\(c\)</span>, which means the (local) maximum point attains zero derivative. The similar argument should also hold for the minimum. Then, we may have a criterion, namely zero derivative, for the (local) <strong>optimal</strong> points.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:MVT"></span>
<img src="fig/Part2/MVT.gif" alt="Fermat's theorem and mean value theorem" width="100%"><!--
<p class="caption marginnote">-->Figure 7.8: Fermat’s theorem and mean value theorem<!--</p>-->
<!--</div>--></span>
</p>
<p>Fermat in the 17th century proposed a theorem to justify the above rough procedure rigorously.<label for="tufte-sn-96" class="margin-toggle sidenote-number">96</label><input type="checkbox" id="tufte-sn-96" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">96</span> Fermat was a lawyer and provincial judge in Toulouse who merely corresponded with major mathematicians of his day through a Franciscan friar to spread his results.</span> By studying the refraction phenomena, Fermat guessed the light always followed the path of least resistance between any two points, (which he took to mean that it traveled along the fastest possible route). Fermat had applied his embryonic version of <a href="sub-calculus.html#sub:calculus">differential calculus</a> to physics. This is the <em>principle of least time (action)</em>, later known as the <em>optimization principle</em>. The principle believes that nature behaves most economically, and it has been found to predict the laws of mechanics correctly. Fermat’s principle revealed that optimization is woven deeply into the fabric of nature. It also expands our conception of what a <a href="sub-calculus.html#sub:diffInt">rate of change</a> is.</p>
<ul>
<li>
<em>Fermat’s theorem</em> : Let <span class="math inline">\(f:[a,b] \mapsto \mathbb{R}\)</span> be a continuous function that takes its maximum or minimum value at point <span class="math inline">\(x^{*}\in(a,b)\)</span>. If <span class="math inline">\(f\)</span> is differentiable at <span class="math inline">\(x^{*}\)</span>, then <span class="math display">\[\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=x^{*}}=0.\]</span>
</li>
</ul>
<div class="solution">
<p class="solution-begin">
Proof <span id="sol-start-14" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-14', 'sol-start-14')"></span>
</p>
<div id="sol-body-14" class="solution-body" style="display: none;">
<p>Assume that <span class="math inline">\(x_{0}\)</span> is a maximum. Since <span class="math inline">\(f(x^{*}+\epsilon)-f(x^{*})\leq0\)</span> and <span class="math inline">\(f(x^{*})-f(x^{*}-\epsilon)\geq0\)</span>, the limits yield
<span class="math display">\[\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=x^{*}} =\lim_{\epsilon\rightarrow0}\frac{f(x^{*}+\epsilon)-f(x^{*})}{\epsilon}\leq0
    \leq\lim_{\epsilon\rightarrow0}\frac{f(x^{*})-f(x^{*}-\epsilon)}{\epsilon}=\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=x^{*}}.\]</span></p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>The theorem gives the location of possible extrema. That is, the extrema of a continuous function <span class="math inline">\(f:[a,b]\mapsto\mathbb{R}\)</span> occur either at the endpoints or at some interior points.<label for="tufte-sn-97" class="margin-toggle sidenote-number">97</label><input type="checkbox" id="tufte-sn-97" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">97</span> The interior set of the closed bounded interval <span class="math inline">\([a,b]\)</span> is <span class="math inline">\((a,b)\)</span>.</span> At the endpoints, the derivative is undefined; at the interior points, the derivative is equal to zero.</p>
<p>One essential consequence of <strong>Fermat’s theorem</strong> yields the <em>mean value theorem</em>, a fundamental approximation tool of differential calculus.</p>
<ul>
<li>
<em>Mean value theorem</em> : Let <span class="math inline">\(f\)</span> be a continuous and differentiable function on <span class="math inline">\([a,b]\)</span>. Then there is a point <span class="math inline">\(c\in(a,b)\)</span> such that <span class="math display">\[\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=c}=\frac{f(b)-f(a)}{b-a}.\]</span>
</li>
</ul>
<div class="solution">
<p class="solution-begin">
Proof <span id="sol-start-15" class="fa fa-plus-square solution-icon clickable" onclick="toggle_visibility('sol-body-15', 'sol-start-15')"></span>
</p>
<div id="sol-body-15" class="solution-body" style="display: none;">
<p>Case 1: Consider <span class="math inline">\(f(a)=f(b)=0\)</span>. If the maximum and minimum values of <span class="math inline">\(f\)</span> are both zero, then <span class="math inline">\(f\)</span>
is constant and <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x|_{x=c}=0\)</span> for all <span class="math inline">\(c\in(a,b)\)</span>. Otherwise, either the maximum is greater than <span class="math inline">\(0\)</span>, or the minimum is less than <span class="math inline">\(0\)</span>. In either case, there is a point <span class="math inline">\(c\in(a,b)\)</span> at which <span class="math inline">\(f\)</span> attains the extreme value. By <strong>Fermat’s theorem</strong>, <span class="math display">\[\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=c}=\frac{f(b)-f(a)}{b-a}=0.\]</span></p>
<p>Case 2: Now rescale the curve. Let <span class="math inline">\(L(x)\)</span> be the linear function through <span class="math inline">\((a,f(a))\)</span> and <span class="math inline">\((b,f(b))\)</span>
<span class="math display">\[L(x)=f(a)+\frac{f(b)-f(a)}{b-a}(x-a).\]</span>
Consider a function <span class="math inline">\(g(x)=f(x)-L(x)\)</span>. Note that both <span class="math inline">\(f\)</span> and <span class="math inline">\(L\)</span> are continuous and differentiable on <span class="math inline">\([a,b]\)</span>, so is <span class="math inline">\(g\)</span>. Moreover, <span class="math inline">\(g(a)=g(b)=0\)</span>. So we are back to Case 1. That is, a point <span class="math inline">\(c\in(a,b)\)</span> exists such that
<span class="math display">\[0=\left.\frac{\mbox{d}g(x)}{\mbox{d}x}\right|_{x=c}=\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=c}-\frac{f(b)-f(a)}{b-a},\]</span>
which implies the result.</p>
<p class="solution-end">
<span class="fa fa-square-o solution-icon"></span>
</p>
</div>
</div>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:MVTproof"></span>
<img src="fig/Part2/MVTproof.gif" alt="Proof of mean value theorem" width="100%"><!--
<p class="caption marginnote">-->Figure 7.9: Proof of mean value theorem<!--</p>-->
<!--</div>--></span>
</p>
<p>Figure <a href="sub-calculus.html#fig:MVTproof">7.9</a> gives a graphical proof of the theorem. The <strong>mean value theorem</strong> makes the geometrically plausible assertion that a differentiable function <span class="math inline">\(f\)</span> on an interval <span class="math inline">\([a,b]\)</span> will, at some point, attain a slope equal to the slope of the line through the endpoints. If the <a href="#sub:diffint">derivative</a> of <span class="math inline">\(f\)</span> is zero everywhere on the interval <span class="math inline">\([a,b]\)</span>, the <strong>mean value theorem</strong> quickly tells that <span class="math inline">\(f\)</span> is a constant function on <span class="math inline">\([a,b]\)</span>. Also, we can rigorously justify our previous intuition of the <strong>monotonicities</strong>. For any <span class="math inline">\(a\leq x_{1}&lt;x_{2}\leq b\)</span>, the <strong>mean value theorem</strong> says that a point <span class="math inline">\(c\)</span> gives <span class="math display">\[f(x_{2})-f(x_{1})=\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=c}(x_{2}-x_{1}).\]</span>
For <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x|_{x=c}&gt;0\)</span>, we deduce that <span class="math inline">\(f(x_{2})-f(x_{1})&gt;0\)</span>, and thus <span class="math inline">\(f\)</span> is strictly increasing. On the other hand, for <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x|_{x=c}&lt;0\)</span>, we have a strictly decreasing <span class="math inline">\(f\)</span>. Therefore we can summarize the <em>trend properties</em> for a <a href="#sub:diffint">differentiable</a> function <span class="math inline">\(f\)</span> on <span class="math inline">\([a,b]\)</span>:</p>
<ul>
<li><p><em>(strictly) Increasing</em> : <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span> is (strictly) positive.</p></li>
<li><p><em>(strictly) Decreasing</em> : <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span> is (strictly) negative.</p></li>
<li><p><em>Constant</em> : <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x=0\)</span> for any <span class="math inline">\(x\in(a,b)\)</span>.</p></li>
</ul>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:1st2nd"></span>
<img src="fig/Part2/1st2nd.gif" alt="The first and the second derivatives" width="100%"><!--
<p class="caption marginnote">-->Figure 7.10: The first and the second derivatives<!--</p>-->
<!--</div>--></span>
</p>
<p>Whether the optimal point is <a href="sub-continuity.html#sub:completeness">maximum</a> or <a href="sub-continuity.html#sub:completeness">minimum</a> is not revealed by the <a href="#sub:diffint">(first-order) derivative</a> but by the <em>second-order derivative</em>, namely the <a href="#sub:diffint">change rate</a> of the first derivative: <span class="math display">\[\mbox{d}\left(\frac{\mbox{d}f(x)}{\mbox{d}x}\right)/\mbox{d}x=\frac{\mbox{d}^{2}f(x)}{\mbox{d}x^{2}}.\]</span>
We illustrate the reason as follows. Let <span class="math inline">\(\mbox{d}^{2}f(x)/\mbox{d}x^{2}&gt;0\)</span>, we know that <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span>
will be <strong>increasing</strong> (an increasing function has a positive derivative). Let <span class="math inline">\(c\)</span> be an extremum such that <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x|_{x=c}=0\)</span> by the <strong>Fermat’s theorem</strong>. If the <strong>second-order derivative</strong> is positive at <span class="math inline">\(c\)</span>, we know that at <span class="math inline">\((c-\epsilon,c+\epsilon)\)</span> the derivative will be positive, namely <span class="math inline">\(f(x)\)</span> will be larger than <span class="math inline">\(f(c)\)</span> for <span class="math inline">\(x\in(c-\epsilon,c+\epsilon)\)</span> due to the positive derivative of <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x\)</span>, so this extremum point must be the minimum point in the neighborhood. (Figure <a href="sub-calculus.html#fig:1st2nd">7.10</a>).<label for="tufte-sn-98" class="margin-toggle sidenote-number">98</label><input type="checkbox" id="tufte-sn-98" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">98</span> 
The <strong>second derivative</strong> tells us about the <em>curvature</em> of the function. If the <strong>curvature</strong> of a function is positive, this means the function’s slope is increasing, so the function must curve upward. The negative curvature means that the function curves downward.</span></p>
<ul>
<li><p><em>(local) Minimum</em> : If <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x|_{x=c}=0\)</span> and <span class="math inline">\(\mbox{d}^{2}f(x)/\mbox{d}x^{2}|_{x=c}&gt;0\)</span>, then <span class="math inline">\(c\)</span> is a local minimum.</p></li>
<li><p><em>(local) Maximum</em> : If <span class="math inline">\(\mbox{d}f(x)/\mbox{d}x|_{x=c}=0\)</span> and <span class="math inline">\(\mbox{d}^{2}f(x)/\mbox{d}x^{2}|_{x=c}&lt;0\)</span>, then <span class="math inline">\(c\)</span>
is a local maximum.</p></li>
</ul>
</div>
<div id="sub:Taylor" class="section level2">
<h2>
<span class="header-section-number">7.4</span> Examples: Power Series and Taylor Series</h2>
<p>If we take the <a href="#sub:diffint">derivative</a> of the <a href="sub-calculus.html#sub:opt">second derivative</a>, we obtain the <em>third derivative</em> of the function. This process can be continued further to get the <em><span class="math inline">\(n\)</span>-th derivative</em> of the function: <span class="math display">\[f^{(n)}(x)=\frac{\mbox{d}^{n}f(x)}{\mbox{d}x^{n}}=\underset{n\mbox{-derivative}}{\underbrace{\frac{\mbox{d}}{\mbox{d}x}\frac{\mbox{d}}{\mbox{d}x}\cdots\frac{\mbox{d}}{\mbox{d}x}}}f(x).\]</span>
<strong>Higher order derivatives</strong> do not have an apparent geometrical interpretation. But it is useful in applications.</p>
<p>Consider the following function <span class="math display">\[f(x)=\sum_{n=0}^{\infty}c_{n}x^{n}=c_{0}+c_{1}x+c_{2}x^{2}+c_{3}x^{3}+\cdots,\]</span>
which is called the <em>power series</em>. A <strong>power series</strong> is <a href="sub-continuity.html#sub:continuousFunc">continuous</a> and <a href="#sub:diffint">differentiable</a> at every point at which it converges. By the <a href="#sub:diffint">differentiation rule of power functions</a>, we have <span class="math inline">\(\mbox{d}(c_{n}x^{n})/\mbox{d}x = nc_n x^{n-1}\)</span>. Then the term-by-term differentation of <span class="math inline">\(\sum_{n=0}^{\infty}c_{n}x^{n}\)</span> gives <span class="math inline">\(\sum_{n=1}^{\infty}nc_{n}x^{n-1}\)</span>, which is another <strong>power series</strong>. By induction, power series are differentiable with an infinite number of times.</p>
<p>Despite the infinite terms of the <strong>power series</strong>, the series can be manipulated more or less as polynomials, a natural functional form in many situations. In fact, an appealing idea of the power series is that it can approximate almost all well-behaved functions, namely almost all <strong>infinitely differentiable</strong> functions.</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:Taylor"></span>
<img src="fig/Part2/Taylor.gif" alt="Talyor series approximates the sine function " width="100%"><!--
<p class="caption marginnote">-->Figure 7.11: Talyor series approximates the sine function <!--</p>-->
<!--</div>--></span>
</p>
<p>Let’s consider a function <span class="math inline">\(f(x)\)</span> at points <span class="math inline">\(x_{0}\)</span>, <span class="math inline">\(x_{1}=x_{0}+\Delta x\)</span>, <span class="math inline">\(x_{2}=x_{0}+2\Delta x\)</span>, etc. For the point <span class="math inline">\(x_{0}\)</span> and <span class="math inline">\(x_{1}\)</span>, we can interpolate them linearly <span class="math display">\[f(x)\approx f(x_{0})+\frac{f(x_{0}+\Delta x)-f(x_{0})}{\Delta x}(x-x_{0})=y_{0}+\frac{\Delta y_{0}}{\Delta x}(x-x_{0}).\]</span>
Taking the limit <span class="math inline">\(\Delta x\rightarrow0\)</span>, we have the (best) <em>linear approximation</em> <span class="math display">\[f(x)\approx y_{0}+\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=x_{0}}(x-x_{0}).\]</span>
But if <span class="math inline">\(f\)</span> is a highly nonlinear function, e.g. <span class="math inline">\(f(x)=\sin(x)\)</span>, the <strong>linear approximation</strong> above is too primitive. We can consider adding the <a href="sub-calculus.html#sub:opt">second derivative</a> to the approximation such that<label for="tufte-sn-99" class="margin-toggle sidenote-number">99</label><input type="checkbox" id="tufte-sn-99" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">99</span> The coefficient <span class="math inline">\(1/2\)</span> in the second term <span class="math display">\[\frac{1}{2}\frac{\mbox{d}^{2}f(x)}{\mbox{d}x^{2}}\]</span> comes from the limit
of <span class="math display">\[\begin{align*}&amp; \lim_{\Delta x\rightarrow0}\frac{\Delta^{2}y_{0}}{(x_{1}-x_{0})(x_{2}-x_{0})}\\
=&amp; \lim_{\Delta x\rightarrow0}\frac{\Delta^{2}y_{0}}{(\Delta x)(2 \Delta x)}\\
=&amp; \lim_{\Delta x\rightarrow0}\frac{\Delta^{2}y_{0}}{2(\Delta x)^{2}}=\frac{1}{2}\frac{\mbox{d}^{2}f(x)}{\mbox{d}x^{2}},\end{align*}\]</span> and the product <span class="math inline">\((x-x_{0})(x-x_{1})\)</span> converges to <span class="math inline">\((x-x_{0})^{2}\)</span> when <span class="math inline">\(\Delta x \rightarrow 0\)</span>.</span> <span class="math display">\[f(x)\approx y_{0}+\left.\frac{\mbox{d}f(x)}{\mbox{d}x}\right|_{x=x_{0}}(x-x_{0})+\frac{1}{2}\left.\frac{\mbox{d}^{2}f(x)}{\mbox{d}x^{2}}\right|_{x=x_{0}}(x-x_{0})^{2}.\]</span>
Dependent on the satisfaction of the approximation, we can keep adding <strong>higher derivatives</strong> to the function. This is a recipe for generating a <strong>power series</strong> representation using only the function in question and its derivatives. The series is called the <em>Taylor series</em>. For a function <span class="math inline">\(f(x)\)</span> defined in some neighborhood of <span class="math inline">\(x_{0}\in\mathbb{R}\)</span>, Taylor series expands <span class="math inline">\(f(x)\)</span> around the point <span class="math inline">\(x_{0}\)</span>:
<span class="math display">\[T(x)=c_{0}+c_{1}(x-x_{0})+\cdots + c_{n}(x-x_{0})^{n} +\cdots,\;\mbox{where }c_{n}=\frac{f^{(n)}(x_{0})}{n!}.\]</span>
In practice, one can only use the first <span class="math inline">\(n\)</span> terms of the series, which we denote as <span class="math inline">\(T_{n}(x)\)</span>. <strong>Taylor series</strong> is a pointwise approximation as the representation of <span class="math inline">\(T(x)\)</span> is expanded at the chosen point <span class="math inline">\(x_{0}\)</span>. When the point <span class="math inline">\(x_{0}\)</span> varies, the derivatives vary so as the expansion. Figure <a href="sub-calculus.html#fig:Taylor">7.11</a> gives the approximation for a cosine function (an infinitely differentiable function).<label for="tufte-sn-100" class="margin-toggle sidenote-number">100</label><input type="checkbox" id="tufte-sn-100" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">100</span> To derive a Taylor series for <span class="math inline">\(\sin(x)\)</span> at <span class="math inline">\(x_{0}=0\)</span>, let’s set <span class="math inline">\(c_{0}=\sin(0)=0\)</span>, <span class="math inline">\(c_{1}=\cos(0)=1\)</span>, <span class="math inline">\(c_{2}=-\sin(0)/2!=0\)</span>, <span class="math inline">\(c_{3}=-\cos(0)/3!=1/3!\)</span>, etc. The series of <span class="math inline">\(\sin(x)\)</span> is <span class="math display">\[x-\frac{x^{3}}{3!}+\frac{x^{5}}{5!}-\frac{x^{7}}{7!}+\cdots.\]</span></span>
<strong>Taylor series</strong> is less likely to converge for those <span class="math inline">\(x\)</span> that are far from the chosen point <span class="math inline">\(x_{0}\)</span>. Although the formulae give good approximations in certain cases, in general, they fail to control the approximation error because the functions are not approximated uniformly; the error grows beyond the interpolation points or the expansion point. The general idea of approximations and applications will be given in chapter [?].</p>
</div>
</div></body></html>

<p style="text-align: center;">
<a href="sub-continuity.html"><button class="btn btn-default">Previous</button></a>
<a href="ch-DE.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-08-30
</p>
</div>
</div>



</body>
</html>
